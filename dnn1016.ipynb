{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df = pd.read_excel(\"C:\\\\Users\\\\user\\\\Desktop\\\\machine\\\\data_1017.xlsx\",sheet_name=\"Sheet1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sex  sc_code  age                                        ht_omr_data  \\\n",
      "0    1        3   32  9011110110000010001001001000101010001001101010...   \n",
      "1    1        1   39  1100010110000000001001101099100111011001101010...   \n",
      "2    1        4   39  9110000110100000000001111000101010000000101110...   \n",
      "3    2        3   34  0000010110000000001000000000101010001000000010...   \n",
      "4    1        2   34  0000100111010000011000101000101010000001000100...   \n",
      "\n",
      "  fixed_type  FG Q1 Q2 Q3 Q4  ... Q366 Q367 Q368 Q369 Q370 Q371 Q372 Q373  \\\n",
      "0          A   0  9  0  1  1  ...    0    0    0    0    0    1    0    0   \n",
      "1          C   0  1  1  0  0  ...    0    0    1    0    0    1    0    0   \n",
      "2          M   0  9  1  1  0  ...    0    0    1    0    0    1    0    0   \n",
      "3          M   0  0  0  0  0  ...    0    1    1    0    0    1    0    1   \n",
      "4          B   0  0  0  0  0  ...    1    0    1    0    0    1    0    0   \n",
      "\n",
      "  Q374 Q375  \n",
      "0    0    1  \n",
      "1    1    1  \n",
      "2    0    1  \n",
      "3    0    1  \n",
      "4    1    1  \n",
      "\n",
      "[5 rows x 381 columns]\n"
     ]
    }
   ],
   "source": [
    "# def split_omr_data(df):\n",
    "#     # 'ht_omr_data' 열의 값을 리스트로 변환 (한 글자씩)\n",
    "#     omr_responses = df['ht_omr_data'].apply(lambda x: list(x[:375]))  # 375개의 문항까지만 자름\n",
    "#     # 리스트를 각각의 문항으로 나누어 새로운 컬럼으로 변환\n",
    "#     omr_df = pd.DataFrame(omr_responses.tolist(), columns=[f'Q{i+1}' for i in range(375)])\n",
    "#     # 원래 df와 결합\n",
    "#     df = pd.concat([df, omr_df], axis=1)\n",
    "#     return df\n",
    "\n",
    "# # 데이터 분리 실행\n",
    "# df_split = split_omr_data(df)\n",
    "\n",
    "# # 결과 확인\n",
    "# print(df_split.head())\n",
    "# df = df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>sc_code</th>\n",
       "      <th>age</th>\n",
       "      <th>ht_omr_data</th>\n",
       "      <th>fixed_type</th>\n",
       "      <th>FG</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>...</th>\n",
       "      <th>t18</th>\n",
       "      <th>t19</th>\n",
       "      <th>t20</th>\n",
       "      <th>t21</th>\n",
       "      <th>t22</th>\n",
       "      <th>t23</th>\n",
       "      <th>t24</th>\n",
       "      <th>t25</th>\n",
       "      <th>t26</th>\n",
       "      <th>t27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9011110110000010001001001000101010001001101010...</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>44</td>\n",
       "      <td>62</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "      <td>39</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1100010110000000001001101099100111011001101010...</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61</td>\n",
       "      <td>56</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>44</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9110000110100000000001111000101010000000101110...</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0000010110000000001000000000101010001000000010...</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0000100111010000011000101000101010000001000100...</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0010100000000010000001001001101010001010011110...</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>55</td>\n",
       "      <td>35</td>\n",
       "      <td>66</td>\n",
       "      <td>44</td>\n",
       "      <td>60</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  sc_code   age                                        ht_omr_data  \\\n",
       "0  1.0      3.0  32.0  9011110110000010001001001000101010001001101010...   \n",
       "1  1.0      1.0  39.0  1100010110000000001001101099100111011001101010...   \n",
       "2  1.0      4.0  39.0  9110000110100000000001111000101010000000101110...   \n",
       "3  2.0      3.0  34.0  0000010110000000001000000000101010001000000010...   \n",
       "4  1.0      2.0  34.0  0000100111010000011000101000101010000001000100...   \n",
       "5  2.0      3.0  27.0  0010100000000010000001001001101010001010011110...   \n",
       "\n",
       "  fixed_type   FG  t1  t2  t3  t4  ...  t18  t19  t20  t21  t22  t23  t24  \\\n",
       "0          A  0.0  48  55  57  54  ...   68   44   62   37   49   53   51   \n",
       "1          C  0.0  61  56  61  60  ...   26   42   41   30   39   43   54   \n",
       "2          M  0.0  46  36  51  52  ...   44   43   55   47   44   44   48   \n",
       "3          M  0.0  46  54  46  61  ...   34   44   41   36   46   44   40   \n",
       "4          B  0.0  37  39  46  50  ...   61   42   45   46   42   43   42   \n",
       "5          M  1.0  41  20  49  47  ...   45   44   55   35   66   44   60   \n",
       "\n",
       "   t25  t26  t27  \n",
       "0   46   39   61  \n",
       "1   44   57   41  \n",
       "2   45   43   65  \n",
       "3   46   41   57  \n",
       "4   44   41   41  \n",
       "5   47   57   59  \n",
       "\n",
       "[6 rows x 33 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'D1': 4, 'D2': 5, 'E': 6, 'M': 7, 'M1': 8, 'M2': 9, 'Ma': 10, 'Mb': 11, 'Mc': 12, 'R': 13, 'X': 14}\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# 'fixed_type'을 숫자형으로 변환\n",
    "df['fixed_type_encoded'] = label_encoder.fit_transform(df['fixed_type'])\n",
    "\n",
    "print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['fixed_type','ht_omr_data','FG'], axis=1)\n",
    "# df = df.drop(['FG'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>sc_code</th>\n",
       "      <th>age</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "      <th>t6</th>\n",
       "      <th>t7</th>\n",
       "      <th>...</th>\n",
       "      <th>t19</th>\n",
       "      <th>t20</th>\n",
       "      <th>t21</th>\n",
       "      <th>t22</th>\n",
       "      <th>t23</th>\n",
       "      <th>t24</th>\n",
       "      <th>t25</th>\n",
       "      <th>t26</th>\n",
       "      <th>t27</th>\n",
       "      <th>fixed_type_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>62</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "      <td>39</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>61</td>\n",
       "      <td>56</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>44</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>65</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "      <td>61</td>\n",
       "      <td>48</td>\n",
       "      <td>59</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30866</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30867</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>43</td>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>57</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30868</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>53</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>64</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30869</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30870</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30871 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex  sc_code  age  t1  t2  t3  t4  t5  t6  t7  ...  t19  t20  t21  t22  \\\n",
       "0        1        3   32  48  55  57  54  46  59  60  ...   44   62   37   49   \n",
       "1        1        1   39  61  56  61  60  50  57  55  ...   42   41   30   39   \n",
       "2        1        4   39  46  36  51  52  46  52  49  ...   43   55   47   44   \n",
       "3        2        3   34  46  54  46  61  48  59  52  ...   44   41   36   46   \n",
       "4        1        2   34  37  39  46  50  44  57  64  ...   42   45   46   42   \n",
       "...    ...      ...  ...  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
       "30866    1        3   39  44  51  51  56  58  57  49  ...   43   41   41   44   \n",
       "30867    1        1   29  43  53  43  49  43  46  45  ...   52   80   60   55   \n",
       "30868    2        1   38  45  35  53  42  44  45  54  ...   51   47   64   52   \n",
       "30869    2        1   18  43  51  50  44  51  52  49  ...   45   41   40   50   \n",
       "30870    1        3   35  42  47  50  42  55  46  52  ...   51   48   55   46   \n",
       "\n",
       "       t23  t24  t25  t26  t27  fixed_type_encoded  \n",
       "0       53   51   46   39   61                   0  \n",
       "1       43   54   44   57   41                   2  \n",
       "2       44   48   45   43   65                   7  \n",
       "3       44   40   46   41   57                   7  \n",
       "4       43   42   44   41   41                   1  \n",
       "...    ...  ...  ...  ...  ...                 ...  \n",
       "30866   51   53   45   58   53                   0  \n",
       "30867   60   45   57   47   38                   7  \n",
       "30868   43   41   43   40   39                   0  \n",
       "30869   42   50   46   42   45                   0  \n",
       "30870   53   46   59   44   44                   7  \n",
       "\n",
       "[30871 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                   int64\n",
       "sc_code               int64\n",
       "age                   int64\n",
       "t1                    int64\n",
       "t2                    int64\n",
       "t3                    int64\n",
       "t4                    int64\n",
       "t5                    int64\n",
       "t6                    int64\n",
       "t7                    int64\n",
       "t8                    int64\n",
       "t9                    int64\n",
       "t10                   int64\n",
       "t11                   int64\n",
       "t12                   int64\n",
       "t13                   int64\n",
       "t14                   int64\n",
       "t15                   int64\n",
       "t16                   int64\n",
       "t17                   int64\n",
       "t18                   int64\n",
       "t19                   int64\n",
       "t20                   int64\n",
       "t21                   int64\n",
       "t22                   int64\n",
       "t23                   int64\n",
       "t24                   int64\n",
       "t25                   int64\n",
       "t26                   int64\n",
       "t27                   int64\n",
       "fixed_type_encoded    int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'D1': 4, 'D2': 5, 'E': 6, 'M': 7, 'M1': 8, 'M2': 9, 'Ma': 10, 'Mb': 11, 'Mc': 12, 'R': 13, 'X': 14}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0562 - loss: 3.3845\n",
      "Epoch 1: val_loss improved from inf to 2.99127, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0563 - loss: 3.3841 - val_accuracy: 0.0959 - val_loss: 2.9913\n",
      "Epoch 2/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0731 - loss: 3.2850\n",
      "Epoch 2: val_loss improved from 2.99127 to 2.92125, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0732 - loss: 3.2844 - val_accuracy: 0.1325 - val_loss: 2.9213\n",
      "Epoch 3/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0861 - loss: 3.1807\n",
      "Epoch 3: val_loss improved from 2.92125 to 2.84956, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0861 - loss: 3.1806 - val_accuracy: 0.1849 - val_loss: 2.8496\n",
      "Epoch 4/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1089 - loss: 3.0866\n",
      "Epoch 4: val_loss improved from 2.84956 to 2.77788, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1090 - loss: 3.0863 - val_accuracy: 0.2322 - val_loss: 2.7779\n",
      "Epoch 5/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1345 - loss: 2.9890\n",
      "Epoch 5: val_loss improved from 2.77788 to 2.72413, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1345 - loss: 2.9889 - val_accuracy: 0.2709 - val_loss: 2.7241\n",
      "Epoch 6/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1581 - loss: 2.9118\n",
      "Epoch 6: val_loss improved from 2.72413 to 2.66437, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1584 - loss: 2.9112 - val_accuracy: 0.3168 - val_loss: 2.6644\n",
      "Epoch 7/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1887 - loss: 2.8414\n",
      "Epoch 7: val_loss improved from 2.66437 to 2.60137, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1888 - loss: 2.8407 - val_accuracy: 0.3655 - val_loss: 2.6014\n",
      "Epoch 8/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2139 - loss: 2.7555\n",
      "Epoch 8: val_loss improved from 2.60137 to 2.54532, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2139 - loss: 2.7553 - val_accuracy: 0.3953 - val_loss: 2.5453\n",
      "Epoch 9/1500\n",
      "\u001b[1m730/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2394 - loss: 2.6933\n",
      "Epoch 9: val_loss improved from 2.54532 to 2.49849, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2397 - loss: 2.6923 - val_accuracy: 0.4155 - val_loss: 2.4985\n",
      "Epoch 10/1500\n",
      "\u001b[1m736/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2601 - loss: 2.6389\n",
      "Epoch 10: val_loss improved from 2.49849 to 2.43119, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2605 - loss: 2.6383 - val_accuracy: 0.4403 - val_loss: 2.4312\n",
      "Epoch 11/1500\n",
      "\u001b[1m738/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2812 - loss: 2.5798\n",
      "Epoch 11: val_loss improved from 2.43119 to 2.38725, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2814 - loss: 2.5791 - val_accuracy: 0.4555 - val_loss: 2.3873\n",
      "Epoch 12/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3089 - loss: 2.5179\n",
      "Epoch 12: val_loss improved from 2.38725 to 2.34346, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3089 - loss: 2.5179 - val_accuracy: 0.4708 - val_loss: 2.3435\n",
      "Epoch 13/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3278 - loss: 2.4701\n",
      "Epoch 13: val_loss improved from 2.34346 to 2.29023, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3280 - loss: 2.4698 - val_accuracy: 0.4811 - val_loss: 2.2902\n",
      "Epoch 14/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3456 - loss: 2.4183\n",
      "Epoch 14: val_loss improved from 2.29023 to 2.24530, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3459 - loss: 2.4177 - val_accuracy: 0.4900 - val_loss: 2.2453\n",
      "Epoch 15/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3726 - loss: 2.3633\n",
      "Epoch 15: val_loss improved from 2.24530 to 2.19925, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3726 - loss: 2.3633 - val_accuracy: 0.4938 - val_loss: 2.1992\n",
      "Epoch 16/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3822 - loss: 2.3257\n",
      "Epoch 16: val_loss improved from 2.19925 to 2.16479, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3822 - loss: 2.3256 - val_accuracy: 0.5007 - val_loss: 2.1648\n",
      "Epoch 17/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3956 - loss: 2.2884\n",
      "Epoch 17: val_loss improved from 2.16479 to 2.12161, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3957 - loss: 2.2879 - val_accuracy: 0.5066 - val_loss: 2.1216\n",
      "Epoch 18/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4086 - loss: 2.2484\n",
      "Epoch 18: val_loss improved from 2.12161 to 2.08004, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4087 - loss: 2.2484 - val_accuracy: 0.5155 - val_loss: 2.0800\n",
      "Epoch 19/1500\n",
      "\u001b[1m740/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4134 - loss: 2.2070\n",
      "Epoch 19: val_loss improved from 2.08004 to 2.04139, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4136 - loss: 2.2068 - val_accuracy: 0.5187 - val_loss: 2.0414\n",
      "Epoch 20/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4337 - loss: 2.1569\n",
      "Epoch 20: val_loss improved from 2.04139 to 2.00162, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4337 - loss: 2.1570 - val_accuracy: 0.5200 - val_loss: 2.0016\n",
      "Epoch 21/1500\n",
      "\u001b[1m742/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4357 - loss: 2.1371\n",
      "Epoch 21: val_loss improved from 2.00162 to 1.95794, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4358 - loss: 2.1367 - val_accuracy: 0.5271 - val_loss: 1.9579\n",
      "Epoch 22/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4526 - loss: 2.0985\n",
      "Epoch 22: val_loss improved from 1.95794 to 1.93187, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4526 - loss: 2.0984 - val_accuracy: 0.5299 - val_loss: 1.9319\n",
      "Epoch 23/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4506 - loss: 2.0712\n",
      "Epoch 23: val_loss improved from 1.93187 to 1.89310, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4506 - loss: 2.0711 - val_accuracy: 0.5377 - val_loss: 1.8931\n",
      "Epoch 24/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4526 - loss: 2.0459\n",
      "Epoch 24: val_loss improved from 1.89310 to 1.86408, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4527 - loss: 2.0458 - val_accuracy: 0.5417 - val_loss: 1.8641\n",
      "Epoch 25/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4607 - loss: 2.0197\n",
      "Epoch 25: val_loss improved from 1.86408 to 1.83268, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4609 - loss: 2.0194 - val_accuracy: 0.5459 - val_loss: 1.8327\n",
      "Epoch 26/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4719 - loss: 1.9869\n",
      "Epoch 26: val_loss improved from 1.83268 to 1.79771, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4719 - loss: 1.9869 - val_accuracy: 0.5480 - val_loss: 1.7977\n",
      "Epoch 27/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4805 - loss: 1.9493\n",
      "Epoch 27: val_loss improved from 1.79771 to 1.76782, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4805 - loss: 1.9493 - val_accuracy: 0.5490 - val_loss: 1.7678\n",
      "Epoch 28/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4841 - loss: 1.9260\n",
      "Epoch 28: val_loss improved from 1.76782 to 1.73960, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4841 - loss: 1.9260 - val_accuracy: 0.5498 - val_loss: 1.7396\n",
      "Epoch 29/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4909 - loss: 1.8942\n",
      "Epoch 29: val_loss improved from 1.73960 to 1.71117, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4908 - loss: 1.8942 - val_accuracy: 0.5571 - val_loss: 1.7112\n",
      "Epoch 30/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4912 - loss: 1.8832\n",
      "Epoch 30: val_loss improved from 1.71117 to 1.68563, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4913 - loss: 1.8830 - val_accuracy: 0.5594 - val_loss: 1.6856\n",
      "Epoch 31/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4910 - loss: 1.8608\n",
      "Epoch 31: val_loss improved from 1.68563 to 1.66115, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4912 - loss: 1.8606 - val_accuracy: 0.5584 - val_loss: 1.6612\n",
      "Epoch 32/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4990 - loss: 1.8336\n",
      "Epoch 32: val_loss improved from 1.66115 to 1.63381, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4990 - loss: 1.8335 - val_accuracy: 0.5611 - val_loss: 1.6338\n",
      "Epoch 33/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4991 - loss: 1.8223\n",
      "Epoch 33: val_loss improved from 1.63381 to 1.60989, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4992 - loss: 1.8219 - val_accuracy: 0.5606 - val_loss: 1.6099\n",
      "Epoch 34/1500\n",
      "\u001b[1m736/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5032 - loss: 1.7857\n",
      "Epoch 34: val_loss improved from 1.60989 to 1.58581, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5033 - loss: 1.7857 - val_accuracy: 0.5665 - val_loss: 1.5858\n",
      "Epoch 35/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5062 - loss: 1.7708\n",
      "Epoch 35: val_loss improved from 1.58581 to 1.56094, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5062 - loss: 1.7708 - val_accuracy: 0.5718 - val_loss: 1.5609\n",
      "Epoch 36/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5062 - loss: 1.7693\n",
      "Epoch 36: val_loss improved from 1.56094 to 1.54386, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5062 - loss: 1.7690 - val_accuracy: 0.5777 - val_loss: 1.5439\n",
      "Epoch 37/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5150 - loss: 1.7176\n",
      "Epoch 37: val_loss improved from 1.54386 to 1.51976, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5150 - loss: 1.7177 - val_accuracy: 0.5832 - val_loss: 1.5198\n",
      "Epoch 38/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5105 - loss: 1.7264\n",
      "Epoch 38: val_loss improved from 1.51976 to 1.49938, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5107 - loss: 1.7261 - val_accuracy: 0.5875 - val_loss: 1.4994\n",
      "Epoch 39/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5157 - loss: 1.6933\n",
      "Epoch 39: val_loss improved from 1.49938 to 1.47701, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5158 - loss: 1.6931 - val_accuracy: 0.5864 - val_loss: 1.4770\n",
      "Epoch 40/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 1.6747\n",
      "Epoch 40: val_loss improved from 1.47701 to 1.46121, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5231 - loss: 1.6745 - val_accuracy: 0.5904 - val_loss: 1.4612\n",
      "Epoch 41/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5275 - loss: 1.6628\n",
      "Epoch 41: val_loss improved from 1.46121 to 1.44121, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5275 - loss: 1.6626 - val_accuracy: 0.5984 - val_loss: 1.4412\n",
      "Epoch 42/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5307 - loss: 1.6386\n",
      "Epoch 42: val_loss improved from 1.44121 to 1.42543, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5306 - loss: 1.6387 - val_accuracy: 0.5994 - val_loss: 1.4254\n",
      "Epoch 43/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5208 - loss: 1.6447\n",
      "Epoch 43: val_loss improved from 1.42543 to 1.40348, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5208 - loss: 1.6447 - val_accuracy: 0.6029 - val_loss: 1.4035\n",
      "Epoch 44/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5329 - loss: 1.6072\n",
      "Epoch 44: val_loss improved from 1.40348 to 1.38896, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5328 - loss: 1.6072 - val_accuracy: 0.6074 - val_loss: 1.3890\n",
      "Epoch 45/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5381 - loss: 1.5916\n",
      "Epoch 45: val_loss improved from 1.38896 to 1.36692, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5381 - loss: 1.5916 - val_accuracy: 0.6117 - val_loss: 1.3669\n",
      "Epoch 46/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5365 - loss: 1.5883\n",
      "Epoch 46: val_loss improved from 1.36692 to 1.35155, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5366 - loss: 1.5881 - val_accuracy: 0.6177 - val_loss: 1.3516\n",
      "Epoch 47/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5403 - loss: 1.5570\n",
      "Epoch 47: val_loss improved from 1.35155 to 1.33455, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5402 - loss: 1.5571 - val_accuracy: 0.6193 - val_loss: 1.3346\n",
      "Epoch 48/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5413 - loss: 1.5542\n",
      "Epoch 48: val_loss improved from 1.33455 to 1.32067, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5413 - loss: 1.5542 - val_accuracy: 0.6228 - val_loss: 1.3207\n",
      "Epoch 49/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5481 - loss: 1.5396\n",
      "Epoch 49: val_loss improved from 1.32067 to 1.31030, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5481 - loss: 1.5395 - val_accuracy: 0.6248 - val_loss: 1.3103\n",
      "Epoch 50/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5452 - loss: 1.5218\n",
      "Epoch 50: val_loss improved from 1.31030 to 1.29842, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5451 - loss: 1.5219 - val_accuracy: 0.6277 - val_loss: 1.2984\n",
      "Epoch 51/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5458 - loss: 1.5152\n",
      "Epoch 51: val_loss improved from 1.29842 to 1.28096, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5458 - loss: 1.5152 - val_accuracy: 0.6334 - val_loss: 1.2810\n",
      "Epoch 52/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5426 - loss: 1.5126\n",
      "Epoch 52: val_loss improved from 1.28096 to 1.26913, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5427 - loss: 1.5124 - val_accuracy: 0.6363 - val_loss: 1.2691\n",
      "Epoch 53/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5444 - loss: 1.5012\n",
      "Epoch 53: val_loss improved from 1.26913 to 1.25243, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5444 - loss: 1.5011 - val_accuracy: 0.6405 - val_loss: 1.2524\n",
      "Epoch 54/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5538 - loss: 1.4874\n",
      "Epoch 54: val_loss improved from 1.25243 to 1.24508, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5538 - loss: 1.4873 - val_accuracy: 0.6410 - val_loss: 1.2451\n",
      "Epoch 55/1500\n",
      "\u001b[1m743/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5486 - loss: 1.4786\n",
      "Epoch 55: val_loss improved from 1.24508 to 1.22936, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5488 - loss: 1.4783 - val_accuracy: 0.6478 - val_loss: 1.2294\n",
      "Epoch 56/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5533 - loss: 1.4709\n",
      "Epoch 56: val_loss improved from 1.22936 to 1.22049, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5533 - loss: 1.4708 - val_accuracy: 0.6465 - val_loss: 1.2205\n",
      "Epoch 57/1500\n",
      "\u001b[1m739/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5588 - loss: 1.4412\n",
      "Epoch 57: val_loss improved from 1.22049 to 1.21084, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5587 - loss: 1.4414 - val_accuracy: 0.6520 - val_loss: 1.2108\n",
      "Epoch 58/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5597 - loss: 1.4467\n",
      "Epoch 58: val_loss improved from 1.21084 to 1.19977, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5597 - loss: 1.4466 - val_accuracy: 0.6586 - val_loss: 1.1998\n",
      "Epoch 59/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5550 - loss: 1.4455\n",
      "Epoch 59: val_loss improved from 1.19977 to 1.19346, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5551 - loss: 1.4453 - val_accuracy: 0.6606 - val_loss: 1.1935\n",
      "Epoch 60/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5626 - loss: 1.4280\n",
      "Epoch 60: val_loss improved from 1.19346 to 1.18494, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5626 - loss: 1.4280 - val_accuracy: 0.6615 - val_loss: 1.1849\n",
      "Epoch 61/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5695 - loss: 1.4122\n",
      "Epoch 61: val_loss improved from 1.18494 to 1.16971, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5694 - loss: 1.4122 - val_accuracy: 0.6640 - val_loss: 1.1697\n",
      "Epoch 62/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5633 - loss: 1.4107\n",
      "Epoch 62: val_loss improved from 1.16971 to 1.15832, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5633 - loss: 1.4106 - val_accuracy: 0.6682 - val_loss: 1.1583\n",
      "Epoch 63/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5688 - loss: 1.4012\n",
      "Epoch 63: val_loss improved from 1.15832 to 1.14985, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5687 - loss: 1.4013 - val_accuracy: 0.6704 - val_loss: 1.1499\n",
      "Epoch 64/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5727 - loss: 1.3852\n",
      "Epoch 64: val_loss improved from 1.14985 to 1.14638, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5727 - loss: 1.3853 - val_accuracy: 0.6719 - val_loss: 1.1464\n",
      "Epoch 65/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5691 - loss: 1.3847\n",
      "Epoch 65: val_loss improved from 1.14638 to 1.13806, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5692 - loss: 1.3846 - val_accuracy: 0.6747 - val_loss: 1.1381\n",
      "Epoch 66/1500\n",
      "\u001b[1m743/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5756 - loss: 1.3693\n",
      "Epoch 66: val_loss improved from 1.13806 to 1.13002, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5755 - loss: 1.3693 - val_accuracy: 0.6761 - val_loss: 1.1300\n",
      "Epoch 67/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5697 - loss: 1.3738\n",
      "Epoch 67: val_loss improved from 1.13002 to 1.12021, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5698 - loss: 1.3738 - val_accuracy: 0.6802 - val_loss: 1.1202\n",
      "Epoch 68/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5716 - loss: 1.3596\n",
      "Epoch 68: val_loss improved from 1.12021 to 1.11582, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5716 - loss: 1.3597 - val_accuracy: 0.6802 - val_loss: 1.1158\n",
      "Epoch 69/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5747 - loss: 1.3574\n",
      "Epoch 69: val_loss improved from 1.11582 to 1.10931, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5747 - loss: 1.3574 - val_accuracy: 0.6803 - val_loss: 1.1093\n",
      "Epoch 70/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5790 - loss: 1.3554\n",
      "Epoch 70: val_loss improved from 1.10931 to 1.09982, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5790 - loss: 1.3554 - val_accuracy: 0.6840 - val_loss: 1.0998\n",
      "Epoch 71/1500\n",
      "\u001b[1m743/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5758 - loss: 1.3579\n",
      "Epoch 71: val_loss improved from 1.09982 to 1.09968, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5759 - loss: 1.3574 - val_accuracy: 0.6823 - val_loss: 1.0997\n",
      "Epoch 72/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5854 - loss: 1.3261\n",
      "Epoch 72: val_loss improved from 1.09968 to 1.08658, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5852 - loss: 1.3263 - val_accuracy: 0.6876 - val_loss: 1.0866\n",
      "Epoch 73/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5807 - loss: 1.3294\n",
      "Epoch 73: val_loss improved from 1.08658 to 1.08171, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5807 - loss: 1.3294 - val_accuracy: 0.6905 - val_loss: 1.0817\n",
      "Epoch 74/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5783 - loss: 1.3362\n",
      "Epoch 74: val_loss improved from 1.08171 to 1.07286, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5784 - loss: 1.3361 - val_accuracy: 0.6931 - val_loss: 1.0729\n",
      "Epoch 75/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5768 - loss: 1.3234\n",
      "Epoch 75: val_loss improved from 1.07286 to 1.06789, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5768 - loss: 1.3235 - val_accuracy: 0.6949 - val_loss: 1.0679\n",
      "Epoch 76/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5833 - loss: 1.3208\n",
      "Epoch 76: val_loss improved from 1.06789 to 1.06693, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5833 - loss: 1.3209 - val_accuracy: 0.6944 - val_loss: 1.0669\n",
      "Epoch 77/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 1.3228\n",
      "Epoch 77: val_loss improved from 1.06693 to 1.05955, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 1.3228 - val_accuracy: 0.6952 - val_loss: 1.0596\n",
      "Epoch 78/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5806 - loss: 1.3087\n",
      "Epoch 78: val_loss improved from 1.05955 to 1.05188, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5806 - loss: 1.3087 - val_accuracy: 0.7012 - val_loss: 1.0519\n",
      "Epoch 79/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5831 - loss: 1.3031\n",
      "Epoch 79: val_loss improved from 1.05188 to 1.04479, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5831 - loss: 1.3033 - val_accuracy: 0.7027 - val_loss: 1.0448\n",
      "Epoch 80/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5886 - loss: 1.2929\n",
      "Epoch 80: val_loss improved from 1.04479 to 1.04196, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5885 - loss: 1.2930 - val_accuracy: 0.7032 - val_loss: 1.0420\n",
      "Epoch 81/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5829 - loss: 1.3090\n",
      "Epoch 81: val_loss improved from 1.04196 to 1.03982, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5829 - loss: 1.3089 - val_accuracy: 0.7017 - val_loss: 1.0398\n",
      "Epoch 82/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5807 - loss: 1.3061\n",
      "Epoch 82: val_loss improved from 1.03982 to 1.03379, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5807 - loss: 1.3061 - val_accuracy: 0.7057 - val_loss: 1.0338\n",
      "Epoch 83/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5859 - loss: 1.2913\n",
      "Epoch 83: val_loss improved from 1.03379 to 1.03050, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5859 - loss: 1.2912 - val_accuracy: 0.7051 - val_loss: 1.0305\n",
      "Epoch 84/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5840 - loss: 1.2973\n",
      "Epoch 84: val_loss improved from 1.03050 to 1.02412, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5840 - loss: 1.2973 - val_accuracy: 0.7059 - val_loss: 1.0241\n",
      "Epoch 85/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5883 - loss: 1.2808\n",
      "Epoch 85: val_loss improved from 1.02412 to 1.02106, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5883 - loss: 1.2809 - val_accuracy: 0.7083 - val_loss: 1.0211\n",
      "Epoch 86/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5833 - loss: 1.2743\n",
      "Epoch 86: val_loss improved from 1.02106 to 1.01627, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5834 - loss: 1.2744 - val_accuracy: 0.7109 - val_loss: 1.0163\n",
      "Epoch 87/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5893 - loss: 1.2832\n",
      "Epoch 87: val_loss improved from 1.01627 to 1.01374, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5894 - loss: 1.2829 - val_accuracy: 0.7119 - val_loss: 1.0137\n",
      "Epoch 88/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5873 - loss: 1.2760\n",
      "Epoch 88: val_loss improved from 1.01374 to 1.00678, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5874 - loss: 1.2759 - val_accuracy: 0.7137 - val_loss: 1.0068\n",
      "Epoch 89/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5888 - loss: 1.2819\n",
      "Epoch 89: val_loss improved from 1.00678 to 1.00297, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5889 - loss: 1.2815 - val_accuracy: 0.7140 - val_loss: 1.0030\n",
      "Epoch 90/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5972 - loss: 1.2544\n",
      "Epoch 90: val_loss improved from 1.00297 to 0.99782, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5972 - loss: 1.2544 - val_accuracy: 0.7189 - val_loss: 0.9978\n",
      "Epoch 91/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5903 - loss: 1.2694\n",
      "Epoch 91: val_loss improved from 0.99782 to 0.99369, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5903 - loss: 1.2694 - val_accuracy: 0.7195 - val_loss: 0.9937\n",
      "Epoch 92/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5831 - loss: 1.2755\n",
      "Epoch 92: val_loss improved from 0.99369 to 0.99306, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5833 - loss: 1.2753 - val_accuracy: 0.7195 - val_loss: 0.9931\n",
      "Epoch 93/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5946 - loss: 1.2595\n",
      "Epoch 93: val_loss improved from 0.99306 to 0.99057, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5946 - loss: 1.2594 - val_accuracy: 0.7194 - val_loss: 0.9906\n",
      "Epoch 94/1500\n",
      "\u001b[1m740/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6006 - loss: 1.2452\n",
      "Epoch 94: val_loss improved from 0.99057 to 0.98601, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6004 - loss: 1.2454 - val_accuracy: 0.7206 - val_loss: 0.9860\n",
      "Epoch 95/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6026 - loss: 1.2264\n",
      "Epoch 95: val_loss improved from 0.98601 to 0.98404, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6024 - loss: 1.2268 - val_accuracy: 0.7208 - val_loss: 0.9840\n",
      "Epoch 96/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5979 - loss: 1.2445\n",
      "Epoch 96: val_loss improved from 0.98404 to 0.97809, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5979 - loss: 1.2445 - val_accuracy: 0.7206 - val_loss: 0.9781\n",
      "Epoch 97/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6045 - loss: 1.2225\n",
      "Epoch 97: val_loss improved from 0.97809 to 0.97677, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6045 - loss: 1.2225 - val_accuracy: 0.7228 - val_loss: 0.9768\n",
      "Epoch 98/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6040 - loss: 1.2295\n",
      "Epoch 98: val_loss improved from 0.97677 to 0.97177, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6038 - loss: 1.2296 - val_accuracy: 0.7240 - val_loss: 0.9718\n",
      "Epoch 99/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6004 - loss: 1.2271\n",
      "Epoch 99: val_loss improved from 0.97177 to 0.96600, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6003 - loss: 1.2272 - val_accuracy: 0.7249 - val_loss: 0.9660\n",
      "Epoch 100/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6011 - loss: 1.2294\n",
      "Epoch 100: val_loss improved from 0.96600 to 0.96461, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6011 - loss: 1.2294 - val_accuracy: 0.7260 - val_loss: 0.9646\n",
      "Epoch 101/1500\n",
      "\u001b[1m737/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6014 - loss: 1.2291\n",
      "Epoch 101: val_loss improved from 0.96461 to 0.96265, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6015 - loss: 1.2289 - val_accuracy: 0.7287 - val_loss: 0.9626\n",
      "Epoch 102/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5999 - loss: 1.2264\n",
      "Epoch 102: val_loss improved from 0.96265 to 0.96007, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5999 - loss: 1.2264 - val_accuracy: 0.7299 - val_loss: 0.9601\n",
      "Epoch 103/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6017 - loss: 1.2248\n",
      "Epoch 103: val_loss improved from 0.96007 to 0.95526, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6016 - loss: 1.2248 - val_accuracy: 0.7299 - val_loss: 0.9553\n",
      "Epoch 104/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 1.2191\n",
      "Epoch 104: val_loss did not improve from 0.95526\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 1.2190 - val_accuracy: 0.7328 - val_loss: 0.9556\n",
      "Epoch 105/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5939 - loss: 1.2257\n",
      "Epoch 105: val_loss improved from 0.95526 to 0.94849, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5940 - loss: 1.2257 - val_accuracy: 0.7323 - val_loss: 0.9485\n",
      "Epoch 106/1500\n",
      "\u001b[1m740/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 1.2186\n",
      "Epoch 106: val_loss did not improve from 0.94849\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 1.2184 - val_accuracy: 0.7323 - val_loss: 0.9491\n",
      "Epoch 107/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6063 - loss: 1.2123\n",
      "Epoch 107: val_loss improved from 0.94849 to 0.94440, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6062 - loss: 1.2124 - val_accuracy: 0.7309 - val_loss: 0.9444\n",
      "Epoch 108/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5990 - loss: 1.2268\n",
      "Epoch 108: val_loss improved from 0.94440 to 0.94209, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5992 - loss: 1.2263 - val_accuracy: 0.7355 - val_loss: 0.9421\n",
      "Epoch 109/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6058 - loss: 1.2077\n",
      "Epoch 109: val_loss improved from 0.94209 to 0.93998, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6058 - loss: 1.2077 - val_accuracy: 0.7357 - val_loss: 0.9400\n",
      "Epoch 110/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 1.2208\n",
      "Epoch 110: val_loss improved from 0.93998 to 0.93357, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 1.2206 - val_accuracy: 0.7388 - val_loss: 0.9336\n",
      "Epoch 111/1500\n",
      "\u001b[1m740/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6057 - loss: 1.2059\n",
      "Epoch 111: val_loss did not improve from 0.93357\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6058 - loss: 1.2057 - val_accuracy: 0.7375 - val_loss: 0.9370\n",
      "Epoch 112/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6042 - loss: 1.1942\n",
      "Epoch 112: val_loss improved from 0.93357 to 0.93122, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6042 - loss: 1.1942 - val_accuracy: 0.7388 - val_loss: 0.9312\n",
      "Epoch 113/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6082 - loss: 1.2055\n",
      "Epoch 113: val_loss improved from 0.93122 to 0.92918, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6082 - loss: 1.2054 - val_accuracy: 0.7370 - val_loss: 0.9292\n",
      "Epoch 114/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6081 - loss: 1.1981\n",
      "Epoch 114: val_loss improved from 0.92918 to 0.92544, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6081 - loss: 1.1981 - val_accuracy: 0.7396 - val_loss: 0.9254\n",
      "Epoch 115/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6103 - loss: 1.1842\n",
      "Epoch 115: val_loss improved from 0.92544 to 0.92264, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6104 - loss: 1.1842 - val_accuracy: 0.7436 - val_loss: 0.9226\n",
      "Epoch 116/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6132 - loss: 1.1806\n",
      "Epoch 116: val_loss improved from 0.92264 to 0.91784, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6132 - loss: 1.1806 - val_accuracy: 0.7425 - val_loss: 0.9178\n",
      "Epoch 117/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6136 - loss: 1.1880\n",
      "Epoch 117: val_loss did not improve from 0.91784\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6135 - loss: 1.1880 - val_accuracy: 0.7427 - val_loss: 0.9203\n",
      "Epoch 118/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6123 - loss: 1.1822\n",
      "Epoch 118: val_loss improved from 0.91784 to 0.91458, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6122 - loss: 1.1821 - val_accuracy: 0.7440 - val_loss: 0.9146\n",
      "Epoch 119/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6109 - loss: 1.1772\n",
      "Epoch 119: val_loss did not improve from 0.91458\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6110 - loss: 1.1773 - val_accuracy: 0.7412 - val_loss: 0.9148\n",
      "Epoch 120/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6091 - loss: 1.1704\n",
      "Epoch 120: val_loss improved from 0.91458 to 0.91238, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6091 - loss: 1.1704 - val_accuracy: 0.7422 - val_loss: 0.9124\n",
      "Epoch 121/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6074 - loss: 1.1883\n",
      "Epoch 121: val_loss improved from 0.91238 to 0.90943, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6074 - loss: 1.1883 - val_accuracy: 0.7440 - val_loss: 0.9094\n",
      "Epoch 122/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6050 - loss: 1.1849\n",
      "Epoch 122: val_loss improved from 0.90943 to 0.90625, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6050 - loss: 1.1849 - val_accuracy: 0.7462 - val_loss: 0.9062\n",
      "Epoch 123/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6061 - loss: 1.1729\n",
      "Epoch 123: val_loss improved from 0.90625 to 0.90591, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6061 - loss: 1.1730 - val_accuracy: 0.7462 - val_loss: 0.9059\n",
      "Epoch 124/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6184 - loss: 1.1669\n",
      "Epoch 124: val_loss improved from 0.90591 to 0.90096, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6184 - loss: 1.1670 - val_accuracy: 0.7501 - val_loss: 0.9010\n",
      "Epoch 125/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6171 - loss: 1.1584\n",
      "Epoch 125: val_loss did not improve from 0.90096\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6171 - loss: 1.1584 - val_accuracy: 0.7436 - val_loss: 0.9066\n",
      "Epoch 126/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6237 - loss: 1.1546\n",
      "Epoch 126: val_loss improved from 0.90096 to 0.89843, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6236 - loss: 1.1548 - val_accuracy: 0.7496 - val_loss: 0.8984\n",
      "Epoch 127/1500\n",
      "\u001b[1m743/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6092 - loss: 1.1742\n",
      "Epoch 127: val_loss improved from 0.89843 to 0.89678, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6093 - loss: 1.1741 - val_accuracy: 0.7501 - val_loss: 0.8968\n",
      "Epoch 128/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6200 - loss: 1.1616\n",
      "Epoch 128: val_loss improved from 0.89678 to 0.89616, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6199 - loss: 1.1616 - val_accuracy: 0.7483 - val_loss: 0.8962\n",
      "Epoch 129/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6179 - loss: 1.1596\n",
      "Epoch 129: val_loss improved from 0.89616 to 0.89390, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6179 - loss: 1.1596 - val_accuracy: 0.7508 - val_loss: 0.8939\n",
      "Epoch 130/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6150 - loss: 1.1559\n",
      "Epoch 130: val_loss improved from 0.89390 to 0.89267, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6150 - loss: 1.1561 - val_accuracy: 0.7508 - val_loss: 0.8927\n",
      "Epoch 131/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6098 - loss: 1.1735\n",
      "Epoch 131: val_loss improved from 0.89267 to 0.88726, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6099 - loss: 1.1733 - val_accuracy: 0.7521 - val_loss: 0.8873\n",
      "Epoch 132/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6146 - loss: 1.1653\n",
      "Epoch 132: val_loss did not improve from 0.88726\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6146 - loss: 1.1650 - val_accuracy: 0.7485 - val_loss: 0.8874\n",
      "Epoch 133/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6210 - loss: 1.1540\n",
      "Epoch 133: val_loss did not improve from 0.88726\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6209 - loss: 1.1540 - val_accuracy: 0.7491 - val_loss: 0.8877\n",
      "Epoch 134/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6116 - loss: 1.1488\n",
      "Epoch 134: val_loss improved from 0.88726 to 0.88370, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6117 - loss: 1.1491 - val_accuracy: 0.7524 - val_loss: 0.8837\n",
      "Epoch 135/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6148 - loss: 1.1555\n",
      "Epoch 135: val_loss improved from 0.88370 to 0.88104, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6148 - loss: 1.1555 - val_accuracy: 0.7545 - val_loss: 0.8810\n",
      "Epoch 136/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6195 - loss: 1.1399\n",
      "Epoch 136: val_loss improved from 0.88104 to 0.87964, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6195 - loss: 1.1400 - val_accuracy: 0.7509 - val_loss: 0.8796\n",
      "Epoch 137/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6215 - loss: 1.1351\n",
      "Epoch 137: val_loss improved from 0.87964 to 0.87557, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6215 - loss: 1.1352 - val_accuracy: 0.7564 - val_loss: 0.8756\n",
      "Epoch 138/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6202 - loss: 1.1508\n",
      "Epoch 138: val_loss did not improve from 0.87557\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6201 - loss: 1.1509 - val_accuracy: 0.7535 - val_loss: 0.8772\n",
      "Epoch 139/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6232 - loss: 1.1420\n",
      "Epoch 139: val_loss improved from 0.87557 to 0.87333, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6232 - loss: 1.1419 - val_accuracy: 0.7555 - val_loss: 0.8733\n",
      "Epoch 140/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6210 - loss: 1.1364\n",
      "Epoch 140: val_loss did not improve from 0.87333\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6209 - loss: 1.1365 - val_accuracy: 0.7566 - val_loss: 0.8741\n",
      "Epoch 141/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 1.1281\n",
      "Epoch 141: val_loss improved from 0.87333 to 0.87053, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6251 - loss: 1.1280 - val_accuracy: 0.7542 - val_loss: 0.8705\n",
      "Epoch 142/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6241 - loss: 1.1323\n",
      "Epoch 142: val_loss improved from 0.87053 to 0.86783, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6241 - loss: 1.1323 - val_accuracy: 0.7595 - val_loss: 0.8678\n",
      "Epoch 143/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6212 - loss: 1.1349\n",
      "Epoch 143: val_loss did not improve from 0.86783\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6212 - loss: 1.1350 - val_accuracy: 0.7564 - val_loss: 0.8685\n",
      "Epoch 144/1500\n",
      "\u001b[1m743/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6163 - loss: 1.1518\n",
      "Epoch 144: val_loss improved from 0.86783 to 0.86610, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6165 - loss: 1.1513 - val_accuracy: 0.7574 - val_loss: 0.8661\n",
      "Epoch 145/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6282 - loss: 1.1275\n",
      "Epoch 145: val_loss improved from 0.86610 to 0.86343, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6282 - loss: 1.1275 - val_accuracy: 0.7585 - val_loss: 0.8634\n",
      "Epoch 146/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6219 - loss: 1.1221\n",
      "Epoch 146: val_loss improved from 0.86343 to 0.86106, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6219 - loss: 1.1221 - val_accuracy: 0.7598 - val_loss: 0.8611\n",
      "Epoch 147/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6262 - loss: 1.1269\n",
      "Epoch 147: val_loss did not improve from 0.86106\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6263 - loss: 1.1268 - val_accuracy: 0.7572 - val_loss: 0.8623\n",
      "Epoch 148/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6330 - loss: 1.1102\n",
      "Epoch 148: val_loss improved from 0.86106 to 0.85958, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6330 - loss: 1.1103 - val_accuracy: 0.7566 - val_loss: 0.8596\n",
      "Epoch 149/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6292 - loss: 1.1250\n",
      "Epoch 149: val_loss improved from 0.85958 to 0.85811, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6292 - loss: 1.1251 - val_accuracy: 0.7595 - val_loss: 0.8581\n",
      "Epoch 150/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6258 - loss: 1.1206\n",
      "Epoch 150: val_loss did not improve from 0.85811\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6258 - loss: 1.1205 - val_accuracy: 0.7582 - val_loss: 0.8584\n",
      "Epoch 151/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6302 - loss: 1.1247\n",
      "Epoch 151: val_loss improved from 0.85811 to 0.85346, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6302 - loss: 1.1247 - val_accuracy: 0.7597 - val_loss: 0.8535\n",
      "Epoch 152/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6242 - loss: 1.1261\n",
      "Epoch 152: val_loss improved from 0.85346 to 0.85265, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6242 - loss: 1.1261 - val_accuracy: 0.7590 - val_loss: 0.8527\n",
      "Epoch 153/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6278 - loss: 1.1152\n",
      "Epoch 153: val_loss improved from 0.85265 to 0.85055, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6278 - loss: 1.1152 - val_accuracy: 0.7585 - val_loss: 0.8505\n",
      "Epoch 154/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6243 - loss: 1.1208\n",
      "Epoch 154: val_loss improved from 0.85055 to 0.85002, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6244 - loss: 1.1208 - val_accuracy: 0.7597 - val_loss: 0.8500\n",
      "Epoch 155/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6317 - loss: 1.1185\n",
      "Epoch 155: val_loss improved from 0.85002 to 0.84688, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6316 - loss: 1.1185 - val_accuracy: 0.7639 - val_loss: 0.8469\n",
      "Epoch 156/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6260 - loss: 1.1166\n",
      "Epoch 156: val_loss improved from 0.84688 to 0.84556, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6261 - loss: 1.1165 - val_accuracy: 0.7647 - val_loss: 0.8456\n",
      "Epoch 157/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6201 - loss: 1.1259\n",
      "Epoch 157: val_loss improved from 0.84556 to 0.84168, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6201 - loss: 1.1258 - val_accuracy: 0.7671 - val_loss: 0.8417\n",
      "Epoch 158/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6241 - loss: 1.1140\n",
      "Epoch 158: val_loss improved from 0.84168 to 0.84127, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6241 - loss: 1.1140 - val_accuracy: 0.7637 - val_loss: 0.8413\n",
      "Epoch 159/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6273 - loss: 1.1132\n",
      "Epoch 159: val_loss did not improve from 0.84127\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6273 - loss: 1.1132 - val_accuracy: 0.7663 - val_loss: 0.8420\n",
      "Epoch 160/1500\n",
      "\u001b[1m742/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6316 - loss: 1.0981\n",
      "Epoch 160: val_loss improved from 0.84127 to 0.83716, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6315 - loss: 1.0985 - val_accuracy: 0.7642 - val_loss: 0.8372\n",
      "Epoch 161/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6301 - loss: 1.1086\n",
      "Epoch 161: val_loss did not improve from 0.83716\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6301 - loss: 1.1085 - val_accuracy: 0.7660 - val_loss: 0.8391\n",
      "Epoch 162/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6328 - loss: 1.1038\n",
      "Epoch 162: val_loss did not improve from 0.83716\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6327 - loss: 1.1038 - val_accuracy: 0.7657 - val_loss: 0.8381\n",
      "Epoch 163/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6236 - loss: 1.1094\n",
      "Epoch 163: val_loss improved from 0.83716 to 0.83531, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6237 - loss: 1.1091 - val_accuracy: 0.7687 - val_loss: 0.8353\n",
      "Epoch 164/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6325 - loss: 1.1024\n",
      "Epoch 164: val_loss improved from 0.83531 to 0.83242, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6325 - loss: 1.1022 - val_accuracy: 0.7691 - val_loss: 0.8324\n",
      "Epoch 165/1500\n",
      "\u001b[1m742/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6293 - loss: 1.0932\n",
      "Epoch 165: val_loss did not improve from 0.83242\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6293 - loss: 1.0935 - val_accuracy: 0.7657 - val_loss: 0.8336\n",
      "Epoch 166/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6282 - loss: 1.0970\n",
      "Epoch 166: val_loss improved from 0.83242 to 0.83217, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6281 - loss: 1.0971 - val_accuracy: 0.7678 - val_loss: 0.8322\n",
      "Epoch 167/1500\n",
      "\u001b[1m742/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6374 - loss: 1.0981\n",
      "Epoch 167: val_loss improved from 0.83217 to 0.83073, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6372 - loss: 1.0979 - val_accuracy: 0.7684 - val_loss: 0.8307\n",
      "Epoch 168/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6291 - loss: 1.1119\n",
      "Epoch 168: val_loss improved from 0.83073 to 0.82735, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6293 - loss: 1.1115 - val_accuracy: 0.7676 - val_loss: 0.8273\n",
      "Epoch 169/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6323 - loss: 1.0926\n",
      "Epoch 169: val_loss improved from 0.82735 to 0.82662, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6323 - loss: 1.0927 - val_accuracy: 0.7686 - val_loss: 0.8266\n",
      "Epoch 170/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6247 - loss: 1.1083\n",
      "Epoch 170: val_loss improved from 0.82662 to 0.82469, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6248 - loss: 1.1079 - val_accuracy: 0.7694 - val_loss: 0.8247\n",
      "Epoch 171/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6364 - loss: 1.0977\n",
      "Epoch 171: val_loss did not improve from 0.82469\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6364 - loss: 1.0978 - val_accuracy: 0.7692 - val_loss: 0.8256\n",
      "Epoch 172/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6317 - loss: 1.0939\n",
      "Epoch 172: val_loss improved from 0.82469 to 0.82269, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6317 - loss: 1.0939 - val_accuracy: 0.7673 - val_loss: 0.8227\n",
      "Epoch 173/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6339 - loss: 1.0802\n",
      "Epoch 173: val_loss improved from 0.82269 to 0.82116, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6339 - loss: 1.0803 - val_accuracy: 0.7705 - val_loss: 0.8212\n",
      "Epoch 174/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6400 - loss: 1.0804\n",
      "Epoch 174: val_loss did not improve from 0.82116\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6399 - loss: 1.0805 - val_accuracy: 0.7684 - val_loss: 0.8224\n",
      "Epoch 175/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6255 - loss: 1.1122\n",
      "Epoch 175: val_loss improved from 0.82116 to 0.81961, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6257 - loss: 1.1119 - val_accuracy: 0.7679 - val_loss: 0.8196\n",
      "Epoch 176/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6289 - loss: 1.0976\n",
      "Epoch 176: val_loss improved from 0.81961 to 0.81704, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6290 - loss: 1.0975 - val_accuracy: 0.7715 - val_loss: 0.8170\n",
      "Epoch 177/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6364 - loss: 1.0871\n",
      "Epoch 177: val_loss improved from 0.81704 to 0.81677, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6363 - loss: 1.0871 - val_accuracy: 0.7713 - val_loss: 0.8168\n",
      "Epoch 178/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6367 - loss: 1.0796\n",
      "Epoch 178: val_loss improved from 0.81677 to 0.81432, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6367 - loss: 1.0796 - val_accuracy: 0.7728 - val_loss: 0.8143\n",
      "Epoch 179/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6324 - loss: 1.0867\n",
      "Epoch 179: val_loss did not improve from 0.81432\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6324 - loss: 1.0867 - val_accuracy: 0.7715 - val_loss: 0.8150\n",
      "Epoch 180/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6386 - loss: 1.0813\n",
      "Epoch 180: val_loss did not improve from 0.81432\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6386 - loss: 1.0812 - val_accuracy: 0.7699 - val_loss: 0.8147\n",
      "Epoch 181/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6374 - loss: 1.0783\n",
      "Epoch 181: val_loss improved from 0.81432 to 0.80893, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6374 - loss: 1.0784 - val_accuracy: 0.7721 - val_loss: 0.8089\n",
      "Epoch 182/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6362 - loss: 1.0664\n",
      "Epoch 182: val_loss did not improve from 0.80893\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6362 - loss: 1.0665 - val_accuracy: 0.7684 - val_loss: 0.8113\n",
      "Epoch 183/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6393 - loss: 1.0766\n",
      "Epoch 183: val_loss improved from 0.80893 to 0.80722, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6393 - loss: 1.0767 - val_accuracy: 0.7713 - val_loss: 0.8072\n",
      "Epoch 184/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6348 - loss: 1.0798\n",
      "Epoch 184: val_loss did not improve from 0.80722\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6348 - loss: 1.0797 - val_accuracy: 0.7754 - val_loss: 0.8074\n",
      "Epoch 185/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6346 - loss: 1.0780\n",
      "Epoch 185: val_loss improved from 0.80722 to 0.80696, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6346 - loss: 1.0780 - val_accuracy: 0.7723 - val_loss: 0.8070\n",
      "Epoch 186/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6365 - loss: 1.0741\n",
      "Epoch 186: val_loss improved from 0.80696 to 0.80486, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6364 - loss: 1.0743 - val_accuracy: 0.7723 - val_loss: 0.8049\n",
      "Epoch 187/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6379 - loss: 1.0754\n",
      "Epoch 187: val_loss improved from 0.80486 to 0.80205, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6380 - loss: 1.0753 - val_accuracy: 0.7760 - val_loss: 0.8021\n",
      "Epoch 188/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6326 - loss: 1.0857\n",
      "Epoch 188: val_loss did not improve from 0.80205\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6326 - loss: 1.0855 - val_accuracy: 0.7736 - val_loss: 0.8068\n",
      "Epoch 189/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6343 - loss: 1.0661\n",
      "Epoch 189: val_loss improved from 0.80205 to 0.80085, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6346 - loss: 1.0660 - val_accuracy: 0.7728 - val_loss: 0.8009\n",
      "Epoch 190/1500\n",
      "\u001b[1m739/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6372 - loss: 1.0726\n",
      "Epoch 190: val_loss did not improve from 0.80085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6371 - loss: 1.0727 - val_accuracy: 0.7700 - val_loss: 0.8011\n",
      "Epoch 191/1500\n",
      "\u001b[1m741/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6357 - loss: 1.0668\n",
      "Epoch 191: val_loss did not improve from 0.80085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6357 - loss: 1.0669 - val_accuracy: 0.7730 - val_loss: 0.8011\n",
      "Epoch 192/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6479 - loss: 1.0470\n",
      "Epoch 192: val_loss improved from 0.80085 to 0.79886, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6478 - loss: 1.0473 - val_accuracy: 0.7713 - val_loss: 0.7989\n",
      "Epoch 193/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6391 - loss: 1.0666\n",
      "Epoch 193: val_loss improved from 0.79886 to 0.79752, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6391 - loss: 1.0666 - val_accuracy: 0.7736 - val_loss: 0.7975\n",
      "Epoch 194/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6357 - loss: 1.0714\n",
      "Epoch 194: val_loss improved from 0.79752 to 0.79413, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6357 - loss: 1.0713 - val_accuracy: 0.7725 - val_loss: 0.7941\n",
      "Epoch 195/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6464 - loss: 1.0606\n",
      "Epoch 195: val_loss did not improve from 0.79413\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6464 - loss: 1.0603 - val_accuracy: 0.7743 - val_loss: 0.7968\n",
      "Epoch 196/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6370 - loss: 1.0726\n",
      "Epoch 196: val_loss did not improve from 0.79413\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6370 - loss: 1.0725 - val_accuracy: 0.7733 - val_loss: 0.7974\n",
      "Epoch 197/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6402 - loss: 1.0533\n",
      "Epoch 197: val_loss improved from 0.79413 to 0.79242, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6402 - loss: 1.0534 - val_accuracy: 0.7764 - val_loss: 0.7924\n",
      "Epoch 198/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6470 - loss: 1.0512\n",
      "Epoch 198: val_loss improved from 0.79242 to 0.79155, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6469 - loss: 1.0515 - val_accuracy: 0.7739 - val_loss: 0.7916\n",
      "Epoch 199/1500\n",
      "\u001b[1m742/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6419 - loss: 1.0607\n",
      "Epoch 199: val_loss improved from 0.79155 to 0.79014, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6419 - loss: 1.0607 - val_accuracy: 0.7770 - val_loss: 0.7901\n",
      "Epoch 200/1500\n",
      "\u001b[1m742/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6400 - loss: 1.0704\n",
      "Epoch 200: val_loss did not improve from 0.79014\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6401 - loss: 1.0699 - val_accuracy: 0.7746 - val_loss: 0.7952\n",
      "Epoch 201/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6321 - loss: 1.0767\n",
      "Epoch 201: val_loss improved from 0.79014 to 0.78725, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6322 - loss: 1.0763 - val_accuracy: 0.7762 - val_loss: 0.7873\n",
      "Epoch 202/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6463 - loss: 1.0505\n",
      "Epoch 202: val_loss improved from 0.78725 to 0.78609, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6463 - loss: 1.0506 - val_accuracy: 0.7789 - val_loss: 0.7861\n",
      "Epoch 203/1500\n",
      "\u001b[1m732/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6408 - loss: 1.0743\n",
      "Epoch 203: val_loss did not improve from 0.78609\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6408 - loss: 1.0736 - val_accuracy: 0.7765 - val_loss: 0.7873\n",
      "Epoch 204/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6406 - loss: 1.0452\n",
      "Epoch 204: val_loss did not improve from 0.78609\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6406 - loss: 1.0453 - val_accuracy: 0.7773 - val_loss: 0.7869\n",
      "Epoch 205/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6365 - loss: 1.0591\n",
      "Epoch 205: val_loss did not improve from 0.78609\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6365 - loss: 1.0592 - val_accuracy: 0.7749 - val_loss: 0.7869\n",
      "Epoch 206/1500\n",
      "\u001b[1m734/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6394 - loss: 1.0625\n",
      "Epoch 206: val_loss improved from 0.78609 to 0.78483, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6396 - loss: 1.0621 - val_accuracy: 0.7778 - val_loss: 0.7848\n",
      "Epoch 207/1500\n",
      "\u001b[1m742/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6451 - loss: 1.0406\n",
      "Epoch 207: val_loss improved from 0.78483 to 0.77872, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6450 - loss: 1.0410 - val_accuracy: 0.7783 - val_loss: 0.7787\n",
      "Epoch 208/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6423 - loss: 1.0509\n",
      "Epoch 208: val_loss improved from 0.77872 to 0.77871, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6423 - loss: 1.0509 - val_accuracy: 0.7775 - val_loss: 0.7787\n",
      "Epoch 209/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6440 - loss: 1.0494\n",
      "Epoch 209: val_loss did not improve from 0.77871\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6441 - loss: 1.0494 - val_accuracy: 0.7749 - val_loss: 0.7813\n",
      "Epoch 210/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6377 - loss: 1.0607\n",
      "Epoch 210: val_loss improved from 0.77871 to 0.77864, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6377 - loss: 1.0606 - val_accuracy: 0.7777 - val_loss: 0.7786\n",
      "Epoch 211/1500\n",
      "\u001b[1m743/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6446 - loss: 1.0498\n",
      "Epoch 211: val_loss improved from 0.77864 to 0.77575, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6447 - loss: 1.0498 - val_accuracy: 0.7802 - val_loss: 0.7758\n",
      "Epoch 212/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6476 - loss: 1.0438\n",
      "Epoch 212: val_loss did not improve from 0.77575\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6475 - loss: 1.0438 - val_accuracy: 0.7783 - val_loss: 0.7759\n",
      "Epoch 213/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6437 - loss: 1.0417\n",
      "Epoch 213: val_loss did not improve from 0.77575\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6437 - loss: 1.0417 - val_accuracy: 0.7823 - val_loss: 0.7772\n",
      "Epoch 214/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6381 - loss: 1.0533\n",
      "Epoch 214: val_loss did not improve from 0.77575\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6382 - loss: 1.0532 - val_accuracy: 0.7765 - val_loss: 0.7761\n",
      "Epoch 215/1500\n",
      "\u001b[1m739/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6480 - loss: 1.0481\n",
      "Epoch 215: val_loss did not improve from 0.77575\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6480 - loss: 1.0478 - val_accuracy: 0.7796 - val_loss: 0.7762\n",
      "Epoch 216/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6438 - loss: 1.0344\n",
      "Epoch 216: val_loss improved from 0.77575 to 0.77427, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6438 - loss: 1.0345 - val_accuracy: 0.7786 - val_loss: 0.7743\n",
      "Epoch 217/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6493 - loss: 1.0364\n",
      "Epoch 217: val_loss improved from 0.77427 to 0.76760, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6493 - loss: 1.0364 - val_accuracy: 0.7780 - val_loss: 0.7676\n",
      "Epoch 218/1500\n",
      "\u001b[1m738/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6490 - loss: 1.0394\n",
      "Epoch 218: val_loss did not improve from 0.76760\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6490 - loss: 1.0396 - val_accuracy: 0.7777 - val_loss: 0.7719\n",
      "Epoch 219/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6482 - loss: 1.0396\n",
      "Epoch 219: val_loss did not improve from 0.76760\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6481 - loss: 1.0396 - val_accuracy: 0.7804 - val_loss: 0.7710\n",
      "Epoch 220/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6515 - loss: 1.0415\n",
      "Epoch 220: val_loss improved from 0.76760 to 0.76644, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6515 - loss: 1.0413 - val_accuracy: 0.7838 - val_loss: 0.7664\n",
      "Epoch 221/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6492 - loss: 1.0417\n",
      "Epoch 221: val_loss did not improve from 0.76644\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6492 - loss: 1.0414 - val_accuracy: 0.7770 - val_loss: 0.7707\n",
      "Epoch 222/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6460 - loss: 1.0381\n",
      "Epoch 222: val_loss did not improve from 0.76644\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6460 - loss: 1.0382 - val_accuracy: 0.7828 - val_loss: 0.7669\n",
      "Epoch 223/1500\n",
      "\u001b[1m743/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6452 - loss: 1.0372\n",
      "Epoch 223: val_loss did not improve from 0.76644\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6452 - loss: 1.0370 - val_accuracy: 0.7801 - val_loss: 0.7700\n",
      "Epoch 224/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6507 - loss: 1.0285\n",
      "Epoch 224: val_loss did not improve from 0.76644\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6506 - loss: 1.0285 - val_accuracy: 0.7812 - val_loss: 0.7666\n",
      "Epoch 225/1500\n",
      "\u001b[1m741/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6533 - loss: 1.0319\n",
      "Epoch 225: val_loss improved from 0.76644 to 0.76512, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6532 - loss: 1.0321 - val_accuracy: 0.7823 - val_loss: 0.7651\n",
      "Epoch 226/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6508 - loss: 1.0261\n",
      "Epoch 226: val_loss improved from 0.76512 to 0.76285, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6508 - loss: 1.0261 - val_accuracy: 0.7840 - val_loss: 0.7628\n",
      "Epoch 227/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6463 - loss: 1.0410\n",
      "Epoch 227: val_loss improved from 0.76285 to 0.75935, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6463 - loss: 1.0407 - val_accuracy: 0.7845 - val_loss: 0.7594\n",
      "Epoch 228/1500\n",
      "\u001b[1m740/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6522 - loss: 1.0181\n",
      "Epoch 228: val_loss did not improve from 0.75935\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6522 - loss: 1.0183 - val_accuracy: 0.7841 - val_loss: 0.7606\n",
      "Epoch 229/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6534 - loss: 1.0199\n",
      "Epoch 229: val_loss improved from 0.75935 to 0.75866, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6533 - loss: 1.0201 - val_accuracy: 0.7812 - val_loss: 0.7587\n",
      "Epoch 230/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6551 - loss: 1.0285\n",
      "Epoch 230: val_loss improved from 0.75866 to 0.75690, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6550 - loss: 1.0284 - val_accuracy: 0.7806 - val_loss: 0.7569\n",
      "Epoch 231/1500\n",
      "\u001b[1m739/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6475 - loss: 1.0231\n",
      "Epoch 231: val_loss did not improve from 0.75690\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6477 - loss: 1.0232 - val_accuracy: 0.7838 - val_loss: 0.7586\n",
      "Epoch 232/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6542 - loss: 1.0189\n",
      "Epoch 232: val_loss did not improve from 0.75690\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6542 - loss: 1.0189 - val_accuracy: 0.7840 - val_loss: 0.7582\n",
      "Epoch 233/1500\n",
      "\u001b[1m736/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6620 - loss: 1.0177\n",
      "Epoch 233: val_loss improved from 0.75690 to 0.75468, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6617 - loss: 1.0180 - val_accuracy: 0.7841 - val_loss: 0.7547\n",
      "Epoch 234/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6501 - loss: 1.0196\n",
      "Epoch 234: val_loss did not improve from 0.75468\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6502 - loss: 1.0196 - val_accuracy: 0.7845 - val_loss: 0.7577\n",
      "Epoch 235/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6451 - loss: 1.0350\n",
      "Epoch 235: val_loss improved from 0.75468 to 0.75173, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6451 - loss: 1.0350 - val_accuracy: 0.7830 - val_loss: 0.7517\n",
      "Epoch 236/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6590 - loss: 1.0068\n",
      "Epoch 236: val_loss did not improve from 0.75173\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6590 - loss: 1.0068 - val_accuracy: 0.7864 - val_loss: 0.7530\n",
      "Epoch 237/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6565 - loss: 1.0082\n",
      "Epoch 237: val_loss did not improve from 0.75173\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6564 - loss: 1.0087 - val_accuracy: 0.7845 - val_loss: 0.7528\n",
      "Epoch 238/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6514 - loss: 1.0174\n",
      "Epoch 238: val_loss did not improve from 0.75173\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6514 - loss: 1.0174 - val_accuracy: 0.7859 - val_loss: 0.7517\n",
      "Epoch 239/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6551 - loss: 1.0216\n",
      "Epoch 239: val_loss did not improve from 0.75173\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6551 - loss: 1.0214 - val_accuracy: 0.7841 - val_loss: 0.7524\n",
      "Epoch 240/1500\n",
      "\u001b[1m741/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6570 - loss: 1.0100\n",
      "Epoch 240: val_loss improved from 0.75173 to 0.74985, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6569 - loss: 1.0103 - val_accuracy: 0.7862 - val_loss: 0.7499\n",
      "Epoch 241/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6491 - loss: 1.0231\n",
      "Epoch 241: val_loss did not improve from 0.74985\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6491 - loss: 1.0231 - val_accuracy: 0.7851 - val_loss: 0.7510\n",
      "Epoch 242/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6639 - loss: 0.9997\n",
      "Epoch 242: val_loss improved from 0.74985 to 0.74770, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6639 - loss: 0.9998 - val_accuracy: 0.7862 - val_loss: 0.7477\n",
      "Epoch 243/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6489 - loss: 1.0238\n",
      "Epoch 243: val_loss improved from 0.74770 to 0.74550, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6489 - loss: 1.0236 - val_accuracy: 0.7869 - val_loss: 0.7455\n",
      "Epoch 244/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6398 - loss: 1.0298\n",
      "Epoch 244: val_loss improved from 0.74550 to 0.74407, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6400 - loss: 1.0295 - val_accuracy: 0.7870 - val_loss: 0.7441\n",
      "Epoch 245/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6557 - loss: 1.0120\n",
      "Epoch 245: val_loss did not improve from 0.74407\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6556 - loss: 1.0120 - val_accuracy: 0.7845 - val_loss: 0.7463\n",
      "Epoch 246/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6519 - loss: 1.0116\n",
      "Epoch 246: val_loss improved from 0.74407 to 0.74343, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6519 - loss: 1.0116 - val_accuracy: 0.7869 - val_loss: 0.7434\n",
      "Epoch 247/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6605 - loss: 1.0022\n",
      "Epoch 247: val_loss did not improve from 0.74343\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6604 - loss: 1.0023 - val_accuracy: 0.7849 - val_loss: 0.7471\n",
      "Epoch 248/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6542 - loss: 1.0162\n",
      "Epoch 248: val_loss improved from 0.74343 to 0.74292, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6542 - loss: 1.0160 - val_accuracy: 0.7880 - val_loss: 0.7429\n",
      "Epoch 249/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6593 - loss: 1.0053\n",
      "Epoch 249: val_loss did not improve from 0.74292\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6593 - loss: 1.0054 - val_accuracy: 0.7859 - val_loss: 0.7454\n",
      "Epoch 250/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6639 - loss: 0.9978\n",
      "Epoch 250: val_loss improved from 0.74292 to 0.74227, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6638 - loss: 0.9980 - val_accuracy: 0.7887 - val_loss: 0.7423\n",
      "Epoch 251/1500\n",
      "\u001b[1m741/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6548 - loss: 1.0033\n",
      "Epoch 251: val_loss improved from 0.74227 to 0.74186, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6548 - loss: 1.0035 - val_accuracy: 0.7841 - val_loss: 0.7419\n",
      "Epoch 252/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6610 - loss: 0.9919\n",
      "Epoch 252: val_loss did not improve from 0.74186\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6610 - loss: 0.9921 - val_accuracy: 0.7848 - val_loss: 0.7438\n",
      "Epoch 253/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6569 - loss: 1.0037\n",
      "Epoch 253: val_loss did not improve from 0.74186\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6569 - loss: 1.0038 - val_accuracy: 0.7851 - val_loss: 0.7436\n",
      "Epoch 254/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6549 - loss: 1.0170\n",
      "Epoch 254: val_loss improved from 0.74186 to 0.73778, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6550 - loss: 1.0166 - val_accuracy: 0.7882 - val_loss: 0.7378\n",
      "Epoch 255/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6538 - loss: 1.0045\n",
      "Epoch 255: val_loss improved from 0.73778 to 0.73743, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6538 - loss: 1.0044 - val_accuracy: 0.7866 - val_loss: 0.7374\n",
      "Epoch 256/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6587 - loss: 1.0015\n",
      "Epoch 256: val_loss improved from 0.73743 to 0.73555, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6586 - loss: 1.0016 - val_accuracy: 0.7880 - val_loss: 0.7356\n",
      "Epoch 257/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6596 - loss: 0.9959\n",
      "Epoch 257: val_loss improved from 0.73555 to 0.73512, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6595 - loss: 0.9961 - val_accuracy: 0.7900 - val_loss: 0.7351\n",
      "Epoch 258/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6585 - loss: 0.9915\n",
      "Epoch 258: val_loss improved from 0.73512 to 0.73356, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6584 - loss: 0.9917 - val_accuracy: 0.7893 - val_loss: 0.7336\n",
      "Epoch 259/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6542 - loss: 1.0078\n",
      "Epoch 259: val_loss did not improve from 0.73356\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6542 - loss: 1.0078 - val_accuracy: 0.7887 - val_loss: 0.7343\n",
      "Epoch 260/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6559 - loss: 1.0061\n",
      "Epoch 260: val_loss did not improve from 0.73356\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6559 - loss: 1.0060 - val_accuracy: 0.7851 - val_loss: 0.7396\n",
      "Epoch 261/1500\n",
      "\u001b[1m741/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6583 - loss: 0.9864\n",
      "Epoch 261: val_loss improved from 0.73356 to 0.73129, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6581 - loss: 0.9868 - val_accuracy: 0.7893 - val_loss: 0.7313\n",
      "Epoch 262/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6548 - loss: 1.0134\n",
      "Epoch 262: val_loss did not improve from 0.73129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6548 - loss: 1.0133 - val_accuracy: 0.7882 - val_loss: 0.7318\n",
      "Epoch 263/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6557 - loss: 1.0007\n",
      "Epoch 263: val_loss improved from 0.73129 to 0.72804, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6557 - loss: 1.0007 - val_accuracy: 0.7900 - val_loss: 0.7280\n",
      "Epoch 264/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6600 - loss: 0.9954\n",
      "Epoch 264: val_loss did not improve from 0.72804\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6600 - loss: 0.9955 - val_accuracy: 0.7879 - val_loss: 0.7313\n",
      "Epoch 265/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6607 - loss: 0.9864\n",
      "Epoch 265: val_loss did not improve from 0.72804\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6607 - loss: 0.9865 - val_accuracy: 0.7867 - val_loss: 0.7326\n",
      "Epoch 266/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6618 - loss: 0.9971\n",
      "Epoch 266: val_loss did not improve from 0.72804\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6619 - loss: 0.9970 - val_accuracy: 0.7911 - val_loss: 0.7290\n",
      "Epoch 267/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6606 - loss: 0.9942\n",
      "Epoch 267: val_loss improved from 0.72804 to 0.72622, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6605 - loss: 0.9943 - val_accuracy: 0.7921 - val_loss: 0.7262\n",
      "Epoch 268/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6618 - loss: 0.9848\n",
      "Epoch 268: val_loss improved from 0.72622 to 0.72092, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6619 - loss: 0.9847 - val_accuracy: 0.7924 - val_loss: 0.7209\n",
      "Epoch 269/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6589 - loss: 0.9947\n",
      "Epoch 269: val_loss did not improve from 0.72092\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6590 - loss: 0.9945 - val_accuracy: 0.7879 - val_loss: 0.7263\n",
      "Epoch 270/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6589 - loss: 0.9976\n",
      "Epoch 270: val_loss did not improve from 0.72092\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6589 - loss: 0.9976 - val_accuracy: 0.7906 - val_loss: 0.7250\n",
      "Epoch 271/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6604 - loss: 1.0137\n",
      "Epoch 271: val_loss did not improve from 0.72092\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6604 - loss: 1.0132 - val_accuracy: 0.7911 - val_loss: 0.7259\n",
      "Epoch 272/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6623 - loss: 0.9934\n",
      "Epoch 272: val_loss did not improve from 0.72092\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6622 - loss: 0.9934 - val_accuracy: 0.7885 - val_loss: 0.7267\n",
      "Epoch 273/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6587 - loss: 1.0005\n",
      "Epoch 273: val_loss did not improve from 0.72092\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6588 - loss: 1.0002 - val_accuracy: 0.7896 - val_loss: 0.7258\n",
      "Epoch 274/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6636 - loss: 0.9943\n",
      "Epoch 274: val_loss improved from 0.72092 to 0.72051, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6636 - loss: 0.9942 - val_accuracy: 0.7911 - val_loss: 0.7205\n",
      "Epoch 275/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6486 - loss: 1.0073\n",
      "Epoch 275: val_loss did not improve from 0.72051\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6488 - loss: 1.0072 - val_accuracy: 0.7890 - val_loss: 0.7243\n",
      "Epoch 276/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6596 - loss: 1.0024\n",
      "Epoch 276: val_loss did not improve from 0.72051\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6597 - loss: 1.0021 - val_accuracy: 0.7896 - val_loss: 0.7264\n",
      "Epoch 277/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6598 - loss: 0.9896\n",
      "Epoch 277: val_loss improved from 0.72051 to 0.72010, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6599 - loss: 0.9895 - val_accuracy: 0.7919 - val_loss: 0.7201\n",
      "Epoch 278/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6609 - loss: 0.9969\n",
      "Epoch 278: val_loss improved from 0.72010 to 0.71846, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6609 - loss: 0.9968 - val_accuracy: 0.7919 - val_loss: 0.7185\n",
      "Epoch 279/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6616 - loss: 0.9844\n",
      "Epoch 279: val_loss did not improve from 0.71846\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6616 - loss: 0.9845 - val_accuracy: 0.7906 - val_loss: 0.7195\n",
      "Epoch 280/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6695 - loss: 0.9835\n",
      "Epoch 280: val_loss did not improve from 0.71846\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6693 - loss: 0.9836 - val_accuracy: 0.7900 - val_loss: 0.7226\n",
      "Epoch 281/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6634 - loss: 0.9844\n",
      "Epoch 281: val_loss improved from 0.71846 to 0.71834, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6634 - loss: 0.9844 - val_accuracy: 0.7930 - val_loss: 0.7183\n",
      "Epoch 282/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6601 - loss: 0.9848\n",
      "Epoch 282: val_loss improved from 0.71834 to 0.71665, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6602 - loss: 0.9847 - val_accuracy: 0.7911 - val_loss: 0.7167\n",
      "Epoch 283/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6536 - loss: 0.9874\n",
      "Epoch 283: val_loss did not improve from 0.71665\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6537 - loss: 0.9874 - val_accuracy: 0.7900 - val_loss: 0.7189\n",
      "Epoch 284/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6732 - loss: 0.9757\n",
      "Epoch 284: val_loss improved from 0.71665 to 0.71654, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6731 - loss: 0.9756 - val_accuracy: 0.7904 - val_loss: 0.7165\n",
      "Epoch 285/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6598 - loss: 0.9784\n",
      "Epoch 285: val_loss improved from 0.71654 to 0.71326, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6598 - loss: 0.9784 - val_accuracy: 0.7932 - val_loss: 0.7133\n",
      "Epoch 286/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6634 - loss: 0.9847\n",
      "Epoch 286: val_loss did not improve from 0.71326\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6634 - loss: 0.9847 - val_accuracy: 0.7908 - val_loss: 0.7177\n",
      "Epoch 287/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6630 - loss: 0.9836\n",
      "Epoch 287: val_loss did not improve from 0.71326\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6630 - loss: 0.9836 - val_accuracy: 0.7924 - val_loss: 0.7151\n",
      "Epoch 288/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6642 - loss: 0.9686\n",
      "Epoch 288: val_loss improved from 0.71326 to 0.71019, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6641 - loss: 0.9690 - val_accuracy: 0.7951 - val_loss: 0.7102\n",
      "Epoch 289/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6592 - loss: 0.9889\n",
      "Epoch 289: val_loss did not improve from 0.71019\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6593 - loss: 0.9887 - val_accuracy: 0.7930 - val_loss: 0.7123\n",
      "Epoch 290/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6683 - loss: 0.9707\n",
      "Epoch 290: val_loss improved from 0.71019 to 0.71006, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6682 - loss: 0.9708 - val_accuracy: 0.7938 - val_loss: 0.7101\n",
      "Epoch 291/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6662 - loss: 0.9825\n",
      "Epoch 291: val_loss improved from 0.71006 to 0.70996, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6662 - loss: 0.9824 - val_accuracy: 0.7942 - val_loss: 0.7100\n",
      "Epoch 292/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6610 - loss: 0.9816\n",
      "Epoch 292: val_loss did not improve from 0.70996\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6610 - loss: 0.9816 - val_accuracy: 0.7950 - val_loss: 0.7117\n",
      "Epoch 293/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6699 - loss: 0.9743\n",
      "Epoch 293: val_loss improved from 0.70996 to 0.70870, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6697 - loss: 0.9746 - val_accuracy: 0.7948 - val_loss: 0.7087\n",
      "Epoch 294/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6602 - loss: 0.9809\n",
      "Epoch 294: val_loss did not improve from 0.70870\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6602 - loss: 0.9808 - val_accuracy: 0.7922 - val_loss: 0.7128\n",
      "Epoch 295/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6757 - loss: 0.9614\n",
      "Epoch 295: val_loss improved from 0.70870 to 0.70584, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6755 - loss: 0.9616 - val_accuracy: 0.7943 - val_loss: 0.7058\n",
      "Epoch 296/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6625 - loss: 0.9815\n",
      "Epoch 296: val_loss did not improve from 0.70584\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6625 - loss: 0.9815 - val_accuracy: 0.7917 - val_loss: 0.7096\n",
      "Epoch 297/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6639 - loss: 0.9779\n",
      "Epoch 297: val_loss did not improve from 0.70584\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6640 - loss: 0.9778 - val_accuracy: 0.7960 - val_loss: 0.7070\n",
      "Epoch 298/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6563 - loss: 0.9878\n",
      "Epoch 298: val_loss did not improve from 0.70584\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6564 - loss: 0.9877 - val_accuracy: 0.7961 - val_loss: 0.7076\n",
      "Epoch 299/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6604 - loss: 0.9823\n",
      "Epoch 299: val_loss improved from 0.70584 to 0.70461, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6604 - loss: 0.9823 - val_accuracy: 0.7937 - val_loss: 0.7046\n",
      "Epoch 300/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6653 - loss: 0.9819\n",
      "Epoch 300: val_loss did not improve from 0.70461\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6652 - loss: 0.9817 - val_accuracy: 0.7940 - val_loss: 0.7057\n",
      "Epoch 301/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6718 - loss: 0.9618\n",
      "Epoch 301: val_loss improved from 0.70461 to 0.70445, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6717 - loss: 0.9621 - val_accuracy: 0.7958 - val_loss: 0.7045\n",
      "Epoch 302/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6726 - loss: 0.9672\n",
      "Epoch 302: val_loss did not improve from 0.70445\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6726 - loss: 0.9671 - val_accuracy: 0.7943 - val_loss: 0.7069\n",
      "Epoch 303/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6612 - loss: 0.9833\n",
      "Epoch 303: val_loss improved from 0.70445 to 0.70430, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6612 - loss: 0.9831 - val_accuracy: 0.7950 - val_loss: 0.7043\n",
      "Epoch 304/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6713 - loss: 0.9640\n",
      "Epoch 304: val_loss improved from 0.70430 to 0.70216, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6713 - loss: 0.9640 - val_accuracy: 0.7950 - val_loss: 0.7022\n",
      "Epoch 305/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6679 - loss: 0.9700\n",
      "Epoch 305: val_loss improved from 0.70216 to 0.69906, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6680 - loss: 0.9700 - val_accuracy: 0.7990 - val_loss: 0.6991\n",
      "Epoch 306/1500\n",
      "\u001b[1m742/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6617 - loss: 0.9821\n",
      "Epoch 306: val_loss did not improve from 0.69906\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6618 - loss: 0.9817 - val_accuracy: 0.7943 - val_loss: 0.7029\n",
      "Epoch 307/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6660 - loss: 0.9680\n",
      "Epoch 307: val_loss did not improve from 0.69906\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6660 - loss: 0.9680 - val_accuracy: 0.7930 - val_loss: 0.7072\n",
      "Epoch 308/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6652 - loss: 0.9724\n",
      "Epoch 308: val_loss did not improve from 0.69906\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6652 - loss: 0.9724 - val_accuracy: 0.7932 - val_loss: 0.7047\n",
      "Epoch 309/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6648 - loss: 0.9783\n",
      "Epoch 309: val_loss did not improve from 0.69906\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6649 - loss: 0.9782 - val_accuracy: 0.7956 - val_loss: 0.7014\n",
      "Epoch 310/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6699 - loss: 0.9500\n",
      "Epoch 310: val_loss did not improve from 0.69906\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6699 - loss: 0.9502 - val_accuracy: 0.7960 - val_loss: 0.7008\n",
      "Epoch 311/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6679 - loss: 0.9593\n",
      "Epoch 311: val_loss did not improve from 0.69906\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6679 - loss: 0.9594 - val_accuracy: 0.7958 - val_loss: 0.7002\n",
      "Epoch 312/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6680 - loss: 0.9748\n",
      "Epoch 312: val_loss improved from 0.69906 to 0.69806, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6680 - loss: 0.9748 - val_accuracy: 0.7982 - val_loss: 0.6981\n",
      "Epoch 313/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6621 - loss: 0.9738\n",
      "Epoch 313: val_loss did not improve from 0.69806\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6621 - loss: 0.9736 - val_accuracy: 0.7938 - val_loss: 0.7000\n",
      "Epoch 314/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6755 - loss: 0.9497\n",
      "Epoch 314: val_loss improved from 0.69806 to 0.69510, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6754 - loss: 0.9500 - val_accuracy: 0.7974 - val_loss: 0.6951\n",
      "Epoch 315/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6709 - loss: 0.9660\n",
      "Epoch 315: val_loss did not improve from 0.69510\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6709 - loss: 0.9659 - val_accuracy: 0.7998 - val_loss: 0.6978\n",
      "Epoch 316/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6707 - loss: 0.9522\n",
      "Epoch 316: val_loss did not improve from 0.69510\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6707 - loss: 0.9522 - val_accuracy: 0.7976 - val_loss: 0.6976\n",
      "Epoch 317/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6705 - loss: 0.9553\n",
      "Epoch 317: val_loss improved from 0.69510 to 0.69411, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6704 - loss: 0.9554 - val_accuracy: 0.7972 - val_loss: 0.6941\n",
      "Epoch 318/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6703 - loss: 0.9700\n",
      "Epoch 318: val_loss improved from 0.69411 to 0.69330, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6702 - loss: 0.9699 - val_accuracy: 0.7997 - val_loss: 0.6933\n",
      "Epoch 319/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6718 - loss: 0.9620\n",
      "Epoch 319: val_loss did not improve from 0.69330\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6718 - loss: 0.9619 - val_accuracy: 0.7977 - val_loss: 0.6957\n",
      "Epoch 320/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6755 - loss: 0.9515\n",
      "Epoch 320: val_loss improved from 0.69330 to 0.69028, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6753 - loss: 0.9518 - val_accuracy: 0.8005 - val_loss: 0.6903\n",
      "Epoch 321/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6651 - loss: 0.9673\n",
      "Epoch 321: val_loss did not improve from 0.69028\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6651 - loss: 0.9672 - val_accuracy: 0.7966 - val_loss: 0.6932\n",
      "Epoch 322/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6700 - loss: 0.9641\n",
      "Epoch 322: val_loss did not improve from 0.69028\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6700 - loss: 0.9640 - val_accuracy: 0.7964 - val_loss: 0.6947\n",
      "Epoch 323/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6671 - loss: 0.9711\n",
      "Epoch 323: val_loss did not improve from 0.69028\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6673 - loss: 0.9707 - val_accuracy: 0.8008 - val_loss: 0.6910\n",
      "Epoch 324/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6698 - loss: 0.9576\n",
      "Epoch 324: val_loss did not improve from 0.69028\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6698 - loss: 0.9577 - val_accuracy: 0.7977 - val_loss: 0.6920\n",
      "Epoch 325/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6717 - loss: 0.9576\n",
      "Epoch 325: val_loss improved from 0.69028 to 0.68830, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6717 - loss: 0.9576 - val_accuracy: 0.8016 - val_loss: 0.6883\n",
      "Epoch 326/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6684 - loss: 0.9592\n",
      "Epoch 326: val_loss did not improve from 0.68830\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6684 - loss: 0.9592 - val_accuracy: 0.8015 - val_loss: 0.6897\n",
      "Epoch 327/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6676 - loss: 0.9623\n",
      "Epoch 327: val_loss did not improve from 0.68830\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6676 - loss: 0.9623 - val_accuracy: 0.7990 - val_loss: 0.6896\n",
      "Epoch 328/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6625 - loss: 0.9780\n",
      "Epoch 328: val_loss improved from 0.68830 to 0.68657, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6627 - loss: 0.9776 - val_accuracy: 0.8018 - val_loss: 0.6866\n",
      "Epoch 329/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6704 - loss: 0.9493\n",
      "Epoch 329: val_loss improved from 0.68657 to 0.68517, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6705 - loss: 0.9493 - val_accuracy: 0.8008 - val_loss: 0.6852\n",
      "Epoch 330/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6712 - loss: 0.9545\n",
      "Epoch 330: val_loss did not improve from 0.68517\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6713 - loss: 0.9545 - val_accuracy: 0.7995 - val_loss: 0.6875\n",
      "Epoch 331/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6631 - loss: 0.9648\n",
      "Epoch 331: val_loss did not improve from 0.68517\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6632 - loss: 0.9647 - val_accuracy: 0.7987 - val_loss: 0.6888\n",
      "Epoch 332/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6596 - loss: 0.9698\n",
      "Epoch 332: val_loss did not improve from 0.68517\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6596 - loss: 0.9698 - val_accuracy: 0.8006 - val_loss: 0.6864\n",
      "Epoch 333/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6675 - loss: 0.9552\n",
      "Epoch 333: val_loss improved from 0.68517 to 0.68505, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6676 - loss: 0.9551 - val_accuracy: 0.8008 - val_loss: 0.6851\n",
      "Epoch 334/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6683 - loss: 0.9592\n",
      "Epoch 334: val_loss improved from 0.68505 to 0.68379, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6684 - loss: 0.9592 - val_accuracy: 0.8024 - val_loss: 0.6838\n",
      "Epoch 335/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6678 - loss: 0.9552\n",
      "Epoch 335: val_loss improved from 0.68379 to 0.68340, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6679 - loss: 0.9551 - val_accuracy: 0.8000 - val_loss: 0.6834\n",
      "Epoch 336/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6686 - loss: 0.9518\n",
      "Epoch 336: val_loss did not improve from 0.68340\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6687 - loss: 0.9518 - val_accuracy: 0.8006 - val_loss: 0.6848\n",
      "Epoch 337/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6756 - loss: 0.9502\n",
      "Epoch 337: val_loss did not improve from 0.68340\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6756 - loss: 0.9502 - val_accuracy: 0.8008 - val_loss: 0.6854\n",
      "Epoch 338/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6710 - loss: 0.9574\n",
      "Epoch 338: val_loss did not improve from 0.68340\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6710 - loss: 0.9573 - val_accuracy: 0.8010 - val_loss: 0.6844\n",
      "Epoch 339/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6799 - loss: 0.9458\n",
      "Epoch 339: val_loss did not improve from 0.68340\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6798 - loss: 0.9459 - val_accuracy: 0.7995 - val_loss: 0.6870\n",
      "Epoch 340/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6653 - loss: 0.9625\n",
      "Epoch 340: val_loss improved from 0.68340 to 0.68055, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6653 - loss: 0.9624 - val_accuracy: 0.8019 - val_loss: 0.6805\n",
      "Epoch 341/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6710 - loss: 0.9412\n",
      "Epoch 341: val_loss did not improve from 0.68055\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6710 - loss: 0.9412 - val_accuracy: 0.7998 - val_loss: 0.6846\n",
      "Epoch 342/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6703 - loss: 0.9572\n",
      "Epoch 342: val_loss did not improve from 0.68055\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6703 - loss: 0.9572 - val_accuracy: 0.8006 - val_loss: 0.6830\n",
      "Epoch 343/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6761 - loss: 0.9392\n",
      "Epoch 343: val_loss improved from 0.68055 to 0.67711, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6761 - loss: 0.9393 - val_accuracy: 0.8052 - val_loss: 0.6771\n",
      "Epoch 344/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6697 - loss: 0.9637\n",
      "Epoch 344: val_loss improved from 0.67711 to 0.67685, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6697 - loss: 0.9636 - val_accuracy: 0.8031 - val_loss: 0.6769\n",
      "Epoch 345/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6758 - loss: 0.9459\n",
      "Epoch 345: val_loss did not improve from 0.67685\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6757 - loss: 0.9460 - val_accuracy: 0.8002 - val_loss: 0.6794\n",
      "Epoch 346/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6744 - loss: 0.9556\n",
      "Epoch 346: val_loss improved from 0.67685 to 0.67488, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6744 - loss: 0.9556 - val_accuracy: 0.8044 - val_loss: 0.6749\n",
      "Epoch 347/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6779 - loss: 0.9402\n",
      "Epoch 347: val_loss did not improve from 0.67488\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6779 - loss: 0.9402 - val_accuracy: 0.8065 - val_loss: 0.6787\n",
      "Epoch 348/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6776 - loss: 0.9406\n",
      "Epoch 348: val_loss did not improve from 0.67488\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6776 - loss: 0.9406 - val_accuracy: 0.8024 - val_loss: 0.6784\n",
      "Epoch 349/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6717 - loss: 0.9495\n",
      "Epoch 349: val_loss improved from 0.67488 to 0.67486, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6717 - loss: 0.9494 - val_accuracy: 0.8042 - val_loss: 0.6749\n",
      "Epoch 350/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6725 - loss: 0.9497\n",
      "Epoch 350: val_loss did not improve from 0.67486\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6725 - loss: 0.9497 - val_accuracy: 0.8029 - val_loss: 0.6757\n",
      "Epoch 351/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6757 - loss: 0.9584\n",
      "Epoch 351: val_loss did not improve from 0.67486\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6756 - loss: 0.9582 - val_accuracy: 0.8039 - val_loss: 0.6758\n",
      "Epoch 352/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6814 - loss: 0.9354\n",
      "Epoch 352: val_loss improved from 0.67486 to 0.67456, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6814 - loss: 0.9356 - val_accuracy: 0.8029 - val_loss: 0.6746\n",
      "Epoch 353/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6756 - loss: 0.9471\n",
      "Epoch 353: val_loss did not improve from 0.67456\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6755 - loss: 0.9471 - val_accuracy: 0.8008 - val_loss: 0.6803\n",
      "Epoch 354/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6746 - loss: 0.9415\n",
      "Epoch 354: val_loss improved from 0.67456 to 0.67401, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6746 - loss: 0.9415 - val_accuracy: 0.8042 - val_loss: 0.6740\n",
      "Epoch 355/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6753 - loss: 0.9419\n",
      "Epoch 355: val_loss improved from 0.67401 to 0.67237, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6753 - loss: 0.9419 - val_accuracy: 0.8045 - val_loss: 0.6724\n",
      "Epoch 356/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6807 - loss: 0.9251\n",
      "Epoch 356: val_loss did not improve from 0.67237\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6806 - loss: 0.9253 - val_accuracy: 0.8039 - val_loss: 0.6735\n",
      "Epoch 357/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6750 - loss: 0.9486\n",
      "Epoch 357: val_loss improved from 0.67237 to 0.67127, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6750 - loss: 0.9486 - val_accuracy: 0.8063 - val_loss: 0.6713\n",
      "Epoch 358/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6853 - loss: 0.9281\n",
      "Epoch 358: val_loss did not improve from 0.67127\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6853 - loss: 0.9282 - val_accuracy: 0.8023 - val_loss: 0.6729\n",
      "Epoch 359/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6790 - loss: 0.9441\n",
      "Epoch 359: val_loss did not improve from 0.67127\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6789 - loss: 0.9443 - val_accuracy: 0.8032 - val_loss: 0.6735\n",
      "Epoch 360/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6779 - loss: 0.9345\n",
      "Epoch 360: val_loss did not improve from 0.67127\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6779 - loss: 0.9345 - val_accuracy: 0.8021 - val_loss: 0.6752\n",
      "Epoch 361/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6808 - loss: 0.9222\n",
      "Epoch 361: val_loss did not improve from 0.67127\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6808 - loss: 0.9223 - val_accuracy: 0.8031 - val_loss: 0.6721\n",
      "Epoch 362/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6752 - loss: 0.9499\n",
      "Epoch 362: val_loss improved from 0.67127 to 0.67047, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6753 - loss: 0.9499 - val_accuracy: 0.8057 - val_loss: 0.6705\n",
      "Epoch 363/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6733 - loss: 0.9448\n",
      "Epoch 363: val_loss did not improve from 0.67047\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6733 - loss: 0.9449 - val_accuracy: 0.8042 - val_loss: 0.6708\n",
      "Epoch 364/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6694 - loss: 0.9596\n",
      "Epoch 364: val_loss did not improve from 0.67047\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6694 - loss: 0.9593 - val_accuracy: 0.8045 - val_loss: 0.6706\n",
      "Epoch 365/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6778 - loss: 0.9242\n",
      "Epoch 365: val_loss improved from 0.67047 to 0.66781, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6778 - loss: 0.9244 - val_accuracy: 0.8028 - val_loss: 0.6678\n",
      "Epoch 366/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6781 - loss: 0.9385\n",
      "Epoch 366: val_loss did not improve from 0.66781\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6781 - loss: 0.9385 - val_accuracy: 0.8015 - val_loss: 0.6741\n",
      "Epoch 367/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6765 - loss: 0.9395\n",
      "Epoch 367: val_loss did not improve from 0.66781\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6764 - loss: 0.9395 - val_accuracy: 0.8015 - val_loss: 0.6724\n",
      "Epoch 368/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6810 - loss: 0.9390\n",
      "Epoch 368: val_loss improved from 0.66781 to 0.66681, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6810 - loss: 0.9390 - val_accuracy: 0.8047 - val_loss: 0.6668\n",
      "Epoch 369/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6847 - loss: 0.9145\n",
      "Epoch 369: val_loss did not improve from 0.66681\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6847 - loss: 0.9147 - val_accuracy: 0.8068 - val_loss: 0.6670\n",
      "Epoch 370/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6814 - loss: 0.9312\n",
      "Epoch 370: val_loss did not improve from 0.66681\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6814 - loss: 0.9312 - val_accuracy: 0.8063 - val_loss: 0.6677\n",
      "Epoch 371/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6791 - loss: 0.9261\n",
      "Epoch 371: val_loss did not improve from 0.66681\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6791 - loss: 0.9262 - val_accuracy: 0.8031 - val_loss: 0.6681\n",
      "Epoch 372/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6787 - loss: 0.9268\n",
      "Epoch 372: val_loss did not improve from 0.66681\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6787 - loss: 0.9268 - val_accuracy: 0.8029 - val_loss: 0.6692\n",
      "Epoch 373/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6797 - loss: 0.9201\n",
      "Epoch 373: val_loss improved from 0.66681 to 0.66231, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6796 - loss: 0.9202 - val_accuracy: 0.8107 - val_loss: 0.6623\n",
      "Epoch 374/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6765 - loss: 0.9398\n",
      "Epoch 374: val_loss did not improve from 0.66231\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6765 - loss: 0.9398 - val_accuracy: 0.8019 - val_loss: 0.6679\n",
      "Epoch 375/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6818 - loss: 0.9268\n",
      "Epoch 375: val_loss did not improve from 0.66231\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6818 - loss: 0.9269 - val_accuracy: 0.8066 - val_loss: 0.6665\n",
      "Epoch 376/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6765 - loss: 0.9344\n",
      "Epoch 376: val_loss did not improve from 0.66231\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6765 - loss: 0.9344 - val_accuracy: 0.8050 - val_loss: 0.6663\n",
      "Epoch 377/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6822 - loss: 0.9370\n",
      "Epoch 377: val_loss improved from 0.66231 to 0.65893, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6822 - loss: 0.9369 - val_accuracy: 0.8078 - val_loss: 0.6589\n",
      "Epoch 378/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6753 - loss: 0.9293\n",
      "Epoch 378: val_loss did not improve from 0.65893\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6753 - loss: 0.9293 - val_accuracy: 0.8044 - val_loss: 0.6654\n",
      "Epoch 379/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6838 - loss: 0.9145\n",
      "Epoch 379: val_loss did not improve from 0.65893\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6836 - loss: 0.9150 - val_accuracy: 0.8045 - val_loss: 0.6660\n",
      "Epoch 380/1500\n",
      "\u001b[1m741/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6853 - loss: 0.9190\n",
      "Epoch 380: val_loss did not improve from 0.65893\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6850 - loss: 0.9196 - val_accuracy: 0.8076 - val_loss: 0.6606\n",
      "Epoch 381/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6802 - loss: 0.9310\n",
      "Epoch 381: val_loss did not improve from 0.65893\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6802 - loss: 0.9310 - val_accuracy: 0.8094 - val_loss: 0.6597\n",
      "Epoch 382/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6869 - loss: 0.9161\n",
      "Epoch 382: val_loss did not improve from 0.65893\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6867 - loss: 0.9165 - val_accuracy: 0.8096 - val_loss: 0.6600\n",
      "Epoch 383/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6807 - loss: 0.9221\n",
      "Epoch 383: val_loss did not improve from 0.65893\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6807 - loss: 0.9222 - val_accuracy: 0.8070 - val_loss: 0.6620\n",
      "Epoch 384/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6810 - loss: 0.9317\n",
      "Epoch 384: val_loss did not improve from 0.65893\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6810 - loss: 0.9317 - val_accuracy: 0.8086 - val_loss: 0.6600\n",
      "Epoch 385/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6829 - loss: 0.9233\n",
      "Epoch 385: val_loss did not improve from 0.65893\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6829 - loss: 0.9233 - val_accuracy: 0.8045 - val_loss: 0.6639\n",
      "Epoch 386/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6910 - loss: 0.9050\n",
      "Epoch 386: val_loss did not improve from 0.65893\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6909 - loss: 0.9052 - val_accuracy: 0.8071 - val_loss: 0.6617\n",
      "Epoch 387/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6750 - loss: 0.9270\n",
      "Epoch 387: val_loss did not improve from 0.65893\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6750 - loss: 0.9270 - val_accuracy: 0.8053 - val_loss: 0.6637\n",
      "Epoch 388/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6867 - loss: 0.9088\n",
      "Epoch 388: val_loss improved from 0.65893 to 0.65571, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6866 - loss: 0.9091 - val_accuracy: 0.8109 - val_loss: 0.6557\n",
      "Epoch 389/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6746 - loss: 0.9384\n",
      "Epoch 389: val_loss did not improve from 0.65571\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6747 - loss: 0.9383 - val_accuracy: 0.8083 - val_loss: 0.6592\n",
      "Epoch 390/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6793 - loss: 0.9261\n",
      "Epoch 390: val_loss did not improve from 0.65571\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6793 - loss: 0.9262 - val_accuracy: 0.8084 - val_loss: 0.6567\n",
      "Epoch 391/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6755 - loss: 0.9238\n",
      "Epoch 391: val_loss did not improve from 0.65571\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6755 - loss: 0.9240 - val_accuracy: 0.8055 - val_loss: 0.6594\n",
      "Epoch 392/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6817 - loss: 0.9241\n",
      "Epoch 392: val_loss did not improve from 0.65571\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6817 - loss: 0.9241 - val_accuracy: 0.8104 - val_loss: 0.6569\n",
      "Epoch 393/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6839 - loss: 0.9216\n",
      "Epoch 393: val_loss improved from 0.65571 to 0.65538, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6838 - loss: 0.9216 - val_accuracy: 0.8087 - val_loss: 0.6554\n",
      "Epoch 394/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6842 - loss: 0.9237\n",
      "Epoch 394: val_loss did not improve from 0.65538\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6841 - loss: 0.9237 - val_accuracy: 0.8052 - val_loss: 0.6586\n",
      "Epoch 395/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6742 - loss: 0.9321\n",
      "Epoch 395: val_loss did not improve from 0.65538\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6744 - loss: 0.9319 - val_accuracy: 0.8049 - val_loss: 0.6613\n",
      "Epoch 396/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6813 - loss: 0.9137\n",
      "Epoch 396: val_loss did not improve from 0.65538\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6813 - loss: 0.9137 - val_accuracy: 0.8113 - val_loss: 0.6558\n",
      "Epoch 397/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6790 - loss: 0.9304\n",
      "Epoch 397: val_loss improved from 0.65538 to 0.65403, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6790 - loss: 0.9302 - val_accuracy: 0.8100 - val_loss: 0.6540\n",
      "Epoch 398/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6823 - loss: 0.9229\n",
      "Epoch 398: val_loss improved from 0.65403 to 0.65333, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6823 - loss: 0.9229 - val_accuracy: 0.8128 - val_loss: 0.6533\n",
      "Epoch 399/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6837 - loss: 0.9134\n",
      "Epoch 399: val_loss improved from 0.65333 to 0.65313, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6837 - loss: 0.9135 - val_accuracy: 0.8112 - val_loss: 0.6531\n",
      "Epoch 400/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6795 - loss: 0.9431\n",
      "Epoch 400: val_loss did not improve from 0.65313\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6795 - loss: 0.9427 - val_accuracy: 0.8078 - val_loss: 0.6538\n",
      "Epoch 401/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6927 - loss: 0.9067\n",
      "Epoch 401: val_loss did not improve from 0.65313\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6924 - loss: 0.9071 - val_accuracy: 0.8092 - val_loss: 0.6532\n",
      "Epoch 402/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6878 - loss: 0.9100\n",
      "Epoch 402: val_loss did not improve from 0.65313\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6878 - loss: 0.9100 - val_accuracy: 0.8045 - val_loss: 0.6559\n",
      "Epoch 403/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6834 - loss: 0.9279\n",
      "Epoch 403: val_loss improved from 0.65313 to 0.65140, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6834 - loss: 0.9275 - val_accuracy: 0.8089 - val_loss: 0.6514\n",
      "Epoch 404/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6855 - loss: 0.9124\n",
      "Epoch 404: val_loss did not improve from 0.65140\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6854 - loss: 0.9125 - val_accuracy: 0.8071 - val_loss: 0.6571\n",
      "Epoch 405/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6826 - loss: 0.9096\n",
      "Epoch 405: val_loss did not improve from 0.65140\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6826 - loss: 0.9097 - val_accuracy: 0.8104 - val_loss: 0.6527\n",
      "Epoch 406/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6863 - loss: 0.9141\n",
      "Epoch 406: val_loss did not improve from 0.65140\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6861 - loss: 0.9143 - val_accuracy: 0.8081 - val_loss: 0.6526\n",
      "Epoch 407/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6869 - loss: 0.9121\n",
      "Epoch 407: val_loss did not improve from 0.65140\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6869 - loss: 0.9121 - val_accuracy: 0.8094 - val_loss: 0.6521\n",
      "Epoch 408/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6795 - loss: 0.9157\n",
      "Epoch 408: val_loss improved from 0.65140 to 0.64964, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6795 - loss: 0.9157 - val_accuracy: 0.8102 - val_loss: 0.6496\n",
      "Epoch 409/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6877 - loss: 0.9127\n",
      "Epoch 409: val_loss improved from 0.64964 to 0.64863, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6877 - loss: 0.9127 - val_accuracy: 0.8100 - val_loss: 0.6486\n",
      "Epoch 410/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6864 - loss: 0.9139\n",
      "Epoch 410: val_loss improved from 0.64863 to 0.64723, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6864 - loss: 0.9139 - val_accuracy: 0.8107 - val_loss: 0.6472\n",
      "Epoch 411/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6736 - loss: 0.9234\n",
      "Epoch 411: val_loss improved from 0.64723 to 0.64612, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6738 - loss: 0.9232 - val_accuracy: 0.8144 - val_loss: 0.6461\n",
      "Epoch 412/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6845 - loss: 0.9073\n",
      "Epoch 412: val_loss did not improve from 0.64612\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6844 - loss: 0.9078 - val_accuracy: 0.8110 - val_loss: 0.6491\n",
      "Epoch 413/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6834 - loss: 0.9142\n",
      "Epoch 413: val_loss did not improve from 0.64612\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6834 - loss: 0.9142 - val_accuracy: 0.8113 - val_loss: 0.6466\n",
      "Epoch 414/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6845 - loss: 0.9199\n",
      "Epoch 414: val_loss did not improve from 0.64612\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6845 - loss: 0.9199 - val_accuracy: 0.8100 - val_loss: 0.6483\n",
      "Epoch 415/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6751 - loss: 0.9176\n",
      "Epoch 415: val_loss did not improve from 0.64612\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6752 - loss: 0.9176 - val_accuracy: 0.8128 - val_loss: 0.6473\n",
      "Epoch 416/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6790 - loss: 0.9218\n",
      "Epoch 416: val_loss did not improve from 0.64612\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6790 - loss: 0.9218 - val_accuracy: 0.8100 - val_loss: 0.6491\n",
      "Epoch 417/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6782 - loss: 0.9224\n",
      "Epoch 417: val_loss did not improve from 0.64612\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6782 - loss: 0.9224 - val_accuracy: 0.8050 - val_loss: 0.6508\n",
      "Epoch 418/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6836 - loss: 0.9142\n",
      "Epoch 418: val_loss did not improve from 0.64612\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6836 - loss: 0.9142 - val_accuracy: 0.8073 - val_loss: 0.6475\n",
      "Epoch 419/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6851 - loss: 0.9168\n",
      "Epoch 419: val_loss did not improve from 0.64612\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6851 - loss: 0.9168 - val_accuracy: 0.8099 - val_loss: 0.6499\n",
      "Epoch 420/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6925 - loss: 0.8999\n",
      "Epoch 420: val_loss did not improve from 0.64612\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6923 - loss: 0.9000 - val_accuracy: 0.8104 - val_loss: 0.6489\n",
      "Epoch 421/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6903 - loss: 0.9075\n",
      "Epoch 421: val_loss did not improve from 0.64612\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6902 - loss: 0.9074 - val_accuracy: 0.8115 - val_loss: 0.6464\n",
      "Epoch 422/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6936 - loss: 0.8979\n",
      "Epoch 422: val_loss improved from 0.64612 to 0.64604, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6936 - loss: 0.8979 - val_accuracy: 0.8096 - val_loss: 0.6460\n",
      "Epoch 423/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6802 - loss: 0.9120\n",
      "Epoch 423: val_loss improved from 0.64604 to 0.64156, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6803 - loss: 0.9120 - val_accuracy: 0.8131 - val_loss: 0.6416\n",
      "Epoch 424/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6815 - loss: 0.9162\n",
      "Epoch 424: val_loss did not improve from 0.64156\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6815 - loss: 0.9161 - val_accuracy: 0.8120 - val_loss: 0.6427\n",
      "Epoch 425/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6882 - loss: 0.9158\n",
      "Epoch 425: val_loss did not improve from 0.64156\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6882 - loss: 0.9158 - val_accuracy: 0.8091 - val_loss: 0.6447\n",
      "Epoch 426/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6823 - loss: 0.9131\n",
      "Epoch 426: val_loss improved from 0.64156 to 0.63916, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6823 - loss: 0.9130 - val_accuracy: 0.8157 - val_loss: 0.6392\n",
      "Epoch 427/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6864 - loss: 0.9013\n",
      "Epoch 427: val_loss did not improve from 0.63916\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6864 - loss: 0.9013 - val_accuracy: 0.8105 - val_loss: 0.6447\n",
      "Epoch 428/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6810 - loss: 0.9188\n",
      "Epoch 428: val_loss did not improve from 0.63916\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6810 - loss: 0.9187 - val_accuracy: 0.8112 - val_loss: 0.6400\n",
      "Epoch 429/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6968 - loss: 0.9062\n",
      "Epoch 429: val_loss did not improve from 0.63916\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6967 - loss: 0.9061 - val_accuracy: 0.8109 - val_loss: 0.6403\n",
      "Epoch 430/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6878 - loss: 0.9069\n",
      "Epoch 430: val_loss did not improve from 0.63916\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6878 - loss: 0.9069 - val_accuracy: 0.8104 - val_loss: 0.6421\n",
      "Epoch 431/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6928 - loss: 0.8990\n",
      "Epoch 431: val_loss did not improve from 0.63916\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6928 - loss: 0.8991 - val_accuracy: 0.8107 - val_loss: 0.6416\n",
      "Epoch 432/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6884 - loss: 0.9116\n",
      "Epoch 432: val_loss did not improve from 0.63916\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6884 - loss: 0.9115 - val_accuracy: 0.8126 - val_loss: 0.6401\n",
      "Epoch 433/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6780 - loss: 0.9192\n",
      "Epoch 433: val_loss did not improve from 0.63916\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6781 - loss: 0.9190 - val_accuracy: 0.8084 - val_loss: 0.6435\n",
      "Epoch 434/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6862 - loss: 0.8984\n",
      "Epoch 434: val_loss did not improve from 0.63916\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6862 - loss: 0.8986 - val_accuracy: 0.8092 - val_loss: 0.6419\n",
      "Epoch 435/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6797 - loss: 0.9196\n",
      "Epoch 435: val_loss did not improve from 0.63916\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6797 - loss: 0.9195 - val_accuracy: 0.8118 - val_loss: 0.6396\n",
      "Epoch 436/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6858 - loss: 0.9057\n",
      "Epoch 436: val_loss did not improve from 0.63916\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6858 - loss: 0.9057 - val_accuracy: 0.8113 - val_loss: 0.6417\n",
      "Epoch 437/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6901 - loss: 0.9026\n",
      "Epoch 437: val_loss improved from 0.63916 to 0.63769, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6901 - loss: 0.9026 - val_accuracy: 0.8147 - val_loss: 0.6377\n",
      "Epoch 438/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6843 - loss: 0.9065\n",
      "Epoch 438: val_loss improved from 0.63769 to 0.63644, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6844 - loss: 0.9066 - val_accuracy: 0.8157 - val_loss: 0.6364\n",
      "Epoch 439/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6801 - loss: 0.9131\n",
      "Epoch 439: val_loss did not improve from 0.63644\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6802 - loss: 0.9128 - val_accuracy: 0.8096 - val_loss: 0.6413\n",
      "Epoch 440/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6925 - loss: 0.8934\n",
      "Epoch 440: val_loss did not improve from 0.63644\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6924 - loss: 0.8935 - val_accuracy: 0.8105 - val_loss: 0.6389\n",
      "Epoch 441/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6895 - loss: 0.9072\n",
      "Epoch 441: val_loss did not improve from 0.63644\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6895 - loss: 0.9070 - val_accuracy: 0.8131 - val_loss: 0.6389\n",
      "Epoch 442/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6905 - loss: 0.8978\n",
      "Epoch 442: val_loss did not improve from 0.63644\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6906 - loss: 0.8977 - val_accuracy: 0.8130 - val_loss: 0.6365\n",
      "Epoch 443/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6895 - loss: 0.8975\n",
      "Epoch 443: val_loss did not improve from 0.63644\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6895 - loss: 0.8975 - val_accuracy: 0.8128 - val_loss: 0.6392\n",
      "Epoch 444/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6952 - loss: 0.8960\n",
      "Epoch 444: val_loss improved from 0.63644 to 0.63325, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6951 - loss: 0.8961 - val_accuracy: 0.8165 - val_loss: 0.6333\n",
      "Epoch 445/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6901 - loss: 0.8962\n",
      "Epoch 445: val_loss did not improve from 0.63325\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6900 - loss: 0.8964 - val_accuracy: 0.8152 - val_loss: 0.6333\n",
      "Epoch 446/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6841 - loss: 0.9119\n",
      "Epoch 446: val_loss did not improve from 0.63325\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6842 - loss: 0.9118 - val_accuracy: 0.8130 - val_loss: 0.6362\n",
      "Epoch 447/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6907 - loss: 0.8926\n",
      "Epoch 447: val_loss did not improve from 0.63325\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6907 - loss: 0.8927 - val_accuracy: 0.8134 - val_loss: 0.6351\n",
      "Epoch 448/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6918 - loss: 0.8960\n",
      "Epoch 448: val_loss improved from 0.63325 to 0.63263, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6918 - loss: 0.8960 - val_accuracy: 0.8162 - val_loss: 0.6326\n",
      "Epoch 449/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6911 - loss: 0.9038\n",
      "Epoch 449: val_loss did not improve from 0.63263\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6911 - loss: 0.9035 - val_accuracy: 0.8131 - val_loss: 0.6362\n",
      "Epoch 450/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6933 - loss: 0.8817\n",
      "Epoch 450: val_loss did not improve from 0.63263\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6932 - loss: 0.8820 - val_accuracy: 0.8130 - val_loss: 0.6370\n",
      "Epoch 451/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6852 - loss: 0.9087\n",
      "Epoch 451: val_loss improved from 0.63263 to 0.63157, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6854 - loss: 0.9084 - val_accuracy: 0.8154 - val_loss: 0.6316\n",
      "Epoch 452/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6838 - loss: 0.9015\n",
      "Epoch 452: val_loss did not improve from 0.63157\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6839 - loss: 0.9015 - val_accuracy: 0.8120 - val_loss: 0.6360\n",
      "Epoch 453/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6932 - loss: 0.8859\n",
      "Epoch 453: val_loss did not improve from 0.63157\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6930 - loss: 0.8863 - val_accuracy: 0.8155 - val_loss: 0.6317\n",
      "Epoch 454/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6892 - loss: 0.9058\n",
      "Epoch 454: val_loss did not improve from 0.63157\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6892 - loss: 0.9058 - val_accuracy: 0.8126 - val_loss: 0.6338\n",
      "Epoch 455/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6877 - loss: 0.9030\n",
      "Epoch 455: val_loss did not improve from 0.63157\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6877 - loss: 0.9029 - val_accuracy: 0.8141 - val_loss: 0.6342\n",
      "Epoch 456/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6917 - loss: 0.8974\n",
      "Epoch 456: val_loss improved from 0.63157 to 0.62896, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6915 - loss: 0.8975 - val_accuracy: 0.8170 - val_loss: 0.6290\n",
      "Epoch 457/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6873 - loss: 0.8998\n",
      "Epoch 457: val_loss did not improve from 0.62896\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6874 - loss: 0.8997 - val_accuracy: 0.8147 - val_loss: 0.6308\n",
      "Epoch 458/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6901 - loss: 0.9046\n",
      "Epoch 458: val_loss did not improve from 0.62896\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6900 - loss: 0.9046 - val_accuracy: 0.8130 - val_loss: 0.6327\n",
      "Epoch 459/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6810 - loss: 0.9124\n",
      "Epoch 459: val_loss did not improve from 0.62896\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6811 - loss: 0.9122 - val_accuracy: 0.8136 - val_loss: 0.6306\n",
      "Epoch 460/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.8965\n",
      "Epoch 460: val_loss did not improve from 0.62896\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.8965 - val_accuracy: 0.8141 - val_loss: 0.6306\n",
      "Epoch 461/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6946 - loss: 0.8913\n",
      "Epoch 461: val_loss did not improve from 0.62896\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6945 - loss: 0.8914 - val_accuracy: 0.8160 - val_loss: 0.6295\n",
      "Epoch 462/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6876 - loss: 0.8988\n",
      "Epoch 462: val_loss did not improve from 0.62896\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6876 - loss: 0.8988 - val_accuracy: 0.8144 - val_loss: 0.6321\n",
      "Epoch 463/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6885 - loss: 0.8987\n",
      "Epoch 463: val_loss did not improve from 0.62896\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6885 - loss: 0.8987 - val_accuracy: 0.8136 - val_loss: 0.6311\n",
      "Epoch 464/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6860 - loss: 0.9026\n",
      "Epoch 464: val_loss did not improve from 0.62896\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6860 - loss: 0.9026 - val_accuracy: 0.8131 - val_loss: 0.6299\n",
      "Epoch 465/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6975 - loss: 0.8892\n",
      "Epoch 465: val_loss did not improve from 0.62896\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6974 - loss: 0.8892 - val_accuracy: 0.8164 - val_loss: 0.6300\n",
      "Epoch 466/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6869 - loss: 0.8986\n",
      "Epoch 466: val_loss improved from 0.62896 to 0.62893, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6869 - loss: 0.8986 - val_accuracy: 0.8154 - val_loss: 0.6289\n",
      "Epoch 467/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6850 - loss: 0.8999\n",
      "Epoch 467: val_loss did not improve from 0.62893\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6851 - loss: 0.8999 - val_accuracy: 0.8136 - val_loss: 0.6309\n",
      "Epoch 468/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6864 - loss: 0.8975\n",
      "Epoch 468: val_loss did not improve from 0.62893\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6866 - loss: 0.8971 - val_accuracy: 0.8144 - val_loss: 0.6293\n",
      "Epoch 469/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6879 - loss: 0.8928\n",
      "Epoch 469: val_loss improved from 0.62893 to 0.62791, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6879 - loss: 0.8928 - val_accuracy: 0.8165 - val_loss: 0.6279\n",
      "Epoch 470/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6838 - loss: 0.9066\n",
      "Epoch 470: val_loss improved from 0.62791 to 0.62610, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6840 - loss: 0.9063 - val_accuracy: 0.8152 - val_loss: 0.6261\n",
      "Epoch 471/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6918 - loss: 0.8848\n",
      "Epoch 471: val_loss did not improve from 0.62610\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6918 - loss: 0.8848 - val_accuracy: 0.8045 - val_loss: 0.6369\n",
      "Epoch 472/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6851 - loss: 0.9083\n",
      "Epoch 472: val_loss improved from 0.62610 to 0.62452, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6852 - loss: 0.9082 - val_accuracy: 0.8151 - val_loss: 0.6245\n",
      "Epoch 473/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6938 - loss: 0.8890\n",
      "Epoch 473: val_loss did not improve from 0.62452\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6937 - loss: 0.8891 - val_accuracy: 0.8185 - val_loss: 0.6255\n",
      "Epoch 474/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6907 - loss: 0.8850\n",
      "Epoch 474: val_loss improved from 0.62452 to 0.62436, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6906 - loss: 0.8851 - val_accuracy: 0.8162 - val_loss: 0.6244\n",
      "Epoch 475/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6965 - loss: 0.8775\n",
      "Epoch 475: val_loss improved from 0.62436 to 0.62219, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6964 - loss: 0.8778 - val_accuracy: 0.8185 - val_loss: 0.6222\n",
      "Epoch 476/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6914 - loss: 0.8883\n",
      "Epoch 476: val_loss did not improve from 0.62219\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6915 - loss: 0.8882 - val_accuracy: 0.8125 - val_loss: 0.6263\n",
      "Epoch 477/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6933 - loss: 0.8903\n",
      "Epoch 477: val_loss did not improve from 0.62219\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6933 - loss: 0.8903 - val_accuracy: 0.8152 - val_loss: 0.6241\n",
      "Epoch 478/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6908 - loss: 0.8953\n",
      "Epoch 478: val_loss did not improve from 0.62219\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6908 - loss: 0.8954 - val_accuracy: 0.8172 - val_loss: 0.6249\n",
      "Epoch 479/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6938 - loss: 0.8882\n",
      "Epoch 479: val_loss improved from 0.62219 to 0.62136, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6938 - loss: 0.8882 - val_accuracy: 0.8175 - val_loss: 0.6214\n",
      "Epoch 480/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6931 - loss: 0.8805\n",
      "Epoch 480: val_loss did not improve from 0.62136\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6931 - loss: 0.8806 - val_accuracy: 0.8170 - val_loss: 0.6233\n",
      "Epoch 481/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6847 - loss: 0.8965\n",
      "Epoch 481: val_loss did not improve from 0.62136\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6848 - loss: 0.8963 - val_accuracy: 0.8188 - val_loss: 0.6219\n",
      "Epoch 482/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6954 - loss: 0.8912\n",
      "Epoch 482: val_loss did not improve from 0.62136\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6953 - loss: 0.8913 - val_accuracy: 0.8178 - val_loss: 0.6221\n",
      "Epoch 483/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6910 - loss: 0.9026\n",
      "Epoch 483: val_loss did not improve from 0.62136\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6909 - loss: 0.9022 - val_accuracy: 0.8147 - val_loss: 0.6227\n",
      "Epoch 484/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6926 - loss: 0.8915\n",
      "Epoch 484: val_loss did not improve from 0.62136\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6925 - loss: 0.8914 - val_accuracy: 0.8131 - val_loss: 0.6263\n",
      "Epoch 485/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6925 - loss: 0.8915\n",
      "Epoch 485: val_loss did not improve from 0.62136\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6924 - loss: 0.8915 - val_accuracy: 0.8168 - val_loss: 0.6214\n",
      "Epoch 486/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6881 - loss: 0.8963\n",
      "Epoch 486: val_loss did not improve from 0.62136\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6883 - loss: 0.8960 - val_accuracy: 0.8188 - val_loss: 0.6220\n",
      "Epoch 487/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6889 - loss: 0.8872\n",
      "Epoch 487: val_loss improved from 0.62136 to 0.61947, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6888 - loss: 0.8874 - val_accuracy: 0.8173 - val_loss: 0.6195\n",
      "Epoch 488/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6870 - loss: 0.9017\n",
      "Epoch 488: val_loss did not improve from 0.61947\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6870 - loss: 0.9016 - val_accuracy: 0.8126 - val_loss: 0.6224\n",
      "Epoch 489/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6955 - loss: 0.8839\n",
      "Epoch 489: val_loss did not improve from 0.61947\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6954 - loss: 0.8840 - val_accuracy: 0.8117 - val_loss: 0.6258\n",
      "Epoch 490/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6932 - loss: 0.8849\n",
      "Epoch 490: val_loss did not improve from 0.61947\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6930 - loss: 0.8852 - val_accuracy: 0.8162 - val_loss: 0.6211\n",
      "Epoch 491/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6860 - loss: 0.8997\n",
      "Epoch 491: val_loss improved from 0.61947 to 0.61933, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6861 - loss: 0.8994 - val_accuracy: 0.8173 - val_loss: 0.6193\n",
      "Epoch 492/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6883 - loss: 0.8997\n",
      "Epoch 492: val_loss improved from 0.61933 to 0.61761, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6884 - loss: 0.8995 - val_accuracy: 0.8183 - val_loss: 0.6176\n",
      "Epoch 493/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6911 - loss: 0.8832\n",
      "Epoch 493: val_loss did not improve from 0.61761\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6912 - loss: 0.8831 - val_accuracy: 0.8196 - val_loss: 0.6189\n",
      "Epoch 494/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6935 - loss: 0.8902\n",
      "Epoch 494: val_loss improved from 0.61761 to 0.61571, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6935 - loss: 0.8902 - val_accuracy: 0.8198 - val_loss: 0.6157\n",
      "Epoch 495/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6924 - loss: 0.8818\n",
      "Epoch 495: val_loss did not improve from 0.61571\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6923 - loss: 0.8820 - val_accuracy: 0.8120 - val_loss: 0.6225\n",
      "Epoch 496/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6960 - loss: 0.8872\n",
      "Epoch 496: val_loss did not improve from 0.61571\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6960 - loss: 0.8871 - val_accuracy: 0.8172 - val_loss: 0.6209\n",
      "Epoch 497/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6926 - loss: 0.8834\n",
      "Epoch 497: val_loss improved from 0.61571 to 0.61463, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6925 - loss: 0.8835 - val_accuracy: 0.8194 - val_loss: 0.6146\n",
      "Epoch 498/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6954 - loss: 0.8793\n",
      "Epoch 498: val_loss did not improve from 0.61463\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6954 - loss: 0.8794 - val_accuracy: 0.8159 - val_loss: 0.6196\n",
      "Epoch 499/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6950 - loss: 0.8860\n",
      "Epoch 499: val_loss did not improve from 0.61463\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6950 - loss: 0.8860 - val_accuracy: 0.8155 - val_loss: 0.6217\n",
      "Epoch 500/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7001 - loss: 0.8694\n",
      "Epoch 500: val_loss did not improve from 0.61463\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7000 - loss: 0.8695 - val_accuracy: 0.8188 - val_loss: 0.6156\n",
      "Epoch 501/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6953 - loss: 0.8753\n",
      "Epoch 501: val_loss did not improve from 0.61463\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6953 - loss: 0.8753 - val_accuracy: 0.8165 - val_loss: 0.6169\n",
      "Epoch 502/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6935 - loss: 0.8799\n",
      "Epoch 502: val_loss did not improve from 0.61463\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6935 - loss: 0.8798 - val_accuracy: 0.8202 - val_loss: 0.6183\n",
      "Epoch 503/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6945 - loss: 0.8818\n",
      "Epoch 503: val_loss did not improve from 0.61463\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6946 - loss: 0.8815 - val_accuracy: 0.8162 - val_loss: 0.6202\n",
      "Epoch 504/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6995 - loss: 0.8697\n",
      "Epoch 504: val_loss improved from 0.61463 to 0.61392, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6993 - loss: 0.8700 - val_accuracy: 0.8215 - val_loss: 0.6139\n",
      "Epoch 505/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6942 - loss: 0.8821\n",
      "Epoch 505: val_loss did not improve from 0.61392\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6941 - loss: 0.8822 - val_accuracy: 0.8173 - val_loss: 0.6190\n",
      "Epoch 506/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6867 - loss: 0.8962\n",
      "Epoch 506: val_loss did not improve from 0.61392\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6867 - loss: 0.8961 - val_accuracy: 0.8212 - val_loss: 0.6149\n",
      "Epoch 507/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6945 - loss: 0.8883\n",
      "Epoch 507: val_loss did not improve from 0.61392\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6945 - loss: 0.8882 - val_accuracy: 0.8178 - val_loss: 0.6169\n",
      "Epoch 508/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6947 - loss: 0.8740\n",
      "Epoch 508: val_loss improved from 0.61392 to 0.61390, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6947 - loss: 0.8740 - val_accuracy: 0.8202 - val_loss: 0.6139\n",
      "Epoch 509/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6906 - loss: 0.8876\n",
      "Epoch 509: val_loss improved from 0.61390 to 0.61293, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6907 - loss: 0.8875 - val_accuracy: 0.8193 - val_loss: 0.6129\n",
      "Epoch 510/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6939 - loss: 0.8833\n",
      "Epoch 510: val_loss did not improve from 0.61293\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6939 - loss: 0.8833 - val_accuracy: 0.8181 - val_loss: 0.6179\n",
      "Epoch 511/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7015 - loss: 0.8674\n",
      "Epoch 511: val_loss improved from 0.61293 to 0.61202, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7015 - loss: 0.8675 - val_accuracy: 0.8207 - val_loss: 0.6120\n",
      "Epoch 512/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6969 - loss: 0.8640\n",
      "Epoch 512: val_loss did not improve from 0.61202\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6968 - loss: 0.8640 - val_accuracy: 0.8188 - val_loss: 0.6150\n",
      "Epoch 513/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6915 - loss: 0.8824\n",
      "Epoch 513: val_loss improved from 0.61202 to 0.61117, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6915 - loss: 0.8824 - val_accuracy: 0.8232 - val_loss: 0.6112\n",
      "Epoch 514/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6899 - loss: 0.8849\n",
      "Epoch 514: val_loss improved from 0.61117 to 0.60989, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6899 - loss: 0.8849 - val_accuracy: 0.8217 - val_loss: 0.6099\n",
      "Epoch 515/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6915 - loss: 0.8874\n",
      "Epoch 515: val_loss did not improve from 0.60989\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6914 - loss: 0.8873 - val_accuracy: 0.8168 - val_loss: 0.6129\n",
      "Epoch 516/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6888 - loss: 0.8853\n",
      "Epoch 516: val_loss did not improve from 0.60989\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6888 - loss: 0.8853 - val_accuracy: 0.8198 - val_loss: 0.6126\n",
      "Epoch 517/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6996 - loss: 0.8708\n",
      "Epoch 517: val_loss improved from 0.60989 to 0.60901, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6996 - loss: 0.8708 - val_accuracy: 0.8206 - val_loss: 0.6090\n",
      "Epoch 518/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6996 - loss: 0.8752\n",
      "Epoch 518: val_loss did not improve from 0.60901\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6996 - loss: 0.8752 - val_accuracy: 0.8196 - val_loss: 0.6118\n",
      "Epoch 519/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6942 - loss: 0.8792\n",
      "Epoch 519: val_loss did not improve from 0.60901\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6943 - loss: 0.8790 - val_accuracy: 0.8219 - val_loss: 0.6099\n",
      "Epoch 520/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6887 - loss: 0.8749\n",
      "Epoch 520: val_loss did not improve from 0.60901\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6887 - loss: 0.8750 - val_accuracy: 0.8236 - val_loss: 0.6101\n",
      "Epoch 521/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6986 - loss: 0.8687\n",
      "Epoch 521: val_loss did not improve from 0.60901\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6985 - loss: 0.8689 - val_accuracy: 0.8160 - val_loss: 0.6148\n",
      "Epoch 522/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6932 - loss: 0.8747\n",
      "Epoch 522: val_loss did not improve from 0.60901\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6932 - loss: 0.8747 - val_accuracy: 0.8220 - val_loss: 0.6100\n",
      "Epoch 523/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7060 - loss: 0.8593\n",
      "Epoch 523: val_loss improved from 0.60901 to 0.60622, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7060 - loss: 0.8593 - val_accuracy: 0.8251 - val_loss: 0.6062\n",
      "Epoch 524/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6917 - loss: 0.8847\n",
      "Epoch 524: val_loss did not improve from 0.60622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6917 - loss: 0.8847 - val_accuracy: 0.8196 - val_loss: 0.6110\n",
      "Epoch 525/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6891 - loss: 0.8889\n",
      "Epoch 525: val_loss did not improve from 0.60622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6891 - loss: 0.8889 - val_accuracy: 0.8162 - val_loss: 0.6132\n",
      "Epoch 526/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6989 - loss: 0.8770\n",
      "Epoch 526: val_loss did not improve from 0.60622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6988 - loss: 0.8770 - val_accuracy: 0.8214 - val_loss: 0.6073\n",
      "Epoch 527/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7001 - loss: 0.8589\n",
      "Epoch 527: val_loss did not improve from 0.60622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7000 - loss: 0.8592 - val_accuracy: 0.8186 - val_loss: 0.6097\n",
      "Epoch 528/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6877 - loss: 0.8847\n",
      "Epoch 528: val_loss did not improve from 0.60622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6877 - loss: 0.8847 - val_accuracy: 0.8173 - val_loss: 0.6105\n",
      "Epoch 529/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.8657\n",
      "Epoch 529: val_loss did not improve from 0.60622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.8657 - val_accuracy: 0.8194 - val_loss: 0.6107\n",
      "Epoch 530/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6987 - loss: 0.8699\n",
      "Epoch 530: val_loss did not improve from 0.60622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6986 - loss: 0.8701 - val_accuracy: 0.8199 - val_loss: 0.6089\n",
      "Epoch 531/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7009 - loss: 0.8613\n",
      "Epoch 531: val_loss did not improve from 0.60622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7009 - loss: 0.8613 - val_accuracy: 0.8212 - val_loss: 0.6083\n",
      "Epoch 532/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6989 - loss: 0.8609\n",
      "Epoch 532: val_loss improved from 0.60622 to 0.60604, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6989 - loss: 0.8610 - val_accuracy: 0.8228 - val_loss: 0.6060\n",
      "Epoch 533/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6941 - loss: 0.8729\n",
      "Epoch 533: val_loss did not improve from 0.60604\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6941 - loss: 0.8730 - val_accuracy: 0.8201 - val_loss: 0.6087\n",
      "Epoch 534/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7034 - loss: 0.8572\n",
      "Epoch 534: val_loss did not improve from 0.60604\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7034 - loss: 0.8572 - val_accuracy: 0.8193 - val_loss: 0.6080\n",
      "Epoch 535/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6925 - loss: 0.8730\n",
      "Epoch 535: val_loss did not improve from 0.60604\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6925 - loss: 0.8731 - val_accuracy: 0.8181 - val_loss: 0.6076\n",
      "Epoch 536/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6876 - loss: 0.8880\n",
      "Epoch 536: val_loss did not improve from 0.60604\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6877 - loss: 0.8879 - val_accuracy: 0.8215 - val_loss: 0.6078\n",
      "Epoch 537/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6977 - loss: 0.8646\n",
      "Epoch 537: val_loss did not improve from 0.60604\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6977 - loss: 0.8646 - val_accuracy: 0.8201 - val_loss: 0.6061\n",
      "Epoch 538/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7058 - loss: 0.8617\n",
      "Epoch 538: val_loss improved from 0.60604 to 0.60493, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7058 - loss: 0.8618 - val_accuracy: 0.8217 - val_loss: 0.6049\n",
      "Epoch 539/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6919 - loss: 0.8828\n",
      "Epoch 539: val_loss did not improve from 0.60493\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6919 - loss: 0.8828 - val_accuracy: 0.8199 - val_loss: 0.6084\n",
      "Epoch 540/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7006 - loss: 0.8703\n",
      "Epoch 540: val_loss improved from 0.60493 to 0.60451, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7006 - loss: 0.8703 - val_accuracy: 0.8227 - val_loss: 0.6045\n",
      "Epoch 541/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7012 - loss: 0.8578\n",
      "Epoch 541: val_loss did not improve from 0.60451\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7012 - loss: 0.8580 - val_accuracy: 0.8188 - val_loss: 0.6090\n",
      "Epoch 542/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6983 - loss: 0.8673\n",
      "Epoch 542: val_loss did not improve from 0.60451\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6982 - loss: 0.8674 - val_accuracy: 0.8206 - val_loss: 0.6103\n",
      "Epoch 543/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6934 - loss: 0.8720\n",
      "Epoch 543: val_loss did not improve from 0.60451\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6934 - loss: 0.8720 - val_accuracy: 0.8214 - val_loss: 0.6083\n",
      "Epoch 544/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6922 - loss: 0.8803\n",
      "Epoch 544: val_loss improved from 0.60451 to 0.60238, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6923 - loss: 0.8801 - val_accuracy: 0.8241 - val_loss: 0.6024\n",
      "Epoch 545/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6928 - loss: 0.8795\n",
      "Epoch 545: val_loss did not improve from 0.60238\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6929 - loss: 0.8793 - val_accuracy: 0.8238 - val_loss: 0.6048\n",
      "Epoch 546/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6919 - loss: 0.8778\n",
      "Epoch 546: val_loss did not improve from 0.60238\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6920 - loss: 0.8777 - val_accuracy: 0.8236 - val_loss: 0.6027\n",
      "Epoch 547/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6914 - loss: 0.8824\n",
      "Epoch 547: val_loss did not improve from 0.60238\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6914 - loss: 0.8823 - val_accuracy: 0.8189 - val_loss: 0.6075\n",
      "Epoch 548/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6960 - loss: 0.8801\n",
      "Epoch 548: val_loss did not improve from 0.60238\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6960 - loss: 0.8799 - val_accuracy: 0.8211 - val_loss: 0.6069\n",
      "Epoch 549/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7037 - loss: 0.8617\n",
      "Epoch 549: val_loss did not improve from 0.60238\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7036 - loss: 0.8618 - val_accuracy: 0.8207 - val_loss: 0.6059\n",
      "Epoch 550/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6961 - loss: 0.8714\n",
      "Epoch 550: val_loss improved from 0.60238 to 0.59950, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6961 - loss: 0.8714 - val_accuracy: 0.8251 - val_loss: 0.5995\n",
      "Epoch 551/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6965 - loss: 0.8661\n",
      "Epoch 551: val_loss did not improve from 0.59950\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6966 - loss: 0.8661 - val_accuracy: 0.8223 - val_loss: 0.6008\n",
      "Epoch 552/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6985 - loss: 0.8769\n",
      "Epoch 552: val_loss did not improve from 0.59950\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6985 - loss: 0.8769 - val_accuracy: 0.8243 - val_loss: 0.6054\n",
      "Epoch 553/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6957 - loss: 0.8799\n",
      "Epoch 553: val_loss did not improve from 0.59950\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6958 - loss: 0.8796 - val_accuracy: 0.8228 - val_loss: 0.6060\n",
      "Epoch 554/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6967 - loss: 0.8618\n",
      "Epoch 554: val_loss did not improve from 0.59950\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6966 - loss: 0.8622 - val_accuracy: 0.8230 - val_loss: 0.6022\n",
      "Epoch 555/1500\n",
      "\u001b[1m740/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6907 - loss: 0.8834\n",
      "Epoch 555: val_loss did not improve from 0.59950\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6909 - loss: 0.8830 - val_accuracy: 0.8215 - val_loss: 0.6039\n",
      "Epoch 556/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6968 - loss: 0.8713\n",
      "Epoch 556: val_loss did not improve from 0.59950\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6968 - loss: 0.8714 - val_accuracy: 0.8191 - val_loss: 0.6065\n",
      "Epoch 557/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6940 - loss: 0.8660\n",
      "Epoch 557: val_loss improved from 0.59950 to 0.59921, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6940 - loss: 0.8661 - val_accuracy: 0.8232 - val_loss: 0.5992\n",
      "Epoch 558/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6962 - loss: 0.8695\n",
      "Epoch 558: val_loss did not improve from 0.59921\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6962 - loss: 0.8694 - val_accuracy: 0.8214 - val_loss: 0.6001\n",
      "Epoch 559/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6971 - loss: 0.8697\n",
      "Epoch 559: val_loss did not improve from 0.59921\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6971 - loss: 0.8697 - val_accuracy: 0.8170 - val_loss: 0.6086\n",
      "Epoch 560/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7054 - loss: 0.8603\n",
      "Epoch 560: val_loss did not improve from 0.59921\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7053 - loss: 0.8603 - val_accuracy: 0.8201 - val_loss: 0.6035\n",
      "Epoch 561/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7028 - loss: 0.8675\n",
      "Epoch 561: val_loss did not improve from 0.59921\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7028 - loss: 0.8673 - val_accuracy: 0.8215 - val_loss: 0.6011\n",
      "Epoch 562/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6992 - loss: 0.8637\n",
      "Epoch 562: val_loss did not improve from 0.59921\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6992 - loss: 0.8637 - val_accuracy: 0.8209 - val_loss: 0.6045\n",
      "Epoch 563/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6970 - loss: 0.8783\n",
      "Epoch 563: val_loss did not improve from 0.59921\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6970 - loss: 0.8781 - val_accuracy: 0.8215 - val_loss: 0.6025\n",
      "Epoch 564/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6909 - loss: 0.8627\n",
      "Epoch 564: val_loss did not improve from 0.59921\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6909 - loss: 0.8628 - val_accuracy: 0.8240 - val_loss: 0.6011\n",
      "Epoch 565/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6952 - loss: 0.8704\n",
      "Epoch 565: val_loss did not improve from 0.59921\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6951 - loss: 0.8703 - val_accuracy: 0.8211 - val_loss: 0.6011\n",
      "Epoch 566/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7007 - loss: 0.8630\n",
      "Epoch 566: val_loss did not improve from 0.59921\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7007 - loss: 0.8631 - val_accuracy: 0.8222 - val_loss: 0.6011\n",
      "Epoch 567/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6984 - loss: 0.8667\n",
      "Epoch 567: val_loss did not improve from 0.59921\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6985 - loss: 0.8665 - val_accuracy: 0.8211 - val_loss: 0.6035\n",
      "Epoch 568/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6970 - loss: 0.8639\n",
      "Epoch 568: val_loss improved from 0.59921 to 0.59845, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6970 - loss: 0.8640 - val_accuracy: 0.8240 - val_loss: 0.5984\n",
      "Epoch 569/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6958 - loss: 0.8650\n",
      "Epoch 569: val_loss improved from 0.59845 to 0.59720, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6959 - loss: 0.8650 - val_accuracy: 0.8253 - val_loss: 0.5972\n",
      "Epoch 570/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6939 - loss: 0.8753\n",
      "Epoch 570: val_loss did not improve from 0.59720\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6942 - loss: 0.8748 - val_accuracy: 0.8211 - val_loss: 0.6015\n",
      "Epoch 571/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7001 - loss: 0.8578\n",
      "Epoch 571: val_loss did not improve from 0.59720\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7001 - loss: 0.8578 - val_accuracy: 0.8246 - val_loss: 0.5994\n",
      "Epoch 572/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6993 - loss: 0.8651\n",
      "Epoch 572: val_loss improved from 0.59720 to 0.59639, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6993 - loss: 0.8650 - val_accuracy: 0.8240 - val_loss: 0.5964\n",
      "Epoch 573/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7058 - loss: 0.8589\n",
      "Epoch 573: val_loss did not improve from 0.59639\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7058 - loss: 0.8587 - val_accuracy: 0.8240 - val_loss: 0.5989\n",
      "Epoch 574/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6987 - loss: 0.8680\n",
      "Epoch 574: val_loss improved from 0.59639 to 0.59443, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6987 - loss: 0.8680 - val_accuracy: 0.8249 - val_loss: 0.5944\n",
      "Epoch 575/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6957 - loss: 0.8613\n",
      "Epoch 575: val_loss did not improve from 0.59443\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6956 - loss: 0.8614 - val_accuracy: 0.8238 - val_loss: 0.5962\n",
      "Epoch 576/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7029 - loss: 0.8583\n",
      "Epoch 576: val_loss did not improve from 0.59443\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7029 - loss: 0.8583 - val_accuracy: 0.8240 - val_loss: 0.5974\n",
      "Epoch 577/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6976 - loss: 0.8657\n",
      "Epoch 577: val_loss did not improve from 0.59443\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6976 - loss: 0.8656 - val_accuracy: 0.8222 - val_loss: 0.5969\n",
      "Epoch 578/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7026 - loss: 0.8623\n",
      "Epoch 578: val_loss did not improve from 0.59443\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7027 - loss: 0.8621 - val_accuracy: 0.8228 - val_loss: 0.5982\n",
      "Epoch 579/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7020 - loss: 0.8678\n",
      "Epoch 579: val_loss did not improve from 0.59443\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7019 - loss: 0.8677 - val_accuracy: 0.8246 - val_loss: 0.5964\n",
      "Epoch 580/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6991 - loss: 0.8588\n",
      "Epoch 580: val_loss did not improve from 0.59443\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6991 - loss: 0.8588 - val_accuracy: 0.8267 - val_loss: 0.5962\n",
      "Epoch 581/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7001 - loss: 0.8611\n",
      "Epoch 581: val_loss improved from 0.59443 to 0.59392, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7001 - loss: 0.8612 - val_accuracy: 0.8267 - val_loss: 0.5939\n",
      "Epoch 582/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6954 - loss: 0.8784\n",
      "Epoch 582: val_loss did not improve from 0.59392\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6957 - loss: 0.8777 - val_accuracy: 0.8275 - val_loss: 0.5965\n",
      "Epoch 583/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7012 - loss: 0.8490\n",
      "Epoch 583: val_loss did not improve from 0.59392\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7012 - loss: 0.8493 - val_accuracy: 0.8233 - val_loss: 0.5965\n",
      "Epoch 584/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7009 - loss: 0.8594\n",
      "Epoch 584: val_loss did not improve from 0.59392\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7010 - loss: 0.8593 - val_accuracy: 0.8257 - val_loss: 0.5962\n",
      "Epoch 585/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6988 - loss: 0.8648\n",
      "Epoch 585: val_loss did not improve from 0.59392\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6988 - loss: 0.8647 - val_accuracy: 0.8261 - val_loss: 0.5949\n",
      "Epoch 586/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6978 - loss: 0.8616\n",
      "Epoch 586: val_loss did not improve from 0.59392\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6980 - loss: 0.8613 - val_accuracy: 0.8214 - val_loss: 0.5986\n",
      "Epoch 587/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6995 - loss: 0.8658\n",
      "Epoch 587: val_loss did not improve from 0.59392\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6996 - loss: 0.8656 - val_accuracy: 0.8246 - val_loss: 0.5950\n",
      "Epoch 588/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7010 - loss: 0.8636\n",
      "Epoch 588: val_loss did not improve from 0.59392\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7010 - loss: 0.8635 - val_accuracy: 0.8235 - val_loss: 0.5963\n",
      "Epoch 589/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6986 - loss: 0.8702\n",
      "Epoch 589: val_loss did not improve from 0.59392\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6986 - loss: 0.8702 - val_accuracy: 0.8240 - val_loss: 0.5947\n",
      "Epoch 590/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6998 - loss: 0.8544\n",
      "Epoch 590: val_loss improved from 0.59392 to 0.59316, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6999 - loss: 0.8544 - val_accuracy: 0.8253 - val_loss: 0.5932\n",
      "Epoch 591/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7000 - loss: 0.8567\n",
      "Epoch 591: val_loss improved from 0.59316 to 0.58941, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7000 - loss: 0.8566 - val_accuracy: 0.8274 - val_loss: 0.5894\n",
      "Epoch 592/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7012 - loss: 0.8628\n",
      "Epoch 592: val_loss did not improve from 0.58941\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7012 - loss: 0.8627 - val_accuracy: 0.8269 - val_loss: 0.5940\n",
      "Epoch 593/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6996 - loss: 0.8597\n",
      "Epoch 593: val_loss did not improve from 0.58941\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6996 - loss: 0.8596 - val_accuracy: 0.8275 - val_loss: 0.5941\n",
      "Epoch 594/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6989 - loss: 0.8559\n",
      "Epoch 594: val_loss did not improve from 0.58941\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6989 - loss: 0.8559 - val_accuracy: 0.8270 - val_loss: 0.5915\n",
      "Epoch 595/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6980 - loss: 0.8455\n",
      "Epoch 595: val_loss did not improve from 0.58941\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6980 - loss: 0.8456 - val_accuracy: 0.8266 - val_loss: 0.5928\n",
      "Epoch 596/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6988 - loss: 0.8607\n",
      "Epoch 596: val_loss did not improve from 0.58941\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6989 - loss: 0.8607 - val_accuracy: 0.8256 - val_loss: 0.5930\n",
      "Epoch 597/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7007 - loss: 0.8452\n",
      "Epoch 597: val_loss did not improve from 0.58941\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7007 - loss: 0.8453 - val_accuracy: 0.8270 - val_loss: 0.5926\n",
      "Epoch 598/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7015 - loss: 0.8552\n",
      "Epoch 598: val_loss did not improve from 0.58941\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7015 - loss: 0.8550 - val_accuracy: 0.8225 - val_loss: 0.5934\n",
      "Epoch 599/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7074 - loss: 0.8531\n",
      "Epoch 599: val_loss did not improve from 0.58941\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7073 - loss: 0.8532 - val_accuracy: 0.8274 - val_loss: 0.5910\n",
      "Epoch 600/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6983 - loss: 0.8578\n",
      "Epoch 600: val_loss did not improve from 0.58941\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6984 - loss: 0.8577 - val_accuracy: 0.8280 - val_loss: 0.5923\n",
      "Epoch 601/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6959 - loss: 0.8691\n",
      "Epoch 601: val_loss did not improve from 0.58941\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6959 - loss: 0.8690 - val_accuracy: 0.8288 - val_loss: 0.5899\n",
      "Epoch 602/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7060 - loss: 0.8485\n",
      "Epoch 602: val_loss did not improve from 0.58941\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7059 - loss: 0.8487 - val_accuracy: 0.8249 - val_loss: 0.5923\n",
      "Epoch 603/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6992 - loss: 0.8679\n",
      "Epoch 603: val_loss improved from 0.58941 to 0.58622, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6992 - loss: 0.8678 - val_accuracy: 0.8269 - val_loss: 0.5862\n",
      "Epoch 604/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7063 - loss: 0.8491\n",
      "Epoch 604: val_loss did not improve from 0.58622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7063 - loss: 0.8491 - val_accuracy: 0.8253 - val_loss: 0.5951\n",
      "Epoch 605/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7059 - loss: 0.8408\n",
      "Epoch 605: val_loss did not improve from 0.58622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7059 - loss: 0.8408 - val_accuracy: 0.8249 - val_loss: 0.5907\n",
      "Epoch 606/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7040 - loss: 0.8538\n",
      "Epoch 606: val_loss did not improve from 0.58622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7040 - loss: 0.8537 - val_accuracy: 0.8264 - val_loss: 0.5894\n",
      "Epoch 607/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7014 - loss: 0.8574\n",
      "Epoch 607: val_loss did not improve from 0.58622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7015 - loss: 0.8574 - val_accuracy: 0.8259 - val_loss: 0.5897\n",
      "Epoch 608/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7065 - loss: 0.8442\n",
      "Epoch 608: val_loss did not improve from 0.58622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7064 - loss: 0.8444 - val_accuracy: 0.8251 - val_loss: 0.5924\n",
      "Epoch 609/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7080 - loss: 0.8426\n",
      "Epoch 609: val_loss did not improve from 0.58622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7079 - loss: 0.8428 - val_accuracy: 0.8301 - val_loss: 0.5891\n",
      "Epoch 610/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7018 - loss: 0.8498\n",
      "Epoch 610: val_loss did not improve from 0.58622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7018 - loss: 0.8500 - val_accuracy: 0.8267 - val_loss: 0.5886\n",
      "Epoch 611/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7052 - loss: 0.8529\n",
      "Epoch 611: val_loss did not improve from 0.58622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7052 - loss: 0.8529 - val_accuracy: 0.8245 - val_loss: 0.5891\n",
      "Epoch 612/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7008 - loss: 0.8560\n",
      "Epoch 612: val_loss did not improve from 0.58622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7008 - loss: 0.8559 - val_accuracy: 0.8270 - val_loss: 0.5882\n",
      "Epoch 613/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7004 - loss: 0.8398\n",
      "Epoch 613: val_loss did not improve from 0.58622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7004 - loss: 0.8398 - val_accuracy: 0.8267 - val_loss: 0.5893\n",
      "Epoch 614/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7000 - loss: 0.8558\n",
      "Epoch 614: val_loss did not improve from 0.58622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7000 - loss: 0.8558 - val_accuracy: 0.8264 - val_loss: 0.5868\n",
      "Epoch 615/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7043 - loss: 0.8498\n",
      "Epoch 615: val_loss improved from 0.58622 to 0.58351, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7043 - loss: 0.8499 - val_accuracy: 0.8266 - val_loss: 0.5835\n",
      "Epoch 616/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7037 - loss: 0.8553\n",
      "Epoch 616: val_loss did not improve from 0.58351\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7037 - loss: 0.8553 - val_accuracy: 0.8262 - val_loss: 0.5874\n",
      "Epoch 617/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7010 - loss: 0.8676\n",
      "Epoch 617: val_loss did not improve from 0.58351\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7010 - loss: 0.8675 - val_accuracy: 0.8275 - val_loss: 0.5853\n",
      "Epoch 618/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7041 - loss: 0.8584\n",
      "Epoch 618: val_loss did not improve from 0.58351\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7041 - loss: 0.8582 - val_accuracy: 0.8280 - val_loss: 0.5859\n",
      "Epoch 619/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7030 - loss: 0.8543\n",
      "Epoch 619: val_loss did not improve from 0.58351\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7030 - loss: 0.8542 - val_accuracy: 0.8285 - val_loss: 0.5849\n",
      "Epoch 620/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7060 - loss: 0.8389\n",
      "Epoch 620: val_loss did not improve from 0.58351\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7059 - loss: 0.8391 - val_accuracy: 0.8266 - val_loss: 0.5840\n",
      "Epoch 621/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6996 - loss: 0.8503\n",
      "Epoch 621: val_loss did not improve from 0.58351\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6996 - loss: 0.8503 - val_accuracy: 0.8280 - val_loss: 0.5884\n",
      "Epoch 622/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7011 - loss: 0.8493\n",
      "Epoch 622: val_loss did not improve from 0.58351\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7012 - loss: 0.8492 - val_accuracy: 0.8270 - val_loss: 0.5860\n",
      "Epoch 623/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6983 - loss: 0.8553\n",
      "Epoch 623: val_loss did not improve from 0.58351\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6983 - loss: 0.8553 - val_accuracy: 0.8253 - val_loss: 0.5908\n",
      "Epoch 624/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6984 - loss: 0.8670\n",
      "Epoch 624: val_loss did not improve from 0.58351\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6984 - loss: 0.8667 - val_accuracy: 0.8293 - val_loss: 0.5842\n",
      "Epoch 625/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7013 - loss: 0.8483\n",
      "Epoch 625: val_loss improved from 0.58351 to 0.58287, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7013 - loss: 0.8483 - val_accuracy: 0.8279 - val_loss: 0.5829\n",
      "Epoch 626/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7012 - loss: 0.8610\n",
      "Epoch 626: val_loss did not improve from 0.58287\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7012 - loss: 0.8610 - val_accuracy: 0.8266 - val_loss: 0.5868\n",
      "Epoch 627/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7053 - loss: 0.8395\n",
      "Epoch 627: val_loss did not improve from 0.58287\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7052 - loss: 0.8400 - val_accuracy: 0.8254 - val_loss: 0.5838\n",
      "Epoch 628/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7035 - loss: 0.8470\n",
      "Epoch 628: val_loss did not improve from 0.58287\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7036 - loss: 0.8470 - val_accuracy: 0.8287 - val_loss: 0.5874\n",
      "Epoch 629/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7058 - loss: 0.8533\n",
      "Epoch 629: val_loss did not improve from 0.58287\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.8534 - val_accuracy: 0.8288 - val_loss: 0.5852\n",
      "Epoch 630/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7069 - loss: 0.8370\n",
      "Epoch 630: val_loss did not improve from 0.58287\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7069 - loss: 0.8372 - val_accuracy: 0.8274 - val_loss: 0.5867\n",
      "Epoch 631/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6983 - loss: 0.8695\n",
      "Epoch 631: val_loss did not improve from 0.58287\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6983 - loss: 0.8695 - val_accuracy: 0.8262 - val_loss: 0.5856\n",
      "Epoch 632/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6951 - loss: 0.8636\n",
      "Epoch 632: val_loss did not improve from 0.58287\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6953 - loss: 0.8632 - val_accuracy: 0.8251 - val_loss: 0.5883\n",
      "Epoch 633/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7103 - loss: 0.8324\n",
      "Epoch 633: val_loss improved from 0.58287 to 0.58210, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7102 - loss: 0.8328 - val_accuracy: 0.8301 - val_loss: 0.5821\n",
      "Epoch 634/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7046 - loss: 0.8438\n",
      "Epoch 634: val_loss improved from 0.58210 to 0.58175, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7046 - loss: 0.8438 - val_accuracy: 0.8277 - val_loss: 0.5818\n",
      "Epoch 635/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6946 - loss: 0.8703\n",
      "Epoch 635: val_loss did not improve from 0.58175\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6947 - loss: 0.8699 - val_accuracy: 0.8254 - val_loss: 0.5885\n",
      "Epoch 636/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6962 - loss: 0.8736\n",
      "Epoch 636: val_loss improved from 0.58175 to 0.58117, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6963 - loss: 0.8731 - val_accuracy: 0.8295 - val_loss: 0.5812\n",
      "Epoch 637/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6997 - loss: 0.8594\n",
      "Epoch 637: val_loss did not improve from 0.58117\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6997 - loss: 0.8593 - val_accuracy: 0.8267 - val_loss: 0.5856\n",
      "Epoch 638/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7102 - loss: 0.8304\n",
      "Epoch 638: val_loss did not improve from 0.58117\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7102 - loss: 0.8306 - val_accuracy: 0.8279 - val_loss: 0.5835\n",
      "Epoch 639/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7163 - loss: 0.8290\n",
      "Epoch 639: val_loss did not improve from 0.58117\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: 0.8293 - val_accuracy: 0.8248 - val_loss: 0.5866\n",
      "Epoch 640/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7030 - loss: 0.8555\n",
      "Epoch 640: val_loss did not improve from 0.58117\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7030 - loss: 0.8553 - val_accuracy: 0.8275 - val_loss: 0.5872\n",
      "Epoch 641/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7052 - loss: 0.8485\n",
      "Epoch 641: val_loss did not improve from 0.58117\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7052 - loss: 0.8485 - val_accuracy: 0.8288 - val_loss: 0.5823\n",
      "Epoch 642/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7044 - loss: 0.8417\n",
      "Epoch 642: val_loss did not improve from 0.58117\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7044 - loss: 0.8417 - val_accuracy: 0.8280 - val_loss: 0.5832\n",
      "Epoch 643/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7077 - loss: 0.8410\n",
      "Epoch 643: val_loss did not improve from 0.58117\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7078 - loss: 0.8411 - val_accuracy: 0.8290 - val_loss: 0.5822\n",
      "Epoch 644/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7054 - loss: 0.8445\n",
      "Epoch 644: val_loss improved from 0.58117 to 0.57868, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7054 - loss: 0.8444 - val_accuracy: 0.8301 - val_loss: 0.5787\n",
      "Epoch 645/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7139 - loss: 0.8288\n",
      "Epoch 645: val_loss did not improve from 0.57868\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.8290 - val_accuracy: 0.8275 - val_loss: 0.5828\n",
      "Epoch 646/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7045 - loss: 0.8458\n",
      "Epoch 646: val_loss did not improve from 0.57868\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7045 - loss: 0.8457 - val_accuracy: 0.8306 - val_loss: 0.5807\n",
      "Epoch 647/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7005 - loss: 0.8543\n",
      "Epoch 647: val_loss did not improve from 0.57868\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7006 - loss: 0.8541 - val_accuracy: 0.8290 - val_loss: 0.5828\n",
      "Epoch 648/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7084 - loss: 0.8421\n",
      "Epoch 648: val_loss did not improve from 0.57868\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7083 - loss: 0.8422 - val_accuracy: 0.8301 - val_loss: 0.5817\n",
      "Epoch 649/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7059 - loss: 0.8458\n",
      "Epoch 649: val_loss did not improve from 0.57868\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7060 - loss: 0.8458 - val_accuracy: 0.8311 - val_loss: 0.5820\n",
      "Epoch 650/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7082 - loss: 0.8480\n",
      "Epoch 650: val_loss did not improve from 0.57868\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7082 - loss: 0.8480 - val_accuracy: 0.8293 - val_loss: 0.5831\n",
      "Epoch 651/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6949 - loss: 0.8640\n",
      "Epoch 651: val_loss did not improve from 0.57868\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6951 - loss: 0.8637 - val_accuracy: 0.8301 - val_loss: 0.5844\n",
      "Epoch 652/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7006 - loss: 0.8423\n",
      "Epoch 652: val_loss did not improve from 0.57868\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7006 - loss: 0.8423 - val_accuracy: 0.8296 - val_loss: 0.5838\n",
      "Epoch 653/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6986 - loss: 0.8506\n",
      "Epoch 653: val_loss improved from 0.57868 to 0.57844, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6987 - loss: 0.8505 - val_accuracy: 0.8296 - val_loss: 0.5784\n",
      "Epoch 654/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 0.8404\n",
      "Epoch 654: val_loss did not improve from 0.57844\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7074 - loss: 0.8405 - val_accuracy: 0.8298 - val_loss: 0.5799\n",
      "Epoch 655/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7053 - loss: 0.8387\n",
      "Epoch 655: val_loss did not improve from 0.57844\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7053 - loss: 0.8388 - val_accuracy: 0.8298 - val_loss: 0.5821\n",
      "Epoch 656/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7064 - loss: 0.8500\n",
      "Epoch 656: val_loss improved from 0.57844 to 0.57831, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7065 - loss: 0.8499 - val_accuracy: 0.8295 - val_loss: 0.5783\n",
      "Epoch 657/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7045 - loss: 0.8446\n",
      "Epoch 657: val_loss did not improve from 0.57831\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7045 - loss: 0.8445 - val_accuracy: 0.8308 - val_loss: 0.5788\n",
      "Epoch 658/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7086 - loss: 0.8373\n",
      "Epoch 658: val_loss did not improve from 0.57831\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7085 - loss: 0.8377 - val_accuracy: 0.8288 - val_loss: 0.5827\n",
      "Epoch 659/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7013 - loss: 0.8495\n",
      "Epoch 659: val_loss did not improve from 0.57831\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7013 - loss: 0.8494 - val_accuracy: 0.8300 - val_loss: 0.5787\n",
      "Epoch 660/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.8423\n",
      "Epoch 660: val_loss did not improve from 0.57831\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.8422 - val_accuracy: 0.8272 - val_loss: 0.5812\n",
      "Epoch 661/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6948 - loss: 0.8655\n",
      "Epoch 661: val_loss improved from 0.57831 to 0.57732, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6949 - loss: 0.8652 - val_accuracy: 0.8293 - val_loss: 0.5773\n",
      "Epoch 662/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7021 - loss: 0.8506\n",
      "Epoch 662: val_loss did not improve from 0.57732\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7021 - loss: 0.8506 - val_accuracy: 0.8313 - val_loss: 0.5817\n",
      "Epoch 663/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7053 - loss: 0.8410\n",
      "Epoch 663: val_loss did not improve from 0.57732\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7053 - loss: 0.8411 - val_accuracy: 0.8317 - val_loss: 0.5795\n",
      "Epoch 664/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7033 - loss: 0.8405\n",
      "Epoch 664: val_loss did not improve from 0.57732\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7033 - loss: 0.8404 - val_accuracy: 0.8313 - val_loss: 0.5797\n",
      "Epoch 665/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7101 - loss: 0.8422\n",
      "Epoch 665: val_loss did not improve from 0.57732\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.8422 - val_accuracy: 0.8326 - val_loss: 0.5779\n",
      "Epoch 666/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.8111\n",
      "Epoch 666: val_loss did not improve from 0.57732\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: 0.8114 - val_accuracy: 0.8291 - val_loss: 0.5787\n",
      "Epoch 667/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7034 - loss: 0.8376\n",
      "Epoch 667: val_loss did not improve from 0.57732\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7035 - loss: 0.8377 - val_accuracy: 0.8303 - val_loss: 0.5775\n",
      "Epoch 668/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7058 - loss: 0.8417\n",
      "Epoch 668: val_loss did not improve from 0.57732\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.8418 - val_accuracy: 0.8322 - val_loss: 0.5781\n",
      "Epoch 669/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 0.8210\n",
      "Epoch 669: val_loss did not improve from 0.57732\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7153 - loss: 0.8214 - val_accuracy: 0.8298 - val_loss: 0.5777\n",
      "Epoch 670/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: 0.8305\n",
      "Epoch 670: val_loss improved from 0.57732 to 0.57640, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: 0.8305 - val_accuracy: 0.8314 - val_loss: 0.5764\n",
      "Epoch 671/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7083 - loss: 0.8346\n",
      "Epoch 671: val_loss did not improve from 0.57640\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7083 - loss: 0.8346 - val_accuracy: 0.8288 - val_loss: 0.5774\n",
      "Epoch 672/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7048 - loss: 0.8439\n",
      "Epoch 672: val_loss did not improve from 0.57640\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7048 - loss: 0.8438 - val_accuracy: 0.8313 - val_loss: 0.5776\n",
      "Epoch 673/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7029 - loss: 0.8473\n",
      "Epoch 673: val_loss did not improve from 0.57640\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7029 - loss: 0.8473 - val_accuracy: 0.8293 - val_loss: 0.5795\n",
      "Epoch 674/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6965 - loss: 0.8576\n",
      "Epoch 674: val_loss did not improve from 0.57640\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6966 - loss: 0.8574 - val_accuracy: 0.8317 - val_loss: 0.5766\n",
      "Epoch 675/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7097 - loss: 0.8353\n",
      "Epoch 675: val_loss did not improve from 0.57640\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7097 - loss: 0.8353 - val_accuracy: 0.8303 - val_loss: 0.5783\n",
      "Epoch 676/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: 0.8313\n",
      "Epoch 676: val_loss improved from 0.57640 to 0.57523, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7112 - loss: 0.8315 - val_accuracy: 0.8311 - val_loss: 0.5752\n",
      "Epoch 677/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7066 - loss: 0.8330\n",
      "Epoch 677: val_loss did not improve from 0.57523\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7067 - loss: 0.8330 - val_accuracy: 0.8301 - val_loss: 0.5765\n",
      "Epoch 678/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 0.8248\n",
      "Epoch 678: val_loss did not improve from 0.57523\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: 0.8251 - val_accuracy: 0.8306 - val_loss: 0.5777\n",
      "Epoch 679/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.8455\n",
      "Epoch 679: val_loss did not improve from 0.57523\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.8453 - val_accuracy: 0.8291 - val_loss: 0.5777\n",
      "Epoch 680/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7045 - loss: 0.8513\n",
      "Epoch 680: val_loss improved from 0.57523 to 0.57351, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7045 - loss: 0.8513 - val_accuracy: 0.8321 - val_loss: 0.5735\n",
      "Epoch 681/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7185 - loss: 0.8163\n",
      "Epoch 681: val_loss improved from 0.57351 to 0.57134, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7184 - loss: 0.8164 - val_accuracy: 0.8303 - val_loss: 0.5713\n",
      "Epoch 682/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7045 - loss: 0.8438\n",
      "Epoch 682: val_loss did not improve from 0.57134\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7045 - loss: 0.8436 - val_accuracy: 0.8342 - val_loss: 0.5734\n",
      "Epoch 683/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7082 - loss: 0.8443\n",
      "Epoch 683: val_loss did not improve from 0.57134\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7082 - loss: 0.8443 - val_accuracy: 0.8304 - val_loss: 0.5767\n",
      "Epoch 684/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7028 - loss: 0.8498\n",
      "Epoch 684: val_loss improved from 0.57134 to 0.57026, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7028 - loss: 0.8496 - val_accuracy: 0.8306 - val_loss: 0.5703\n",
      "Epoch 685/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7044 - loss: 0.8366\n",
      "Epoch 685: val_loss did not improve from 0.57026\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7044 - loss: 0.8366 - val_accuracy: 0.8327 - val_loss: 0.5726\n",
      "Epoch 686/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7021 - loss: 0.8478\n",
      "Epoch 686: val_loss did not improve from 0.57026\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7022 - loss: 0.8475 - val_accuracy: 0.8296 - val_loss: 0.5769\n",
      "Epoch 687/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7108 - loss: 0.8325\n",
      "Epoch 687: val_loss improved from 0.57026 to 0.57018, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7108 - loss: 0.8325 - val_accuracy: 0.8350 - val_loss: 0.5702\n",
      "Epoch 688/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7077 - loss: 0.8450\n",
      "Epoch 688: val_loss did not improve from 0.57018\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7076 - loss: 0.8450 - val_accuracy: 0.8343 - val_loss: 0.5729\n",
      "Epoch 689/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7089 - loss: 0.8286\n",
      "Epoch 689: val_loss did not improve from 0.57018\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7089 - loss: 0.8286 - val_accuracy: 0.8287 - val_loss: 0.5779\n",
      "Epoch 690/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7039 - loss: 0.8426\n",
      "Epoch 690: val_loss did not improve from 0.57018\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7040 - loss: 0.8424 - val_accuracy: 0.8304 - val_loss: 0.5744\n",
      "Epoch 691/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7074 - loss: 0.8323\n",
      "Epoch 691: val_loss improved from 0.57018 to 0.57006, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7074 - loss: 0.8323 - val_accuracy: 0.8326 - val_loss: 0.5701\n",
      "Epoch 692/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7066 - loss: 0.8373\n",
      "Epoch 692: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7066 - loss: 0.8373 - val_accuracy: 0.8326 - val_loss: 0.5715\n",
      "Epoch 693/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7094 - loss: 0.8253\n",
      "Epoch 693: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7094 - loss: 0.8254 - val_accuracy: 0.8287 - val_loss: 0.5704\n",
      "Epoch 694/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7055 - loss: 0.8488\n",
      "Epoch 694: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7055 - loss: 0.8488 - val_accuracy: 0.8330 - val_loss: 0.5719\n",
      "Epoch 695/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7049 - loss: 0.8494\n",
      "Epoch 695: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7049 - loss: 0.8492 - val_accuracy: 0.8324 - val_loss: 0.5735\n",
      "Epoch 696/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7112 - loss: 0.8317\n",
      "Epoch 696: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7112 - loss: 0.8315 - val_accuracy: 0.8298 - val_loss: 0.5737\n",
      "Epoch 697/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7082 - loss: 0.8264\n",
      "Epoch 697: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7081 - loss: 0.8263 - val_accuracy: 0.8298 - val_loss: 0.5724\n",
      "Epoch 698/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7017 - loss: 0.8407\n",
      "Epoch 698: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7017 - loss: 0.8407 - val_accuracy: 0.8311 - val_loss: 0.5710\n",
      "Epoch 699/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.8359\n",
      "Epoch 699: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.8359 - val_accuracy: 0.8306 - val_loss: 0.5731\n",
      "Epoch 700/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7153 - loss: 0.8250\n",
      "Epoch 700: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7153 - loss: 0.8250 - val_accuracy: 0.8300 - val_loss: 0.5744\n",
      "Epoch 701/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7069 - loss: 0.8381\n",
      "Epoch 701: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7069 - loss: 0.8380 - val_accuracy: 0.8335 - val_loss: 0.5707\n",
      "Epoch 702/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7048 - loss: 0.8367\n",
      "Epoch 702: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7047 - loss: 0.8368 - val_accuracy: 0.8296 - val_loss: 0.5708\n",
      "Epoch 703/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.8403\n",
      "Epoch 703: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.8402 - val_accuracy: 0.8319 - val_loss: 0.5736\n",
      "Epoch 704/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.8289\n",
      "Epoch 704: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.8289 - val_accuracy: 0.8326 - val_loss: 0.5705\n",
      "Epoch 705/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7084 - loss: 0.8397\n",
      "Epoch 705: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7084 - loss: 0.8394 - val_accuracy: 0.8319 - val_loss: 0.5720\n",
      "Epoch 706/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.8250\n",
      "Epoch 706: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.8251 - val_accuracy: 0.8285 - val_loss: 0.5732\n",
      "Epoch 707/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: 0.8408\n",
      "Epoch 707: val_loss did not improve from 0.57006\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7105 - loss: 0.8407 - val_accuracy: 0.8334 - val_loss: 0.5717\n",
      "Epoch 708/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7024 - loss: 0.8437\n",
      "Epoch 708: val_loss improved from 0.57006 to 0.56837, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7025 - loss: 0.8435 - val_accuracy: 0.8334 - val_loss: 0.5684\n",
      "Epoch 709/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7094 - loss: 0.8399\n",
      "Epoch 709: val_loss did not improve from 0.56837\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7094 - loss: 0.8398 - val_accuracy: 0.8343 - val_loss: 0.5701\n",
      "Epoch 710/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7082 - loss: 0.8172\n",
      "Epoch 710: val_loss improved from 0.56837 to 0.56728, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7081 - loss: 0.8176 - val_accuracy: 0.8322 - val_loss: 0.5673\n",
      "Epoch 711/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7005 - loss: 0.8596\n",
      "Epoch 711: val_loss did not improve from 0.56728\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7007 - loss: 0.8589 - val_accuracy: 0.8360 - val_loss: 0.5686\n",
      "Epoch 712/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.8333\n",
      "Epoch 712: val_loss did not improve from 0.56728\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7158 - loss: 0.8334 - val_accuracy: 0.8311 - val_loss: 0.5711\n",
      "Epoch 713/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7054 - loss: 0.8329\n",
      "Epoch 713: val_loss did not improve from 0.56728\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7054 - loss: 0.8328 - val_accuracy: 0.8326 - val_loss: 0.5710\n",
      "Epoch 714/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7094 - loss: 0.8388\n",
      "Epoch 714: val_loss did not improve from 0.56728\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7093 - loss: 0.8387 - val_accuracy: 0.8296 - val_loss: 0.5783\n",
      "Epoch 715/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.8351\n",
      "Epoch 715: val_loss did not improve from 0.56728\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.8351 - val_accuracy: 0.8355 - val_loss: 0.5697\n",
      "Epoch 716/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7122 - loss: 0.8243\n",
      "Epoch 716: val_loss improved from 0.56728 to 0.56715, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7122 - loss: 0.8243 - val_accuracy: 0.8343 - val_loss: 0.5671\n",
      "Epoch 717/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7018 - loss: 0.8417\n",
      "Epoch 717: val_loss did not improve from 0.56715\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7019 - loss: 0.8417 - val_accuracy: 0.8324 - val_loss: 0.5694\n",
      "Epoch 718/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7041 - loss: 0.8516\n",
      "Epoch 718: val_loss did not improve from 0.56715\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7042 - loss: 0.8514 - val_accuracy: 0.8327 - val_loss: 0.5692\n",
      "Epoch 719/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.8251\n",
      "Epoch 719: val_loss did not improve from 0.56715\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7141 - loss: 0.8251 - val_accuracy: 0.8334 - val_loss: 0.5681\n",
      "Epoch 720/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7062 - loss: 0.8290\n",
      "Epoch 720: val_loss did not improve from 0.56715\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7062 - loss: 0.8288 - val_accuracy: 0.8327 - val_loss: 0.5688\n",
      "Epoch 721/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7025 - loss: 0.8577\n",
      "Epoch 721: val_loss did not improve from 0.56715\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7025 - loss: 0.8573 - val_accuracy: 0.8319 - val_loss: 0.5684\n",
      "Epoch 722/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7111 - loss: 0.8260\n",
      "Epoch 722: val_loss did not improve from 0.56715\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.8261 - val_accuracy: 0.8321 - val_loss: 0.5698\n",
      "Epoch 723/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7118 - loss: 0.8285\n",
      "Epoch 723: val_loss did not improve from 0.56715\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7118 - loss: 0.8286 - val_accuracy: 0.8347 - val_loss: 0.5690\n",
      "Epoch 724/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: 0.8294\n",
      "Epoch 724: val_loss did not improve from 0.56715\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: 0.8295 - val_accuracy: 0.8360 - val_loss: 0.5676\n",
      "Epoch 725/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7096 - loss: 0.8252\n",
      "Epoch 725: val_loss improved from 0.56715 to 0.56697, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7097 - loss: 0.8252 - val_accuracy: 0.8347 - val_loss: 0.5670\n",
      "Epoch 726/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7023 - loss: 0.8313\n",
      "Epoch 726: val_loss improved from 0.56697 to 0.56549, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7024 - loss: 0.8312 - val_accuracy: 0.8368 - val_loss: 0.5655\n",
      "Epoch 727/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7089 - loss: 0.8250\n",
      "Epoch 727: val_loss improved from 0.56549 to 0.56543, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7089 - loss: 0.8250 - val_accuracy: 0.8335 - val_loss: 0.5654\n",
      "Epoch 728/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7107 - loss: 0.8207\n",
      "Epoch 728: val_loss did not improve from 0.56543\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7107 - loss: 0.8208 - val_accuracy: 0.8316 - val_loss: 0.5708\n",
      "Epoch 729/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7044 - loss: 0.8270\n",
      "Epoch 729: val_loss did not improve from 0.56543\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7044 - loss: 0.8270 - val_accuracy: 0.8308 - val_loss: 0.5658\n",
      "Epoch 730/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7061 - loss: 0.8374\n",
      "Epoch 730: val_loss did not improve from 0.56543\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7061 - loss: 0.8374 - val_accuracy: 0.8340 - val_loss: 0.5658\n",
      "Epoch 731/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7131 - loss: 0.8191\n",
      "Epoch 731: val_loss did not improve from 0.56543\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7131 - loss: 0.8192 - val_accuracy: 0.8317 - val_loss: 0.5662\n",
      "Epoch 732/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: 0.8185\n",
      "Epoch 732: val_loss did not improve from 0.56543\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7104 - loss: 0.8186 - val_accuracy: 0.8332 - val_loss: 0.5669\n",
      "Epoch 733/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7079 - loss: 0.8347\n",
      "Epoch 733: val_loss did not improve from 0.56543\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7079 - loss: 0.8347 - val_accuracy: 0.8350 - val_loss: 0.5667\n",
      "Epoch 734/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 0.8241\n",
      "Epoch 734: val_loss did not improve from 0.56543\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7074 - loss: 0.8244 - val_accuracy: 0.8340 - val_loss: 0.5676\n",
      "Epoch 735/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.8223\n",
      "Epoch 735: val_loss improved from 0.56543 to 0.56424, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.8223 - val_accuracy: 0.8329 - val_loss: 0.5642\n",
      "Epoch 736/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7137 - loss: 0.8183\n",
      "Epoch 736: val_loss did not improve from 0.56424\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7136 - loss: 0.8185 - val_accuracy: 0.8361 - val_loss: 0.5659\n",
      "Epoch 737/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7158 - loss: 0.8290\n",
      "Epoch 737: val_loss did not improve from 0.56424\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7157 - loss: 0.8291 - val_accuracy: 0.8327 - val_loss: 0.5689\n",
      "Epoch 738/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7089 - loss: 0.8229\n",
      "Epoch 738: val_loss improved from 0.56424 to 0.56154, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7088 - loss: 0.8230 - val_accuracy: 0.8360 - val_loss: 0.5615\n",
      "Epoch 739/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7074 - loss: 0.8323\n",
      "Epoch 739: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 0.8322 - val_accuracy: 0.8338 - val_loss: 0.5644\n",
      "Epoch 740/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.8249\n",
      "Epoch 740: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.8249 - val_accuracy: 0.8364 - val_loss: 0.5656\n",
      "Epoch 741/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7143 - loss: 0.8221\n",
      "Epoch 741: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7143 - loss: 0.8221 - val_accuracy: 0.8348 - val_loss: 0.5674\n",
      "Epoch 742/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7115 - loss: 0.8320\n",
      "Epoch 742: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: 0.8321 - val_accuracy: 0.8355 - val_loss: 0.5667\n",
      "Epoch 743/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7081 - loss: 0.8279\n",
      "Epoch 743: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7081 - loss: 0.8279 - val_accuracy: 0.8371 - val_loss: 0.5643\n",
      "Epoch 744/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7107 - loss: 0.8236\n",
      "Epoch 744: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7107 - loss: 0.8237 - val_accuracy: 0.8355 - val_loss: 0.5644\n",
      "Epoch 745/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7109 - loss: 0.8387\n",
      "Epoch 745: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.8386 - val_accuracy: 0.8335 - val_loss: 0.5660\n",
      "Epoch 746/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7033 - loss: 0.8298\n",
      "Epoch 746: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7033 - loss: 0.8298 - val_accuracy: 0.8332 - val_loss: 0.5679\n",
      "Epoch 747/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7086 - loss: 0.8237\n",
      "Epoch 747: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7087 - loss: 0.8237 - val_accuracy: 0.8330 - val_loss: 0.5631\n",
      "Epoch 748/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7150 - loss: 0.8166\n",
      "Epoch 748: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 0.8167 - val_accuracy: 0.8329 - val_loss: 0.5662\n",
      "Epoch 749/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.8127\n",
      "Epoch 749: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 0.8128 - val_accuracy: 0.8351 - val_loss: 0.5626\n",
      "Epoch 750/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7094 - loss: 0.8264\n",
      "Epoch 750: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7093 - loss: 0.8264 - val_accuracy: 0.8361 - val_loss: 0.5631\n",
      "Epoch 751/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7030 - loss: 0.8399\n",
      "Epoch 751: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.8395 - val_accuracy: 0.8335 - val_loss: 0.5618\n",
      "Epoch 752/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7146 - loss: 0.8114\n",
      "Epoch 752: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7146 - loss: 0.8115 - val_accuracy: 0.8345 - val_loss: 0.5648\n",
      "Epoch 753/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7097 - loss: 0.8246\n",
      "Epoch 753: val_loss did not improve from 0.56154\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.8243 - val_accuracy: 0.8332 - val_loss: 0.5631\n",
      "Epoch 754/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7118 - loss: 0.8228\n",
      "Epoch 754: val_loss improved from 0.56154 to 0.56132, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.8229 - val_accuracy: 0.8351 - val_loss: 0.5613\n",
      "Epoch 755/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.8051\n",
      "Epoch 755: val_loss did not improve from 0.56132\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7170 - loss: 0.8053 - val_accuracy: 0.8356 - val_loss: 0.5624\n",
      "Epoch 756/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7113 - loss: 0.8262\n",
      "Epoch 756: val_loss improved from 0.56132 to 0.55973, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7113 - loss: 0.8262 - val_accuracy: 0.8369 - val_loss: 0.5597\n",
      "Epoch 757/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.8233\n",
      "Epoch 757: val_loss did not improve from 0.55973\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.8232 - val_accuracy: 0.8338 - val_loss: 0.5630\n",
      "Epoch 758/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7127 - loss: 0.8191\n",
      "Epoch 758: val_loss did not improve from 0.55973\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7127 - loss: 0.8192 - val_accuracy: 0.8363 - val_loss: 0.5622\n",
      "Epoch 759/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7151 - loss: 0.8154\n",
      "Epoch 759: val_loss did not improve from 0.55973\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7151 - loss: 0.8154 - val_accuracy: 0.8338 - val_loss: 0.5652\n",
      "Epoch 760/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7093 - loss: 0.8172\n",
      "Epoch 760: val_loss did not improve from 0.55973\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7093 - loss: 0.8173 - val_accuracy: 0.8313 - val_loss: 0.5673\n",
      "Epoch 761/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7139 - loss: 0.8194\n",
      "Epoch 761: val_loss did not improve from 0.55973\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.8195 - val_accuracy: 0.8337 - val_loss: 0.5619\n",
      "Epoch 762/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.8331\n",
      "Epoch 762: val_loss did not improve from 0.55973\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.8331 - val_accuracy: 0.8372 - val_loss: 0.5621\n",
      "Epoch 763/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.8288\n",
      "Epoch 763: val_loss improved from 0.55973 to 0.55795, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7099 - loss: 0.8287 - val_accuracy: 0.8369 - val_loss: 0.5579\n",
      "Epoch 764/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7143 - loss: 0.8272\n",
      "Epoch 764: val_loss did not improve from 0.55795\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.8272 - val_accuracy: 0.8353 - val_loss: 0.5603\n",
      "Epoch 765/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7113 - loss: 0.8188\n",
      "Epoch 765: val_loss did not improve from 0.55795\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7113 - loss: 0.8188 - val_accuracy: 0.8309 - val_loss: 0.5667\n",
      "Epoch 766/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7080 - loss: 0.8219\n",
      "Epoch 766: val_loss did not improve from 0.55795\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7080 - loss: 0.8219 - val_accuracy: 0.8314 - val_loss: 0.5622\n",
      "Epoch 767/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7089 - loss: 0.8177\n",
      "Epoch 767: val_loss did not improve from 0.55795\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7090 - loss: 0.8177 - val_accuracy: 0.8348 - val_loss: 0.5602\n",
      "Epoch 768/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7102 - loss: 0.8219\n",
      "Epoch 768: val_loss did not improve from 0.55795\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7103 - loss: 0.8219 - val_accuracy: 0.8316 - val_loss: 0.5666\n",
      "Epoch 769/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7103 - loss: 0.8156\n",
      "Epoch 769: val_loss did not improve from 0.55795\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7103 - loss: 0.8157 - val_accuracy: 0.8376 - val_loss: 0.5600\n",
      "Epoch 770/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.8277\n",
      "Epoch 770: val_loss did not improve from 0.55795\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.8277 - val_accuracy: 0.8350 - val_loss: 0.5584\n",
      "Epoch 771/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7143 - loss: 0.8125\n",
      "Epoch 771: val_loss did not improve from 0.55795\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.8127 - val_accuracy: 0.8350 - val_loss: 0.5639\n",
      "Epoch 772/1500\n",
      "\u001b[1m743/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.8132\n",
      "Epoch 772: val_loss did not improve from 0.55795\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: 0.8133 - val_accuracy: 0.8314 - val_loss: 0.5659\n",
      "Epoch 773/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: 0.8161\n",
      "Epoch 773: val_loss did not improve from 0.55795\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: 0.8163 - val_accuracy: 0.8377 - val_loss: 0.5587\n",
      "Epoch 774/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7145 - loss: 0.8278\n",
      "Epoch 774: val_loss did not improve from 0.55795\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7145 - loss: 0.8278 - val_accuracy: 0.8356 - val_loss: 0.5597\n",
      "Epoch 775/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7097 - loss: 0.8302\n",
      "Epoch 775: val_loss improved from 0.55795 to 0.55740, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7097 - loss: 0.8302 - val_accuracy: 0.8366 - val_loss: 0.5574\n",
      "Epoch 776/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 0.8129\n",
      "Epoch 776: val_loss improved from 0.55740 to 0.55563, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 0.8130 - val_accuracy: 0.8371 - val_loss: 0.5556\n",
      "Epoch 777/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 0.8281\n",
      "Epoch 777: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 0.8281 - val_accuracy: 0.8343 - val_loss: 0.5612\n",
      "Epoch 778/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7034 - loss: 0.8406\n",
      "Epoch 778: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7035 - loss: 0.8404 - val_accuracy: 0.8358 - val_loss: 0.5600\n",
      "Epoch 779/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.8120\n",
      "Epoch 779: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.8120 - val_accuracy: 0.8379 - val_loss: 0.5568\n",
      "Epoch 780/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7173 - loss: 0.8198\n",
      "Epoch 780: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7174 - loss: 0.8198 - val_accuracy: 0.8387 - val_loss: 0.5569\n",
      "Epoch 781/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 0.8173\n",
      "Epoch 781: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 0.8174 - val_accuracy: 0.8389 - val_loss: 0.5564\n",
      "Epoch 782/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7048 - loss: 0.8263\n",
      "Epoch 782: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7049 - loss: 0.8262 - val_accuracy: 0.8327 - val_loss: 0.5624\n",
      "Epoch 783/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7103 - loss: 0.8262\n",
      "Epoch 783: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7104 - loss: 0.8259 - val_accuracy: 0.8376 - val_loss: 0.5573\n",
      "Epoch 784/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7065 - loss: 0.8215\n",
      "Epoch 784: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7066 - loss: 0.8214 - val_accuracy: 0.8397 - val_loss: 0.5566\n",
      "Epoch 785/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7126 - loss: 0.8161\n",
      "Epoch 785: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7126 - loss: 0.8161 - val_accuracy: 0.8371 - val_loss: 0.5566\n",
      "Epoch 786/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7099 - loss: 0.8296\n",
      "Epoch 786: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.8294 - val_accuracy: 0.8347 - val_loss: 0.5589\n",
      "Epoch 787/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7126 - loss: 0.8204\n",
      "Epoch 787: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7126 - loss: 0.8204 - val_accuracy: 0.8348 - val_loss: 0.5599\n",
      "Epoch 788/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7117 - loss: 0.8119\n",
      "Epoch 788: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7117 - loss: 0.8121 - val_accuracy: 0.8372 - val_loss: 0.5570\n",
      "Epoch 789/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.8236\n",
      "Epoch 789: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.8235 - val_accuracy: 0.8350 - val_loss: 0.5614\n",
      "Epoch 790/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7095 - loss: 0.8204\n",
      "Epoch 790: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7096 - loss: 0.8205 - val_accuracy: 0.8343 - val_loss: 0.5587\n",
      "Epoch 791/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.8225\n",
      "Epoch 791: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.8224 - val_accuracy: 0.8355 - val_loss: 0.5581\n",
      "Epoch 792/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7150 - loss: 0.8118\n",
      "Epoch 792: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 0.8120 - val_accuracy: 0.8389 - val_loss: 0.5563\n",
      "Epoch 793/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7195 - loss: 0.8048\n",
      "Epoch 793: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7195 - loss: 0.8048 - val_accuracy: 0.8358 - val_loss: 0.5581\n",
      "Epoch 794/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7140 - loss: 0.8088\n",
      "Epoch 794: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7140 - loss: 0.8090 - val_accuracy: 0.8371 - val_loss: 0.5580\n",
      "Epoch 795/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7118 - loss: 0.8247\n",
      "Epoch 795: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.8246 - val_accuracy: 0.8368 - val_loss: 0.5561\n",
      "Epoch 796/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7184 - loss: 0.7911\n",
      "Epoch 796: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7183 - loss: 0.7915 - val_accuracy: 0.8348 - val_loss: 0.5594\n",
      "Epoch 797/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7150 - loss: 0.8128\n",
      "Epoch 797: val_loss did not improve from 0.55563\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7150 - loss: 0.8128 - val_accuracy: 0.8371 - val_loss: 0.5578\n",
      "Epoch 798/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7120 - loss: 0.8231\n",
      "Epoch 798: val_loss improved from 0.55563 to 0.55129, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7120 - loss: 0.8231 - val_accuracy: 0.8384 - val_loss: 0.5513\n",
      "Epoch 799/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7136 - loss: 0.8192\n",
      "Epoch 799: val_loss did not improve from 0.55129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7136 - loss: 0.8192 - val_accuracy: 0.8360 - val_loss: 0.5579\n",
      "Epoch 800/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.8129\n",
      "Epoch 800: val_loss did not improve from 0.55129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.8131 - val_accuracy: 0.8379 - val_loss: 0.5554\n",
      "Epoch 801/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 0.8169\n",
      "Epoch 801: val_loss did not improve from 0.55129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.8168 - val_accuracy: 0.8390 - val_loss: 0.5568\n",
      "Epoch 802/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7183 - loss: 0.8133\n",
      "Epoch 802: val_loss did not improve from 0.55129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7183 - loss: 0.8133 - val_accuracy: 0.8385 - val_loss: 0.5574\n",
      "Epoch 803/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7085 - loss: 0.8225\n",
      "Epoch 803: val_loss did not improve from 0.55129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7085 - loss: 0.8226 - val_accuracy: 0.8390 - val_loss: 0.5557\n",
      "Epoch 804/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7086 - loss: 0.8299\n",
      "Epoch 804: val_loss did not improve from 0.55129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7086 - loss: 0.8298 - val_accuracy: 0.8372 - val_loss: 0.5553\n",
      "Epoch 805/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.8180\n",
      "Epoch 805: val_loss did not improve from 0.55129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.8179 - val_accuracy: 0.8342 - val_loss: 0.5581\n",
      "Epoch 806/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7060 - loss: 0.8399\n",
      "Epoch 806: val_loss did not improve from 0.55129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7062 - loss: 0.8392 - val_accuracy: 0.8384 - val_loss: 0.5569\n",
      "Epoch 807/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.8156\n",
      "Epoch 807: val_loss did not improve from 0.55129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7111 - loss: 0.8156 - val_accuracy: 0.8372 - val_loss: 0.5562\n",
      "Epoch 808/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.8020\n",
      "Epoch 808: val_loss did not improve from 0.55129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7198 - loss: 0.8023 - val_accuracy: 0.8387 - val_loss: 0.5547\n",
      "Epoch 809/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7172 - loss: 0.8041\n",
      "Epoch 809: val_loss did not improve from 0.55129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7172 - loss: 0.8041 - val_accuracy: 0.8358 - val_loss: 0.5563\n",
      "Epoch 810/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.8266\n",
      "Epoch 810: val_loss did not improve from 0.55129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.8265 - val_accuracy: 0.8376 - val_loss: 0.5528\n",
      "Epoch 811/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.8017\n",
      "Epoch 811: val_loss did not improve from 0.55129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.8017 - val_accuracy: 0.8384 - val_loss: 0.5526\n",
      "Epoch 812/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7173 - loss: 0.7950\n",
      "Epoch 812: val_loss did not improve from 0.55129\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7173 - loss: 0.7953 - val_accuracy: 0.8382 - val_loss: 0.5536\n",
      "Epoch 813/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7230 - loss: 0.7971\n",
      "Epoch 813: val_loss improved from 0.55129 to 0.55017, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.7976 - val_accuracy: 0.8385 - val_loss: 0.5502\n",
      "Epoch 814/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.8222\n",
      "Epoch 814: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.8223 - val_accuracy: 0.8382 - val_loss: 0.5562\n",
      "Epoch 815/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7068 - loss: 0.8185\n",
      "Epoch 815: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7068 - loss: 0.8185 - val_accuracy: 0.8345 - val_loss: 0.5543\n",
      "Epoch 816/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.8075\n",
      "Epoch 816: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.8077 - val_accuracy: 0.8385 - val_loss: 0.5540\n",
      "Epoch 817/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7157 - loss: 0.8034\n",
      "Epoch 817: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7157 - loss: 0.8034 - val_accuracy: 0.8371 - val_loss: 0.5549\n",
      "Epoch 818/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.8220\n",
      "Epoch 818: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.8219 - val_accuracy: 0.8394 - val_loss: 0.5529\n",
      "Epoch 819/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.8210\n",
      "Epoch 819: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.8210 - val_accuracy: 0.8397 - val_loss: 0.5534\n",
      "Epoch 820/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7164 - loss: 0.8004\n",
      "Epoch 820: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7164 - loss: 0.8005 - val_accuracy: 0.8405 - val_loss: 0.5526\n",
      "Epoch 821/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: 0.8181\n",
      "Epoch 821: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: 0.8181 - val_accuracy: 0.8384 - val_loss: 0.5530\n",
      "Epoch 822/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.8176\n",
      "Epoch 822: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7134 - loss: 0.8174 - val_accuracy: 0.8390 - val_loss: 0.5509\n",
      "Epoch 823/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7153 - loss: 0.8222\n",
      "Epoch 823: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7152 - loss: 0.8222 - val_accuracy: 0.8384 - val_loss: 0.5541\n",
      "Epoch 824/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7197 - loss: 0.8008\n",
      "Epoch 824: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7195 - loss: 0.8012 - val_accuracy: 0.8392 - val_loss: 0.5513\n",
      "Epoch 825/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7139 - loss: 0.8089\n",
      "Epoch 825: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7139 - loss: 0.8088 - val_accuracy: 0.8385 - val_loss: 0.5520\n",
      "Epoch 826/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7173 - loss: 0.8093\n",
      "Epoch 826: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7172 - loss: 0.8094 - val_accuracy: 0.8394 - val_loss: 0.5521\n",
      "Epoch 827/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7130 - loss: 0.8083\n",
      "Epoch 827: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7131 - loss: 0.8085 - val_accuracy: 0.8387 - val_loss: 0.5560\n",
      "Epoch 828/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7123 - loss: 0.8210\n",
      "Epoch 828: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7123 - loss: 0.8209 - val_accuracy: 0.8384 - val_loss: 0.5531\n",
      "Epoch 829/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.8116\n",
      "Epoch 829: val_loss did not improve from 0.55017\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.8116 - val_accuracy: 0.8387 - val_loss: 0.5505\n",
      "Epoch 830/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 0.8131\n",
      "Epoch 830: val_loss improved from 0.55017 to 0.55004, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.8127 - val_accuracy: 0.8413 - val_loss: 0.5500\n",
      "Epoch 831/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7192 - loss: 0.8126\n",
      "Epoch 831: val_loss did not improve from 0.55004\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7192 - loss: 0.8126 - val_accuracy: 0.8405 - val_loss: 0.5525\n",
      "Epoch 832/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7181 - loss: 0.8003\n",
      "Epoch 832: val_loss did not improve from 0.55004\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7180 - loss: 0.8005 - val_accuracy: 0.8374 - val_loss: 0.5533\n",
      "Epoch 833/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7173 - loss: 0.8150\n",
      "Epoch 833: val_loss improved from 0.55004 to 0.54885, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7172 - loss: 0.8150 - val_accuracy: 0.8402 - val_loss: 0.5489\n",
      "Epoch 834/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7178 - loss: 0.8073\n",
      "Epoch 834: val_loss did not improve from 0.54885\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7178 - loss: 0.8072 - val_accuracy: 0.8363 - val_loss: 0.5542\n",
      "Epoch 835/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7047 - loss: 0.8285\n",
      "Epoch 835: val_loss improved from 0.54885 to 0.54873, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7048 - loss: 0.8282 - val_accuracy: 0.8410 - val_loss: 0.5487\n",
      "Epoch 836/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7145 - loss: 0.7971\n",
      "Epoch 836: val_loss did not improve from 0.54873\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7145 - loss: 0.7971 - val_accuracy: 0.8366 - val_loss: 0.5567\n",
      "Epoch 837/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 0.8085\n",
      "Epoch 837: val_loss did not improve from 0.54873\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 0.8085 - val_accuracy: 0.8406 - val_loss: 0.5490\n",
      "Epoch 838/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7157 - loss: 0.8157\n",
      "Epoch 838: val_loss improved from 0.54873 to 0.54766, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7157 - loss: 0.8156 - val_accuracy: 0.8398 - val_loss: 0.5477\n",
      "Epoch 839/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.8044\n",
      "Epoch 839: val_loss did not improve from 0.54766\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.8044 - val_accuracy: 0.8394 - val_loss: 0.5485\n",
      "Epoch 840/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.8075\n",
      "Epoch 840: val_loss did not improve from 0.54766\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.8074 - val_accuracy: 0.8413 - val_loss: 0.5484\n",
      "Epoch 841/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7220 - loss: 0.7998\n",
      "Epoch 841: val_loss did not improve from 0.54766\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7219 - loss: 0.7999 - val_accuracy: 0.8421 - val_loss: 0.5508\n",
      "Epoch 842/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: 0.8198\n",
      "Epoch 842: val_loss did not improve from 0.54766\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 0.8197 - val_accuracy: 0.8410 - val_loss: 0.5485\n",
      "Epoch 843/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: 0.8089\n",
      "Epoch 843: val_loss did not improve from 0.54766\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 0.8088 - val_accuracy: 0.8397 - val_loss: 0.5508\n",
      "Epoch 844/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 0.8112\n",
      "Epoch 844: val_loss did not improve from 0.54766\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7148 - loss: 0.8112 - val_accuracy: 0.8426 - val_loss: 0.5481\n",
      "Epoch 845/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7168 - loss: 0.8100\n",
      "Epoch 845: val_loss did not improve from 0.54766\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7168 - loss: 0.8101 - val_accuracy: 0.8398 - val_loss: 0.5481\n",
      "Epoch 846/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: 0.8160\n",
      "Epoch 846: val_loss improved from 0.54766 to 0.54622, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.8161 - val_accuracy: 0.8418 - val_loss: 0.5462\n",
      "Epoch 847/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7139 - loss: 0.8083\n",
      "Epoch 847: val_loss did not improve from 0.54622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.8083 - val_accuracy: 0.8392 - val_loss: 0.5519\n",
      "Epoch 848/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7165 - loss: 0.8066\n",
      "Epoch 848: val_loss did not improve from 0.54622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7164 - loss: 0.8067 - val_accuracy: 0.8400 - val_loss: 0.5525\n",
      "Epoch 849/1500\n",
      "\u001b[1m741/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 0.8305\n",
      "Epoch 849: val_loss did not improve from 0.54622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7107 - loss: 0.8299 - val_accuracy: 0.8384 - val_loss: 0.5539\n",
      "Epoch 850/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7111 - loss: 0.8220\n",
      "Epoch 850: val_loss did not improve from 0.54622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7111 - loss: 0.8219 - val_accuracy: 0.8410 - val_loss: 0.5488\n",
      "Epoch 851/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7094 - loss: 0.8189\n",
      "Epoch 851: val_loss did not improve from 0.54622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7095 - loss: 0.8185 - val_accuracy: 0.8384 - val_loss: 0.5536\n",
      "Epoch 852/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7051 - loss: 0.8131\n",
      "Epoch 852: val_loss did not improve from 0.54622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7052 - loss: 0.8131 - val_accuracy: 0.8408 - val_loss: 0.5492\n",
      "Epoch 853/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7120 - loss: 0.8002\n",
      "Epoch 853: val_loss did not improve from 0.54622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7121 - loss: 0.8002 - val_accuracy: 0.8385 - val_loss: 0.5524\n",
      "Epoch 854/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.8124\n",
      "Epoch 854: val_loss did not improve from 0.54622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: 0.8124 - val_accuracy: 0.8389 - val_loss: 0.5515\n",
      "Epoch 855/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.8158\n",
      "Epoch 855: val_loss did not improve from 0.54622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.8157 - val_accuracy: 0.8402 - val_loss: 0.5463\n",
      "Epoch 856/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7076 - loss: 0.8176\n",
      "Epoch 856: val_loss did not improve from 0.54622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7077 - loss: 0.8175 - val_accuracy: 0.8402 - val_loss: 0.5477\n",
      "Epoch 857/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7177 - loss: 0.8119\n",
      "Epoch 857: val_loss did not improve from 0.54622\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7177 - loss: 0.8118 - val_accuracy: 0.8387 - val_loss: 0.5500\n",
      "Epoch 858/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7183 - loss: 0.7983\n",
      "Epoch 858: val_loss improved from 0.54622 to 0.54526, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.7984 - val_accuracy: 0.8429 - val_loss: 0.5453\n",
      "Epoch 859/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 0.8089\n",
      "Epoch 859: val_loss did not improve from 0.54526\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 0.8088 - val_accuracy: 0.8395 - val_loss: 0.5469\n",
      "Epoch 860/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.7961\n",
      "Epoch 860: val_loss did not improve from 0.54526\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 0.7964 - val_accuracy: 0.8394 - val_loss: 0.5497\n",
      "Epoch 861/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7056 - loss: 0.8260\n",
      "Epoch 861: val_loss improved from 0.54526 to 0.54417, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7058 - loss: 0.8256 - val_accuracy: 0.8411 - val_loss: 0.5442\n",
      "Epoch 862/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.7984\n",
      "Epoch 862: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7198 - loss: 0.7987 - val_accuracy: 0.8405 - val_loss: 0.5468\n",
      "Epoch 863/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7186 - loss: 0.8018\n",
      "Epoch 863: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7186 - loss: 0.8018 - val_accuracy: 0.8392 - val_loss: 0.5508\n",
      "Epoch 864/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7200 - loss: 0.7976\n",
      "Epoch 864: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7200 - loss: 0.7976 - val_accuracy: 0.8395 - val_loss: 0.5455\n",
      "Epoch 865/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7165 - loss: 0.7963\n",
      "Epoch 865: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7164 - loss: 0.7964 - val_accuracy: 0.8379 - val_loss: 0.5488\n",
      "Epoch 866/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.8033\n",
      "Epoch 866: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.8035 - val_accuracy: 0.8405 - val_loss: 0.5482\n",
      "Epoch 867/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7097 - loss: 0.8141\n",
      "Epoch 867: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7099 - loss: 0.8137 - val_accuracy: 0.8403 - val_loss: 0.5453\n",
      "Epoch 868/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7125 - loss: 0.8072\n",
      "Epoch 868: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7126 - loss: 0.8072 - val_accuracy: 0.8405 - val_loss: 0.5494\n",
      "Epoch 869/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: 0.7912\n",
      "Epoch 869: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 0.7917 - val_accuracy: 0.8403 - val_loss: 0.5460\n",
      "Epoch 870/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7127 - loss: 0.8142\n",
      "Epoch 870: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7127 - loss: 0.8142 - val_accuracy: 0.8397 - val_loss: 0.5460\n",
      "Epoch 871/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 0.8156\n",
      "Epoch 871: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7154 - loss: 0.8156 - val_accuracy: 0.8402 - val_loss: 0.5492\n",
      "Epoch 872/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7136 - loss: 0.8105\n",
      "Epoch 872: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7137 - loss: 0.8104 - val_accuracy: 0.8392 - val_loss: 0.5479\n",
      "Epoch 873/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7202 - loss: 0.7928\n",
      "Epoch 873: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7202 - loss: 0.7929 - val_accuracy: 0.8418 - val_loss: 0.5453\n",
      "Epoch 874/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7170 - loss: 0.8200\n",
      "Epoch 874: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7169 - loss: 0.8200 - val_accuracy: 0.8398 - val_loss: 0.5507\n",
      "Epoch 875/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7143 - loss: 0.8216\n",
      "Epoch 875: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7144 - loss: 0.8214 - val_accuracy: 0.8405 - val_loss: 0.5467\n",
      "Epoch 876/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7219 - loss: 0.8054\n",
      "Epoch 876: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.8055 - val_accuracy: 0.8418 - val_loss: 0.5470\n",
      "Epoch 877/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.7996\n",
      "Epoch 877: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.7996 - val_accuracy: 0.8403 - val_loss: 0.5510\n",
      "Epoch 878/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7108 - loss: 0.8193\n",
      "Epoch 878: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7108 - loss: 0.8191 - val_accuracy: 0.8411 - val_loss: 0.5451\n",
      "Epoch 879/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7192 - loss: 0.7944\n",
      "Epoch 879: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.7945 - val_accuracy: 0.8397 - val_loss: 0.5464\n",
      "Epoch 880/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.7999\n",
      "Epoch 880: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.7998 - val_accuracy: 0.8410 - val_loss: 0.5450\n",
      "Epoch 881/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7067 - loss: 0.8166\n",
      "Epoch 881: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7069 - loss: 0.8164 - val_accuracy: 0.8397 - val_loss: 0.5459\n",
      "Epoch 882/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.7899\n",
      "Epoch 882: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7189 - loss: 0.7899 - val_accuracy: 0.8389 - val_loss: 0.5458\n",
      "Epoch 883/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7219 - loss: 0.7966\n",
      "Epoch 883: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7219 - loss: 0.7968 - val_accuracy: 0.8416 - val_loss: 0.5476\n",
      "Epoch 884/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7207 - loss: 0.7994\n",
      "Epoch 884: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: 0.7995 - val_accuracy: 0.8394 - val_loss: 0.5510\n",
      "Epoch 885/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.7952\n",
      "Epoch 885: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.7953 - val_accuracy: 0.8416 - val_loss: 0.5467\n",
      "Epoch 886/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7192 - loss: 0.7984\n",
      "Epoch 886: val_loss did not improve from 0.54417\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7192 - loss: 0.7983 - val_accuracy: 0.8381 - val_loss: 0.5511\n",
      "Epoch 887/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.8240\n",
      "Epoch 887: val_loss improved from 0.54417 to 0.54134, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7134 - loss: 0.8237 - val_accuracy: 0.8434 - val_loss: 0.5413\n",
      "Epoch 888/1500\n",
      "\u001b[1m757/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.8059\n",
      "Epoch 888: val_loss did not improve from 0.54134\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.8058 - val_accuracy: 0.8434 - val_loss: 0.5416\n",
      "Epoch 889/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7216 - loss: 0.7959\n",
      "Epoch 889: val_loss improved from 0.54134 to 0.54085, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7216 - loss: 0.7960 - val_accuracy: 0.8436 - val_loss: 0.5409\n",
      "Epoch 890/1500\n",
      "\u001b[1m743/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7163 - loss: 0.7987\n",
      "Epoch 890: val_loss did not improve from 0.54085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7163 - loss: 0.7987 - val_accuracy: 0.8426 - val_loss: 0.5452\n",
      "Epoch 891/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7193 - loss: 0.8001\n",
      "Epoch 891: val_loss did not improve from 0.54085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7194 - loss: 0.8000 - val_accuracy: 0.8379 - val_loss: 0.5476\n",
      "Epoch 892/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7147 - loss: 0.8111\n",
      "Epoch 892: val_loss did not improve from 0.54085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7148 - loss: 0.8109 - val_accuracy: 0.8382 - val_loss: 0.5493\n",
      "Epoch 893/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7176 - loss: 0.8064\n",
      "Epoch 893: val_loss did not improve from 0.54085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7176 - loss: 0.8063 - val_accuracy: 0.8421 - val_loss: 0.5425\n",
      "Epoch 894/1500\n",
      "\u001b[1m766/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7184 - loss: 0.8054\n",
      "Epoch 894: val_loss did not improve from 0.54085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7183 - loss: 0.8054 - val_accuracy: 0.8384 - val_loss: 0.5485\n",
      "Epoch 895/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7123 - loss: 0.8083\n",
      "Epoch 895: val_loss did not improve from 0.54085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7123 - loss: 0.8082 - val_accuracy: 0.8419 - val_loss: 0.5410\n",
      "Epoch 896/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7172 - loss: 0.8002\n",
      "Epoch 896: val_loss did not improve from 0.54085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7172 - loss: 0.8002 - val_accuracy: 0.8418 - val_loss: 0.5462\n",
      "Epoch 897/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7135 - loss: 0.8119\n",
      "Epoch 897: val_loss did not improve from 0.54085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7136 - loss: 0.8117 - val_accuracy: 0.8423 - val_loss: 0.5454\n",
      "Epoch 898/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7205 - loss: 0.7958\n",
      "Epoch 898: val_loss did not improve from 0.54085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 0.7960 - val_accuracy: 0.8424 - val_loss: 0.5409\n",
      "Epoch 899/1500\n",
      "\u001b[1m741/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7165 - loss: 0.7990\n",
      "Epoch 899: val_loss did not improve from 0.54085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7164 - loss: 0.7993 - val_accuracy: 0.8423 - val_loss: 0.5428\n",
      "Epoch 900/1500\n",
      "\u001b[1m746/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.7759\n",
      "Epoch 900: val_loss did not improve from 0.54085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.7764 - val_accuracy: 0.8426 - val_loss: 0.5440\n",
      "Epoch 901/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.8032\n",
      "Epoch 901: val_loss did not improve from 0.54085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7143 - loss: 0.8032 - val_accuracy: 0.8416 - val_loss: 0.5437\n",
      "Epoch 902/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7176 - loss: 0.8012\n",
      "Epoch 902: val_loss did not improve from 0.54085\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7176 - loss: 0.8012 - val_accuracy: 0.8429 - val_loss: 0.5422\n",
      "Epoch 903/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7197 - loss: 0.8007\n",
      "Epoch 903: val_loss improved from 0.54085 to 0.53870, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7198 - loss: 0.8004 - val_accuracy: 0.8431 - val_loss: 0.5387\n",
      "Epoch 904/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.7873\n",
      "Epoch 904: val_loss did not improve from 0.53870\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.7876 - val_accuracy: 0.8434 - val_loss: 0.5414\n",
      "Epoch 905/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7214 - loss: 0.8004\n",
      "Epoch 905: val_loss did not improve from 0.53870\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7213 - loss: 0.8004 - val_accuracy: 0.8439 - val_loss: 0.5400\n",
      "Epoch 906/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.7975\n",
      "Epoch 906: val_loss did not improve from 0.53870\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.7976 - val_accuracy: 0.8418 - val_loss: 0.5427\n",
      "Epoch 907/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7273 - loss: 0.7834\n",
      "Epoch 907: val_loss did not improve from 0.53870\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7273 - loss: 0.7837 - val_accuracy: 0.8413 - val_loss: 0.5410\n",
      "Epoch 908/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7186 - loss: 0.7938\n",
      "Epoch 908: val_loss did not improve from 0.53870\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7186 - loss: 0.7937 - val_accuracy: 0.8415 - val_loss: 0.5413\n",
      "Epoch 909/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.7993\n",
      "Epoch 909: val_loss did not improve from 0.53870\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.7993 - val_accuracy: 0.8405 - val_loss: 0.5479\n",
      "Epoch 910/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7184 - loss: 0.7962\n",
      "Epoch 910: val_loss did not improve from 0.53870\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7184 - loss: 0.7964 - val_accuracy: 0.8410 - val_loss: 0.5410\n",
      "Epoch 911/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.8015\n",
      "Epoch 911: val_loss improved from 0.53870 to 0.53780, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.8015 - val_accuracy: 0.8432 - val_loss: 0.5378\n",
      "Epoch 912/1500\n",
      "\u001b[1m747/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7178 - loss: 0.7928\n",
      "Epoch 912: val_loss did not improve from 0.53780\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7178 - loss: 0.7930 - val_accuracy: 0.8436 - val_loss: 0.5414\n",
      "Epoch 913/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7120 - loss: 0.7993\n",
      "Epoch 913: val_loss did not improve from 0.53780\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7121 - loss: 0.7993 - val_accuracy: 0.8419 - val_loss: 0.5405\n",
      "Epoch 914/1500\n",
      "\u001b[1m768/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 0.8086\n",
      "Epoch 914: val_loss did not improve from 0.53780\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7149 - loss: 0.8085 - val_accuracy: 0.8426 - val_loss: 0.5397\n",
      "Epoch 915/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7116 - loss: 0.8058\n",
      "Epoch 915: val_loss did not improve from 0.53780\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7117 - loss: 0.8056 - val_accuracy: 0.8416 - val_loss: 0.5408\n",
      "Epoch 916/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7205 - loss: 0.7924\n",
      "Epoch 916: val_loss did not improve from 0.53780\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 0.7925 - val_accuracy: 0.8415 - val_loss: 0.5431\n",
      "Epoch 917/1500\n",
      "\u001b[1m767/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: 0.8111\n",
      "Epoch 917: val_loss did not improve from 0.53780\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: 0.8110 - val_accuracy: 0.8408 - val_loss: 0.5404\n",
      "Epoch 918/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.8109\n",
      "Epoch 918: val_loss did not improve from 0.53780\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7143 - loss: 0.8107 - val_accuracy: 0.8390 - val_loss: 0.5419\n",
      "Epoch 919/1500\n",
      "\u001b[1m743/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7192 - loss: 0.7924\n",
      "Epoch 919: val_loss did not improve from 0.53780\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7192 - loss: 0.7926 - val_accuracy: 0.8405 - val_loss: 0.5442\n",
      "Epoch 920/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7173 - loss: 0.8002\n",
      "Epoch 920: val_loss did not improve from 0.53780\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7174 - loss: 0.8001 - val_accuracy: 0.8402 - val_loss: 0.5415\n",
      "Epoch 921/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7181 - loss: 0.8091\n",
      "Epoch 921: val_loss did not improve from 0.53780\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.8089 - val_accuracy: 0.8421 - val_loss: 0.5411\n",
      "Epoch 922/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7121 - loss: 0.8061\n",
      "Epoch 922: val_loss improved from 0.53780 to 0.53725, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7122 - loss: 0.8059 - val_accuracy: 0.8428 - val_loss: 0.5373\n",
      "Epoch 923/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.7860\n",
      "Epoch 923: val_loss did not improve from 0.53725\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7300 - loss: 0.7861 - val_accuracy: 0.8423 - val_loss: 0.5410\n",
      "Epoch 924/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7172 - loss: 0.8022\n",
      "Epoch 924: val_loss did not improve from 0.53725\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7172 - loss: 0.8023 - val_accuracy: 0.8403 - val_loss: 0.5413\n",
      "Epoch 925/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7165 - loss: 0.7981\n",
      "Epoch 925: val_loss did not improve from 0.53725\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7165 - loss: 0.7981 - val_accuracy: 0.8449 - val_loss: 0.5376\n",
      "Epoch 926/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.8056\n",
      "Epoch 926: val_loss did not improve from 0.53725\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.8055 - val_accuracy: 0.8395 - val_loss: 0.5446\n",
      "Epoch 927/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7292 - loss: 0.7749\n",
      "Epoch 927: val_loss did not improve from 0.53725\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7291 - loss: 0.7751 - val_accuracy: 0.8397 - val_loss: 0.5404\n",
      "Epoch 928/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.7999\n",
      "Epoch 928: val_loss did not improve from 0.53725\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.7998 - val_accuracy: 0.8411 - val_loss: 0.5411\n",
      "Epoch 929/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7100 - loss: 0.8039\n",
      "Epoch 929: val_loss did not improve from 0.53725\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7101 - loss: 0.8037 - val_accuracy: 0.8436 - val_loss: 0.5406\n",
      "Epoch 930/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7214 - loss: 0.8027\n",
      "Epoch 930: val_loss did not improve from 0.53725\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7214 - loss: 0.8027 - val_accuracy: 0.8418 - val_loss: 0.5390\n",
      "Epoch 931/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.8021\n",
      "Epoch 931: val_loss did not improve from 0.53725\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.8020 - val_accuracy: 0.8447 - val_loss: 0.5386\n",
      "Epoch 932/1500\n",
      "\u001b[1m739/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: 0.8098\n",
      "Epoch 932: val_loss improved from 0.53725 to 0.53592, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7105 - loss: 0.8097 - val_accuracy: 0.8450 - val_loss: 0.5359\n",
      "Epoch 933/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.7933\n",
      "Epoch 933: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.7933 - val_accuracy: 0.8429 - val_loss: 0.5410\n",
      "Epoch 934/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: 0.7910\n",
      "Epoch 934: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: 0.7911 - val_accuracy: 0.8444 - val_loss: 0.5376\n",
      "Epoch 935/1500\n",
      "\u001b[1m741/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.8115\n",
      "Epoch 935: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7121 - loss: 0.8111 - val_accuracy: 0.8426 - val_loss: 0.5418\n",
      "Epoch 936/1500\n",
      "\u001b[1m743/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7181 - loss: 0.8003\n",
      "Epoch 936: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7181 - loss: 0.8002 - val_accuracy: 0.8428 - val_loss: 0.5367\n",
      "Epoch 937/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.7928\n",
      "Epoch 937: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.7928 - val_accuracy: 0.8429 - val_loss: 0.5429\n",
      "Epoch 938/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7194 - loss: 0.7956\n",
      "Epoch 938: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7194 - loss: 0.7956 - val_accuracy: 0.8450 - val_loss: 0.5375\n",
      "Epoch 939/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7134 - loss: 0.8138\n",
      "Epoch 939: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.8130 - val_accuracy: 0.8445 - val_loss: 0.5426\n",
      "Epoch 940/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7163 - loss: 0.8038\n",
      "Epoch 940: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7163 - loss: 0.8037 - val_accuracy: 0.8440 - val_loss: 0.5385\n",
      "Epoch 941/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7101 - loss: 0.8119\n",
      "Epoch 941: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7102 - loss: 0.8119 - val_accuracy: 0.8436 - val_loss: 0.5370\n",
      "Epoch 942/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7258 - loss: 0.7835\n",
      "Epoch 942: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.7836 - val_accuracy: 0.8413 - val_loss: 0.5412\n",
      "Epoch 943/1500\n",
      "\u001b[1m742/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7122 - loss: 0.8019\n",
      "Epoch 943: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7122 - loss: 0.8018 - val_accuracy: 0.8434 - val_loss: 0.5378\n",
      "Epoch 944/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.7921\n",
      "Epoch 944: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.7921 - val_accuracy: 0.8418 - val_loss: 0.5363\n",
      "Epoch 945/1500\n",
      "\u001b[1m761/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7158 - loss: 0.8005\n",
      "Epoch 945: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7158 - loss: 0.8003 - val_accuracy: 0.8421 - val_loss: 0.5406\n",
      "Epoch 946/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7156 - loss: 0.7920\n",
      "Epoch 946: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7157 - loss: 0.7919 - val_accuracy: 0.8450 - val_loss: 0.5363\n",
      "Epoch 947/1500\n",
      "\u001b[1m765/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7165 - loss: 0.8026\n",
      "Epoch 947: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7166 - loss: 0.8025 - val_accuracy: 0.8465 - val_loss: 0.5362\n",
      "Epoch 948/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7236 - loss: 0.7962\n",
      "Epoch 948: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7235 - loss: 0.7960 - val_accuracy: 0.8419 - val_loss: 0.5415\n",
      "Epoch 949/1500\n",
      "\u001b[1m739/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.7932\n",
      "Epoch 949: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.7933 - val_accuracy: 0.8450 - val_loss: 0.5360\n",
      "Epoch 950/1500\n",
      "\u001b[1m763/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7202 - loss: 0.7945\n",
      "Epoch 950: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7202 - loss: 0.7946 - val_accuracy: 0.8432 - val_loss: 0.5363\n",
      "Epoch 951/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: 0.7786\n",
      "Epoch 951: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7242 - loss: 0.7789 - val_accuracy: 0.8406 - val_loss: 0.5396\n",
      "Epoch 952/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.7998\n",
      "Epoch 952: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.7997 - val_accuracy: 0.8439 - val_loss: 0.5375\n",
      "Epoch 953/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7255 - loss: 0.7903\n",
      "Epoch 953: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7255 - loss: 0.7904 - val_accuracy: 0.8431 - val_loss: 0.5379\n",
      "Epoch 954/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.7857\n",
      "Epoch 954: val_loss did not improve from 0.53592\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.7858 - val_accuracy: 0.8421 - val_loss: 0.5393\n",
      "Epoch 955/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 0.7969\n",
      "Epoch 955: val_loss improved from 0.53592 to 0.53259, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7108 - loss: 0.7968 - val_accuracy: 0.8470 - val_loss: 0.5326\n",
      "Epoch 956/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.7860\n",
      "Epoch 956: val_loss did not improve from 0.53259\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.7862 - val_accuracy: 0.8434 - val_loss: 0.5368\n",
      "Epoch 957/1500\n",
      "\u001b[1m759/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.7929\n",
      "Epoch 957: val_loss improved from 0.53259 to 0.53023, saving model to C:\\Users\\user\\Desktop\\DNN_eflow.weights.h5\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7239 - loss: 0.7930 - val_accuracy: 0.8453 - val_loss: 0.5302\n",
      "Epoch 958/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7205 - loss: 0.7885\n",
      "Epoch 958: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.7889 - val_accuracy: 0.8429 - val_loss: 0.5362\n",
      "Epoch 959/1500\n",
      "\u001b[1m751/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.7846\n",
      "Epoch 959: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.7850 - val_accuracy: 0.8455 - val_loss: 0.5351\n",
      "Epoch 960/1500\n",
      "\u001b[1m769/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.7870\n",
      "Epoch 960: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.7871 - val_accuracy: 0.8429 - val_loss: 0.5350\n",
      "Epoch 961/1500\n",
      "\u001b[1m752/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.7939\n",
      "Epoch 961: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.7938 - val_accuracy: 0.8452 - val_loss: 0.5346\n",
      "Epoch 962/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7232 - loss: 0.7915\n",
      "Epoch 962: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 0.7918 - val_accuracy: 0.8431 - val_loss: 0.5395\n",
      "Epoch 963/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7193 - loss: 0.7841\n",
      "Epoch 963: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7192 - loss: 0.7844 - val_accuracy: 0.8437 - val_loss: 0.5347\n",
      "Epoch 964/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7141 - loss: 0.8079\n",
      "Epoch 964: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.8078 - val_accuracy: 0.8463 - val_loss: 0.5370\n",
      "Epoch 965/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7192 - loss: 0.8026\n",
      "Epoch 965: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7192 - loss: 0.8024 - val_accuracy: 0.8453 - val_loss: 0.5348\n",
      "Epoch 966/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7196 - loss: 0.7923\n",
      "Epoch 966: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7195 - loss: 0.7923 - val_accuracy: 0.8431 - val_loss: 0.5420\n",
      "Epoch 967/1500\n",
      "\u001b[1m754/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7201 - loss: 0.7932\n",
      "Epoch 967: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7201 - loss: 0.7932 - val_accuracy: 0.8421 - val_loss: 0.5365\n",
      "Epoch 968/1500\n",
      "\u001b[1m771/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7168 - loss: 0.7857\n",
      "Epoch 968: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7168 - loss: 0.7857 - val_accuracy: 0.8423 - val_loss: 0.5353\n",
      "Epoch 969/1500\n",
      "\u001b[1m756/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7169 - loss: 0.8012\n",
      "Epoch 969: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7169 - loss: 0.8012 - val_accuracy: 0.8457 - val_loss: 0.5323\n",
      "Epoch 970/1500\n",
      "\u001b[1m736/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7186 - loss: 0.7967\n",
      "Epoch 970: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 0.7967 - val_accuracy: 0.8419 - val_loss: 0.5396\n",
      "Epoch 971/1500\n",
      "\u001b[1m750/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7145 - loss: 0.7986\n",
      "Epoch 971: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7146 - loss: 0.7985 - val_accuracy: 0.8453 - val_loss: 0.5350\n",
      "Epoch 972/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7151 - loss: 0.8062\n",
      "Epoch 972: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7152 - loss: 0.8061 - val_accuracy: 0.8440 - val_loss: 0.5342\n",
      "Epoch 973/1500\n",
      "\u001b[1m755/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.7980\n",
      "Epoch 973: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.7979 - val_accuracy: 0.8447 - val_loss: 0.5348\n",
      "Epoch 974/1500\n",
      "\u001b[1m744/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7152 - loss: 0.8025\n",
      "Epoch 974: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7153 - loss: 0.8019 - val_accuracy: 0.8421 - val_loss: 0.5332\n",
      "Epoch 975/1500\n",
      "\u001b[1m745/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7269 - loss: 0.7686\n",
      "Epoch 975: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7269 - loss: 0.7689 - val_accuracy: 0.8431 - val_loss: 0.5362\n",
      "Epoch 976/1500\n",
      "\u001b[1m741/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7197 - loss: 0.7841\n",
      "Epoch 976: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7197 - loss: 0.7843 - val_accuracy: 0.8419 - val_loss: 0.5396\n",
      "Epoch 977/1500\n",
      "\u001b[1m753/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.7794\n",
      "Epoch 977: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.7794 - val_accuracy: 0.8447 - val_loss: 0.5346\n",
      "Epoch 978/1500\n",
      "\u001b[1m741/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7150 - loss: 0.8005\n",
      "Epoch 978: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7151 - loss: 0.8004 - val_accuracy: 0.8429 - val_loss: 0.5327\n",
      "Epoch 979/1500\n",
      "\u001b[1m762/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.7985\n",
      "Epoch 979: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.7984 - val_accuracy: 0.8402 - val_loss: 0.5385\n",
      "Epoch 980/1500\n",
      "\u001b[1m764/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7198 - loss: 0.7965\n",
      "Epoch 980: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7198 - loss: 0.7964 - val_accuracy: 0.8440 - val_loss: 0.5334\n",
      "Epoch 981/1500\n",
      "\u001b[1m748/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7193 - loss: 0.7894\n",
      "Epoch 981: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7194 - loss: 0.7894 - val_accuracy: 0.8432 - val_loss: 0.5362\n",
      "Epoch 982/1500\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7197 - loss: 0.7872\n",
      "Epoch 982: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7196 - loss: 0.7872 - val_accuracy: 0.8450 - val_loss: 0.5304\n",
      "Epoch 983/1500\n",
      "\u001b[1m749/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.7980\n",
      "Epoch 983: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7162 - loss: 0.7978 - val_accuracy: 0.8458 - val_loss: 0.5303\n",
      "Epoch 984/1500\n",
      "\u001b[1m770/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.7784\n",
      "Epoch 984: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7227 - loss: 0.7784 - val_accuracy: 0.8462 - val_loss: 0.5346\n",
      "Epoch 985/1500\n",
      "\u001b[1m758/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.7842\n",
      "Epoch 985: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.7844 - val_accuracy: 0.8455 - val_loss: 0.5343\n",
      "Epoch 986/1500\n",
      "\u001b[1m760/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.7978\n",
      "Epoch 986: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.7978 - val_accuracy: 0.8447 - val_loss: 0.5319\n",
      "Epoch 987/1500\n",
      "\u001b[1m740/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7177 - loss: 0.7896\n",
      "Epoch 987: val_loss did not improve from 0.53023\n",
      "\u001b[1m772/772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7177 - loss: 0.7895 - val_accuracy: 0.8444 - val_loss: 0.5330\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "from keras.layers import LeakyReLU, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# Enable Mixed Precision (새로운 방식으로 설정)\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')\n",
    "\n",
    "# 1. 데이터 로드 및 전처리\n",
    "X = df.iloc[:, :-1]\n",
    "y = df['fixed_type_encoded']  # 타겟 클래스\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # 결측값(9)을 NaN으로 대체하고 나중에 처리\n",
    "# X.replace(9, np.nan, inplace=True)\n",
    "\n",
    "# # 결측치를 열 별 최빈값으로 대체\n",
    "# X.fillna(df.mode().iloc[0], inplace=True)\n",
    "\n",
    "# 데이터가 모두 숫자인지 확인하고, 필요시 변환\n",
    "X = X.astype(float)\n",
    "\n",
    "# OneHot 인코딩으로 타겟을 인코딩 (다중 클래스 분류이므로 필요)\n",
    "onehot = OneHotEncoder(sparse_output=False)  \n",
    "y_encoded = onehot.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# 2. 훈련 데이터와 테스트 데이터로 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. 딥러닝 모델 정의 (이후 코드는 동일)\n",
    "# model = Sequential()\n",
    "# model.add(layers.Dense(128, activation='leakyrelu', input_shape=(x_train.shape[1],), name='Hidden-1'))\n",
    "# model.add(layers.Dropout(0.3))  # Dropout 규제\n",
    "# model.add(layers.Dense(64, activation='leakyrelu', name='Hidden-2'))\n",
    "# model.add(layers.Dropout(0.3))\n",
    "# model.add(layers.Dense(32, activation='leakyrelu', name='Hidden-3'))\n",
    "# model.add(layers.Dropout(0.3))  # Dropout 규제\n",
    "# model.add(layers.Dense(y_train.shape[1], activation='softmax'))  # Output layer with 'softmax' for multi-class classification\n",
    "model = Sequential()\n",
    "#hidden1\n",
    "model.add(layers.Dense(128, input_shape=(x_train.shape[1],), name='Hidden-1',kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))  # LeakyReLU 활성화 함수 추가\n",
    "model.add(layers.Dropout(0.3))  # Dropout 규제\n",
    "#hidden2\n",
    "model.add(layers.Dense(64, name='Hidden-2',kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))  # LeakyReLU 활성화 함수 추가\n",
    "model.add(layers.Dropout(0.3))\n",
    "#hidden3\n",
    "model.add(layers.Dense(32, name='Hidden-3',kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))  # LeakyReLU 활성화 함수 추가\n",
    "model.add(layers.Dropout(0.3))\n",
    "#hidden4\n",
    "model.add(layers.Dense(16, name='Hidden-4',kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))  # LeakyReLU 활성화 함수 추가\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(y_train.shape[1], activation='softmax'))  # 다중 클래스 분류를 위한 softmax 출력층\n",
    "\n",
    "# 4. 모델 컴파일 (이후 코드는 동일)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 5. 콜백 설정 및 모델 학습\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=30)\n",
    "model_path = 'C:\\\\Users\\\\user\\\\Desktop\\\\DNN_eflow.weights.h5'\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='auto')\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=1500, \n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_test, y_test), \n",
    "                    callbacks=[early_stop, checkpoint])\n",
    "\n",
    "# 6. 학습 결과 시각화\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Accuracy: 0.8453441295546559\n",
      "F1 Score: 0.8379049780983641\n",
      "Precision: 0.8375880083114229\n",
      "Recall: 0.8453441295546559\n",
      "Cohen's Kappa: 0.7895162992916983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. 예측값 계산 (학습)\n",
    "predictions = model.predict(x_test)  # 각 클래스에 대한 확률 예측\n",
    "actual = np.asarray(y_test)\n",
    "\n",
    "# 예측값과 실제값 변환 (argmax로 가장 높은 확률의 클래스로 변환)\n",
    "pred = [np.argmax(pred) for pred in predictions]  # 예측값\n",
    "act = [np.argmax(a) for a in actual]  # 실제값\n",
    "\n",
    "# DataFrame으로 변환\n",
    "pred_df = pd.DataFrame(pred, columns=[\"예측값\"])\n",
    "actual_df = pd.DataFrame(act, columns=[\"실제값\"])\n",
    "\n",
    "# 2. 성능 지표 계산\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# 정확도\n",
    "accuracy = accuracy_score(actual_df[\"실제값\"], pred_df[\"예측값\"])\n",
    "\n",
    "# F1 스코어 (다중 클래스이므로 weighted 평균 사용)\n",
    "f1 = f1_score(actual_df[\"실제값\"], pred_df[\"예측값\"], average='weighted')\n",
    "\n",
    "# 정밀도 (Precision)\n",
    "precision = precision_score(actual_df[\"실제값\"], pred_df[\"예측값\"], average='weighted')\n",
    "\n",
    "# 재현율 (Recall)\n",
    "recall = recall_score(actual_df[\"실제값\"], pred_df[\"예측값\"], average='weighted')\n",
    "\n",
    "# 성능 결과 출력\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "kappa = cohen_kappa_score(actual_df[\"실제값\"], pred_df[\"예측값\"])\n",
    "print(f\"Cohen's Kappa: {kappa}\")\n",
    "\n",
    "# 3. 혼동 행렬 계산 및 시각화\n",
    "conf_matrix = confusion_matrix(actual_df[\"실제값\"], pred_df[\"예측값\"])\n",
    "\n",
    "# 혼동 행렬 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(act), yticklabels=np.unique(act))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n",
    "\n",
    "# 4. 결과 저장\n",
    "pred_df.to_excel(\"C:\\\\Users\\\\user\\\\Desktop\\\\DNN_Pred.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
